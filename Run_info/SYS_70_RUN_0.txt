[INFO] Number of total samples: 4600
[INFO] Observable dimension of a sample: 7
[INFO] Xp.shape (E-DMD): (4600, 7)
[INFO] Yf.shape (E-DMD): (4600, 7)
Number of training snapshots: 2300
Number of validation snapshots: 2300
70
0.4803844614152614
0.5
0.5773502691896257
0.2847473987257497
2.057039
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.5
Train Error Threshold      :  1e-06
Validation Error Threshold :  1e-06
Maximum number of Epochs   :  1000
Batch Size   :  400
--------------------------------------
Epoch No:  1000  |   Training error:  0.0020471942
                   Validation error:  0.0022785766
---------------------------------------------------------------------------------------------------
Current Training Error  : 0.0020471942
Current Validation Error      : 0.0022785766
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.3
Train Error Threshold      :  1e-06
Validation Error Threshold :  1e-06
Maximum number of Epochs   :  10000
Batch Size   :  400
--------------------------------------
Epoch No:  1000  |   Training error:  0.0016101087
                   Validation error:  0.0018298235
---------------------------------------------------------------------------------------------------
Epoch No:  2000  |   Training error:  0.0014407398
                   Validation error:  0.0016512247
---------------------------------------------------------------------------------------------------
Epoch No:  3000  |   Training error:  0.0013445417
                   Validation error:  0.0015492928
---------------------------------------------------------------------------------------------------
Epoch No:  4000  |   Training error:  0.0013371907
                   Validation error:  0.0015309013
---------------------------------------------------------------------------------------------------
Epoch No:  5000  |   Training error:  0.0013131422
                   Validation error:  0.0015228768
---------------------------------------------------------------------------------------------------
Epoch No:  6000  |   Training error:  0.0012290267
                   Validation error:  0.0014231305
---------------------------------------------------------------------------------------------------
Epoch No:  7000  |   Training error:  0.0011816313
                   Validation error:  0.0013784955
---------------------------------------------------------------------------------------------------
Epoch No:  8000  |   Training error:  0.0011588562
                   Validation error:  0.0013583943
---------------------------------------------------------------------------------------------------
Epoch No:  9000  |   Training error:  0.0011429444
                   Validation error:  0.0013416273
---------------------------------------------------------------------------------------------------
Epoch No:  10000  |   Training error:  0.0011436051
                    Validation error:  0.0013430172
---------------------------------------------------------------------------------------------------
Current Training Error  : 0.0011436051
Current Validation Error      : 0.0013430172
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.1
Train Error Threshold      :  1e-07
Validation Error Threshold :  1e-07
Maximum number of Epochs   :  10000
Batch Size   :  400
--------------------------------------
Epoch No:  1000  |   Training error:  0.0011177592
                   Validation error:  0.0013182358
---------------------------------------------------------------------------------------------------
Epoch No:  2000  |   Training error:  0.0011132996
                   Validation error:  0.0013142014
---------------------------------------------------------------------------------------------------
Epoch No:  3000  |   Training error:  0.0011102991
                   Validation error:  0.0013111954
---------------------------------------------------------------------------------------------------
Epoch No:  4000  |   Training error:  0.0011056135
                   Validation error:  0.0013063991
---------------------------------------------------------------------------------------------------
Epoch No:  5000  |   Training error:  0.001100901
                   Validation error:  0.0013027319
---------------------------------------------------------------------------------------------------
Epoch No:  6000  |   Training error:  0.0010971868
                   Validation error:  0.0012996517
---------------------------------------------------------------------------------------------------
Epoch No:  7000  |   Training error:  0.0010936839
                   Validation error:  0.0012964623
---------------------------------------------------------------------------------------------------
Epoch No:  8000  |   Training error:  0.0010903699
                   Validation error:  0.0012925507
---------------------------------------------------------------------------------------------------
Epoch No:  9000  |   Training error:  0.0010880621
                   Validation error:  0.0012897297
---------------------------------------------------------------------------------------------------
Epoch No:  10000  |   Training error:  0.0010843748
                    Validation error:  0.0012868479
---------------------------------------------------------------------------------------------------
Current Training Error  : 0.0010843748
Current Validation Error      : 0.0012868479
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.09
Train Error Threshold      :  1e-08
Validation Error Threshold :  1e-08
Maximum number of Epochs   :  10000
Batch Size   :  400
--------------------------------------
Epoch No:  1000  |   Training error:  0.0010793352
                   Validation error:  0.0012814635
---------------------------------------------------------------------------------------------------
Epoch No:  2000  |   Training error:  0.0010786866
                   Validation error:  0.0012812755
---------------------------------------------------------------------------------------------------
Epoch No:  3000  |   Training error:  0.00107329
                   Validation error:  0.0012749445
---------------------------------------------------------------------------------------------------
Epoch No:  4000  |   Training error:  0.0010698341
                   Validation error:  0.0012711866
---------------------------------------------------------------------------------------------------
Epoch No:  5000  |   Training error:  0.001066339
                   Validation error:  0.0012675762
---------------------------------------------------------------------------------------------------
Epoch No:  6000  |   Training error:  0.0010629958
                   Validation error:  0.0012635158
---------------------------------------------------------------------------------------------------
Epoch No:  7000  |   Training error:  0.0010599623
                   Validation error:  0.0012604963
---------------------------------------------------------------------------------------------------
Epoch No:  8000  |   Training error:  0.0010554539
                   Validation error:  0.0012552503
---------------------------------------------------------------------------------------------------
Epoch No:  9000  |   Training error:  0.0010515114
                   Validation error:  0.00125102
---------------------------------------------------------------------------------------------------
Epoch No:  10000  |   Training error:  0.0010476259
                    Validation error:  0.0012464756
---------------------------------------------------------------------------------------------------
Current Training Error  : 0.0010476259
Current Validation Error      : 0.0012464756
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.08
Train Error Threshold      :  1e-08
Validation Error Threshold :  1e-08
Maximum number of Epochs   :  10000
Batch Size   :  400
--------------------------------------
Epoch No:  1000  |   Training error:  0.0010450645
                   Validation error:  0.001243627
---------------------------------------------------------------------------------------------------
Epoch No:  2000  |   Training error:  0.0010411986
                   Validation error:  0.0012397375
---------------------------------------------------------------------------------------------------
Epoch No:  3000  |   Training error:  0.0010370357
                   Validation error:  0.001235574
---------------------------------------------------------------------------------------------------
Epoch No:  4000  |   Training error:  0.001034562
                   Validation error:  0.0012334952
---------------------------------------------------------------------------------------------------
Epoch No:  5000  |   Training error:  0.0010312588
                   Validation error:  0.0012302983
---------------------------------------------------------------------------------------------------
Epoch No:  6000  |   Training error:  0.0010270292
                   Validation error:  0.0012262093
---------------------------------------------------------------------------------------------------
Epoch No:  7000  |   Training error:  0.0010234906
                   Validation error:  0.0012238054
---------------------------------------------------------------------------------------------------
Epoch No:  8000  |   Training error:  0.0010203496
                   Validation error:  0.0012210542
---------------------------------------------------------------------------------------------------
Epoch No:  9000  |   Training error:  0.0010165876
                   Validation error:  0.001218371
---------------------------------------------------------------------------------------------------
Epoch No:  10000  |   Training error:  0.0010132061
                    Validation error:  0.0012152403
---------------------------------------------------------------------------------------------------
Current Training Error  : 0.0010132061
Current Validation Error      : 0.0012152403
0.0010132061
---   OUTPUT COMPENSATED STATE TRAINING COMPLETE   ---
                                  0           1  ...           3           4
MSE training             0.00204719  0.00114361  ...  0.00104763  0.00101321
MSE validation           0.00227858  0.00134302  ...  0.00124648  0.00121524
activation flag                   2           2  ...           2           2
activation function             elu         elu  ...         elu         elu
batch size                      400         400  ...         400         400
no of epochs                   1000       10000  ...       10000       10000
r^2 training accuracy       95.4004     97.4083  ...     97.5782     97.6586
r^2 validation accuracy     94.9362     96.9285  ...      97.083     97.1468
step size                       0.5         0.3  ...        0.09        0.08
training error           0.00204719  0.00114361  ...  0.00104763  0.00101321
validation error         0.00227858  0.00134302  ...  0.00124648  0.00121524
x_hidden_variable_list    [6, 6, 3]   [6, 6, 3]  ...   [6, 6, 3]   [6, 6, 3]

[12 rows x 5 columns]
[[ 4.72021610e-01  3.38556647e-01  4.18689936e-01  5.00197947e-01
  -8.31248388e-02 -1.01515174e-01  3.24863672e-01 -1.07199080e-01
  -5.25555760e-02 -8.89151245e-02  1.40477065e-02 -4.08105925e-02
  -5.05048744e-02 -4.77822088e-02  3.71716097e-02 -4.54329997e-02
   1.43755116e-02 -4.80397791e-02  3.32842022e-02  6.11363053e-02
  -2.87101828e-02  1.82384923e-02  0.00000000e+00 -4.12337303e-01
   3.24655920e-01 -1.24408327e-01 -5.02387285e-01 -2.06434093e-02
  -5.06358445e-02  5.62729686e-03]
 [ 8.48779082e-01 -7.17963576e-01  4.39066291e-01 -4.07984763e-01
  -6.20698750e-01  1.23670173e+00  9.55862701e-02 -1.52714169e-02
  -2.87818648e-02 -6.84470981e-02  6.31697848e-02 -5.33242058e-03
   1.75399706e-02 -3.29068955e-03 -1.02510201e-02 -3.64312492e-02
  -8.67458135e-02  1.23510864e-02 -3.33768316e-02  6.75345659e-02
   1.99070331e-02  1.52588412e-01  0.00000000e+00  2.58281022e-01
   2.03587085e-01 -1.38544366e-02 -2.55340874e-01  1.23702683e-01
   8.43230262e-02 -1.55303730e-02]
 [-1.94961563e-01  1.55483186e-01  2.25668952e-01  4.12493140e-01
  -2.89172649e-01  5.04668131e-02  2.09587902e-01 -3.79245579e-02
   2.90083885e-02  1.40719330e-02 -9.05176252e-02 -1.37555199e-02
  -5.71453385e-02 -4.55610454e-03  6.52652234e-03 -2.30827183e-02
  -5.50810695e-02 -1.13127036e-02  7.05968589e-02 -5.37536992e-03
  -4.00860906e-02 -9.74392071e-02  0.00000000e+00  2.81244814e-01
   9.77065065e-04 -1.87420592e-01  1.21638685e-01  8.36841017e-03
   4.71372642e-02  2.15253569e-02]
 [ 1.42681122e-01  1.38099000e-01  8.26231465e-02 -2.26357430e-01
   2.51242518e-01 -2.18633577e-01 -5.43674342e-02 -1.85664743e-02
  -1.33187901e-02 -3.13937361e-03  4.41333950e-02 -3.78221180e-03
   1.29165230e-02 -2.42586769e-02  1.08600771e-02 -1.62226576e-02
   2.82936487e-02 -1.33429570e-02 -2.53299829e-02 -1.63266603e-02
   3.21783088e-02  4.04494070e-02  0.00000000e+00 -1.11716382e-01
   2.11330220e-01  3.92476805e-02 -1.26983836e-01 -5.83285354e-02
  -2.97826901e-02  1.04227504e-02]
 [-3.32499057e-01  2.28532419e-01  1.91549256e-01  2.63558447e-01
   1.80633068e-01 -9.07276496e-02  1.71841830e-01  1.72209516e-02
   1.33938745e-01  1.57564908e-01 -9.09818411e-02 -5.18622436e-02
  -6.73819110e-02  1.42334700e-01 -1.94332581e-02  4.73408625e-02
   1.58480048e-01  7.75364563e-02 -1.39649525e-01  3.54051404e-02
  -9.51924697e-02 -1.61421329e-01  0.00000000e+00 -5.51268339e-01
   8.25713500e-02  2.76592281e-02 -2.24414557e-01  1.21404314e-02
  -1.29421018e-02 -2.04169676e-02]
 [ 7.42916584e-01 -5.83198488e-01  2.36311868e-01 -8.48347068e-01
  -2.93863863e-01  9.25468326e-01 -5.09513199e-01  4.33954410e-02
   7.95441493e-02  7.11459294e-02  1.27575779e-02 -1.26514174e-02
   2.74136700e-02  7.45158195e-02 -3.37066762e-02 -1.36511875e-02
  -2.17071385e-03  8.58126134e-02 -1.21233612e-01  3.20427865e-02
  -7.66631439e-02  3.27694453e-02  0.00000000e+00  4.86871414e-02
  -6.11775033e-02  6.64975122e-02  8.99702758e-02  1.61608413e-01
   1.30482927e-01 -3.34106609e-02]
 [-3.14152181e-01  2.81061769e-01  2.43116930e-01  4.22723740e-01
  -1.06773570e-01 -1.62992939e-01  7.70393848e-01 -6.45077005e-02
   8.77915416e-03 -3.01323342e-03 -2.41301488e-02 -4.00016233e-02
  -2.90398877e-02 -9.98169184e-04  7.67876767e-03 -2.29442846e-02
  -2.15396704e-03 -2.02907324e-02  8.61994922e-03  6.58323690e-02
  -1.75015200e-02 -4.62848842e-02  0.00000000e+00 -3.58619928e-01
   2.70332694e-01  6.73865750e-02 -3.77056181e-01 -8.66112113e-02
  -8.02366585e-02  1.01704057e-02]
 [ 9.10587192e-01  8.89168978e-02 -1.71380925e+00 -5.12568235e-01
   6.78518340e-02 -4.41929698e-01 -9.30596709e-01 -3.02964635e-02
   2.90434062e-01  4.97242093e-01 -7.20400035e-01  1.38922380e-02
  -4.89886791e-01  3.62063706e-01  2.42087558e-01  2.55168200e-01
   1.15831215e-02  9.02870148e-02  2.27217302e-01 -1.47329539e-01
  -4.58247691e-01 -7.96424508e-01  0.00000000e+00 -2.38341618e+00
   6.75198734e-01 -2.02376157e-01 -1.59907281e+00 -3.52915539e-03
   6.15526596e-03  7.12292343e-02]
 [-6.24968290e-01  4.42626774e-01 -8.98404777e-01  5.56450903e-01
  -3.71360987e-01 -1.03725262e-01  4.02868062e-01 -2.66276747e-02
   3.57256889e-01  4.79882210e-01 -3.32526028e-01  1.75967604e-01
   1.85024559e-01  3.92382108e-02  1.07147612e-01  1.17679276e-01
  -1.73717827e-01  2.49621570e-01 -2.61997014e-01 -1.49054468e-01
   6.07348204e-01 -3.42899024e-01  0.00000000e+00 -1.71442270e+00
   5.33708990e-01  2.75964886e-01 -9.99372780e-01  3.12265055e-03
   1.93631351e-02  5.07161133e-02]
 [-1.77198768e-01 -2.86528707e-01 -8.13382789e-02  9.92919579e-02
  -1.29084074e+00  6.70777142e-01  5.77111483e-01 -8.88769776e-02
   1.41930491e-01  6.32992536e-02  9.32350382e-02 -1.15862206e-01
   4.02539283e-01  2.36165002e-01  3.53870749e-01  1.02935284e-02
  -1.75657466e-01 -9.69285741e-02 -1.60486192e-01  6.58358753e-01
  -3.83784086e-01 -2.24543065e-01  0.00000000e+00  3.38556796e-01
   6.68136328e-02 -4.99234110e-01  2.75127497e-02  3.04085225e-01
  -3.37647498e-02 -3.87767591e-02]
 [ 8.92740369e-01 -1.21604311e+00  4.66681808e-01  1.79148111e-02
   2.45707184e-02  8.30945373e-01 -4.89901006e-01  7.99527228e-01
   3.76926437e-02  7.68536404e-02 -2.08924741e-01  5.48284352e-01
   1.06011964e-01 -1.98116675e-01 -7.38254607e-01  3.28864068e-01
  -3.76861811e-01  2.27851868e-01  2.88977265e-01 -1.92369729e-01
   2.59052873e-01  8.39488745e-01  0.00000000e+00  2.38693070e+00
   5.19058585e-01 -4.15042788e-01  4.80691940e-01 -5.67216992e-01
  -4.44107890e-01  5.79882525e-02]
 [ 4.15755570e-01 -4.74210158e-02  1.38449565e-01  1.00829892e-01
   2.10326925e-01 -3.65294427e-01 -4.57485437e-01 -2.35200942e-01
   4.38201010e-01 -2.05884203e-01 -3.99543583e-01 -2.17268392e-02
   2.25557879e-01  3.87856886e-02 -2.18918407e-03 -3.40303332e-01
  -1.95349216e-01 -1.24205470e-01  1.33700356e-01  4.44391727e-01
  -7.81964242e-01 -7.58748293e-01  0.00000000e+00  4.52652834e-02
   2.59203434e-01 -7.51773417e-01 -5.17218351e-01 -1.95833623e-01
  -2.46394232e-01  2.06719562e-02]
 [ 6.41154051e-01  3.37557793e-01  2.83643931e-01 -1.35616457e+00
  -4.68263775e-01 -8.47803891e-01 -1.18001986e+00  3.76001120e-01
   3.91849801e-02  9.83202681e-02 -2.31172025e-01  1.15914106e-01
   2.60332048e-01  8.63628238e-02  2.35143956e-02 -1.70469269e-01
   1.18656598e-01  4.71216738e-01  1.21947691e-01 -8.08251441e-01
   9.03922096e-02  1.38807938e-01  0.00000000e+00  1.47572398e+00
   6.69378459e-01 -1.12785709e+00  1.08588588e+00  9.99344513e-03
   3.88388991e-01 -2.15763710e-02]
 [ 3.60034108e-02  7.67257344e-03 -6.98638380e-01  4.85708445e-01
  -1.29481101e+00  5.53385504e-02 -7.56273866e-02 -6.09043241e-01
  -3.51963460e-01 -1.95649624e-01 -3.39335240e-02 -2.34038636e-01
  -5.28396443e-02  2.19291836e-01 -6.03780933e-02 -9.07979310e-02
  -2.02189848e-01 -5.25277779e-02 -8.66898708e-03  2.05893070e-02
   4.90600139e-01  6.06440365e-01  0.00000000e+00  1.12954783e+00
  -6.02932751e-01 -8.20460320e-01  9.19193208e-01  4.20251340e-01
   8.86628091e-01 -2.75183231e-01]
 [-1.57804951e-01 -1.93809271e-01  1.02898479e+00  5.11063516e-01
  -4.74434912e-01  2.46352538e-01 -3.26581858e-02  2.19091047e-02
  -3.61383110e-01 -2.80940890e-01  2.24536002e-01  2.13068664e-01
   1.31324127e-01 -2.47522011e-01  4.55174714e-01  1.64270028e-01
  -6.01137936e-01 -1.98013321e-01  5.68196833e-01 -9.80517045e-02
   5.79907000e-01  2.03512713e-01  0.00000000e+00  1.72171152e+00
  -1.13869071e+00 -7.55480170e-01  1.37175190e+00  4.62557495e-01
   3.56213003e-01  8.13888013e-02]
 [ 3.16732258e-01 -3.83855790e-01 -2.83055514e-01 -8.54100138e-02
  -8.36213470e-01 -3.24855500e-05 -5.43858707e-01 -3.17064337e-02
   2.92859286e-01  6.18303455e-02  1.13387287e-01 -5.27197599e-01
   1.20162135e-02  1.04343399e-01  1.60209881e-03 -1.20201401e-01
  -1.32553935e-01 -1.94758043e-01 -9.62805599e-02  1.80751622e-01
  -5.85892260e-01  8.27701092e-02  0.00000000e+00  1.10702157e+00
   1.44331706e+00 -6.15364373e-01 -2.54080117e-01 -1.94513902e-01
  -2.08073854e-01  3.01686436e-01]
 [-2.10854590e-01 -1.13472509e+00 -6.40003264e-01  9.86311018e-01
  -1.77692130e-01  1.85218954e+00  1.16771090e+00  5.19027948e-01
   1.15492314e-01 -1.16215954e-02 -2.09119260e-01  2.80016333e-01
   2.61475742e-01  1.74286991e-01 -5.67484498e-02  4.31424044e-02
  -1.06386654e-01  1.56662479e-01  3.39574963e-02 -1.09141037e-01
  -2.82227755e-01  3.71830463e-01  0.00000000e+00  3.20794845e+00
  -9.31086004e-01  5.39278507e-01  1.31869018e+00  1.42928123e-01
   2.35664576e-01  9.87854600e-03]
 [ 2.94792444e-01 -1.80234104e-01 -9.45258617e-01  2.03779548e-01
  -6.66597068e-01  1.74163684e-01  1.10995613e-01  1.08779259e-01
   3.33873034e-01 -9.22608078e-02 -7.08168373e-02  1.27328411e-01
  -1.40865281e-01 -1.02967255e-01 -2.88913757e-01  6.63279032e-04
   1.58132054e-02  5.90206757e-02  3.21817487e-01  7.41249979e-01
  -3.47356707e-01 -1.87513351e-01  0.00000000e+00  9.76143718e-01
  -1.29114628e-01  1.54409319e-01  3.15160900e-01  6.49110079e-02
  -3.51823449e-01 -2.48855781e-02]
 [-6.67452812e-01  1.38474035e+00  1.23455632e+00  1.57202899e-01
   1.74883246e+00 -1.12067032e+00 -3.42481822e-01 -6.54553950e-01
   2.28824422e-01  2.04294652e-01 -2.82363802e-01 -1.77971661e-01
  -1.90061420e-01  2.97669530e-01  1.29798293e-01 -4.43857424e-02
  -2.41367429e-01 -1.63145617e-01  3.06502432e-01  7.59017050e-01
  -5.49215198e-01 -1.27685010e-01  0.00000000e+00  2.15665147e-01
  -2.57387638e-01 -1.88609853e-01  8.28576684e-01 -9.23836082e-02
  -1.19693860e-01  2.75722705e-02]
 [-1.91825181e-01  6.77523971e-01  2.65178353e-01  2.92960018e-01
  -2.35643253e-01 -6.79048002e-01 -1.76491201e-01  6.46104753e-01
   2.23806471e-01  4.42119777e-01  5.15198886e-01 -1.87782750e-01
   1.57752335e-01  5.35469174e-01 -3.02843511e-01  5.37263930e-01
   1.00268054e+00  4.78971273e-01 -1.33380008e+00  7.68559892e-03
   7.85466373e-01  5.74971676e-01  0.00000000e+00 -1.15605092e+00
   1.65677595e+00 -6.74811482e-01 -1.24662042e+00  9.36235264e-02
  -1.09827057e-01 -5.81094287e-02]
 [ 1.26931453e+00 -2.55051374e+00  3.78774822e-01 -1.52502751e+00
  -6.97381854e-01  2.20281386e+00  4.09762681e-01 -6.22534633e-01
   2.35857949e-01  2.10892960e-01  1.35469204e-02 -3.34103554e-01
  -3.63902479e-01  4.85194206e-01  3.56837332e-01  9.61749069e-03
   2.97771871e-01  3.09208054e-02 -1.51415676e-01  4.73012388e-01
  -3.89781624e-01 -6.72709405e-01  0.00000000e+00 -4.02161455e+00
  -2.63929844e-01  1.64883113e+00 -3.21849823e+00  1.73949301e-01
  -2.37902328e-01 -6.70736432e-02]
 [ 1.42058802e+00 -9.67213660e-02 -1.43865502e+00 -2.06736422e+00
   1.15796041e+00 -5.36676824e-01 -1.38192952e+00  4.28931415e-03
  -2.27251157e-01 -1.20658733e-01  4.47364688e-01  1.30644575e-01
   5.14725804e-01 -1.21475019e-01  1.59848899e-01  6.33786097e-02
  -1.04220949e-01 -1.03829883e-01 -3.69792014e-01  9.76711139e-02
   5.41807353e-01  7.36005485e-01  0.00000000e+00 -2.13091940e-01
   2.50085324e-01  2.77412653e-01  1.51447356e-01  1.39519989e-01
   6.64825439e-02 -9.07462928e-03]
 [-1.93710625e-01  2.78077602e-01 -7.08065182e-03  2.40872368e-01
   4.87094373e-03 -2.29145318e-01 -3.47872488e-02  6.96308911e-02
   8.58664066e-02 -8.03382322e-02 -3.44852746e-01  1.29713044e-01
   3.80947627e-02  5.05493768e-02 -1.39468256e-02  4.22564335e-02
  -4.63147201e-02  1.37966676e-02 -6.72237426e-02  1.61423415e-01
  -3.81300002e-02  1.06794991e-01  1.00000000e+00  6.48825109e-01
   6.71667278e-01  2.04836994e-01  1.23191617e-01 -2.39544455e-03
  -7.68288732e-01  8.79165530e-02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.72442630e-01
  -2.35118885e-02  1.23098075e-01 -1.12233780e-01  1.02342024e-01
   6.32936135e-02 -2.97929868e-02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  3.17164898e-01
  -1.78293020e-01 -5.91724925e-02  3.67524773e-01  8.25831890e-02
   4.07653973e-02 -1.94820445e-02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  3.76921743e-02
   2.11989552e-01  9.07771364e-02 -1.97821096e-01 -1.06007591e-01
  -1.60198510e-01  6.74285367e-02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.60803318e-01
  -1.67703867e-01  1.33877844e-01  9.17732269e-02 -2.51443963e-02
  -1.27833098e-01  1.21234600e-02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  8.39816630e-01
  -2.80644566e-01 -7.97527432e-01  1.21402466e+00  6.11618042e-01
   6.53835416e-01 -4.12244760e-02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  1.24535525e+00
  -1.37497580e+00  6.63225472e-01  1.42801297e+00  1.21220559e-01
   5.58743477e-01 -6.02425002e-02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.48145869e-01
   8.02733153e-02  4.60870087e-01 -3.36657643e-01  5.34102976e-01
   1.31150588e-01  4.96095717e-01]]
Eigen values: 
[1.         0.95182735 0.95182735 0.7681029  0.7681029  0.99890142
 0.99890142 0.69286066 0.69286066 0.82287222 0.82287222 0.36575727
 0.36575727 0.89994308 0.22303001 0.22303001 0.05050051 0.05050051
 0.30547913 0.60893377 0.60893377 0.64531761 0.56347962 0.69439402
 0.69439402 0.27980154 0.23574879 0.61411754 0.18216549 0.18216549]
[COMP] The identified Koopman operator is STABLE
------ ------ -----
----- Run Info ----
------ ------ -----
                                  0           1           2
x_hidden_variable_list            6           6           3
activation flag                   2           2           2
activation function             elu         elu         elu
no of epochs                   1000        1000        1000
batch size                      400         400         400
step size                       0.5         0.5         0.5
training error           0.00204719  0.00204719  0.00204719
validation error         0.00227858  0.00227858  0.00227858
r^2 training accuracy       95.4004     95.4004     95.4004
r^2 validation accuracy     94.9362     94.9362     94.9362
MSE training             0.00204719  0.00204719  0.00204719
MSE validation           0.00227858  0.00227858  0.00227858
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
                                  0           1           2
x_hidden_variable_list            6           6           3
activation flag                   2           2           2
activation function             elu         elu         elu
no of epochs                  10000       10000       10000
batch size                      400         400         400
step size                       0.3         0.3         0.3
training error           0.00114361  0.00114361  0.00114361
validation error         0.00134302  0.00134302  0.00134302
r^2 training accuracy       97.4083     97.4083     97.4083
r^2 validation accuracy     96.9285     96.9285     96.9285
MSE training             0.00114361  0.00114361  0.00114361
MSE validation           0.00134302  0.00134302  0.00134302
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
                                  0           1           2
x_hidden_variable_list            6           6           3
activation flag                   2           2           2
activation function             elu         elu         elu
no of epochs                  10000       10000       10000
batch size                      400         400         400
step size                       0.1         0.1         0.1
training error           0.00108437  0.00108437  0.00108437
validation error         0.00128685  0.00128685  0.00128685
r^2 training accuracy       97.5053     97.5053     97.5053
r^2 validation accuracy     97.0137     97.0137     97.0137
MSE training             0.00108437  0.00108437  0.00108437
MSE validation           0.00128685  0.00128685  0.00128685
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
                                  0           1           2
x_hidden_variable_list            6           6           3
activation flag                   2           2           2
activation function             elu         elu         elu
no of epochs                  10000       10000       10000
batch size                      400         400         400
step size                      0.09        0.09        0.09
training error           0.00104763  0.00104763  0.00104763
validation error         0.00124648  0.00124648  0.00124648
r^2 training accuracy       97.5782     97.5782     97.5782
r^2 validation accuracy      97.083      97.083      97.083
MSE training             0.00104763  0.00104763  0.00104763
MSE validation           0.00124648  0.00124648  0.00124648
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
                                  0           1           2
x_hidden_variable_list            6           6           3
activation flag                   2           2           2
activation function             elu         elu         elu
no of epochs                  10000       10000       10000
batch size                      400         400         400
step size                      0.08        0.08        0.08
training error           0.00101321  0.00101321  0.00101321
validation error         0.00121524  0.00121524  0.00121524
r^2 training accuracy       97.6586     97.6586     97.6586
r^2 validation accuracy     97.1468     97.1468     97.1468
MSE training             0.00101321  0.00101321  0.00101321
MSE validation           0.00121524  0.00121524  0.00121524
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
