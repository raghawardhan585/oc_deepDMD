[INFO] Number of total samples: 4600
[INFO] Observable dimension of a sample: 7
[INFO] Xp.shape (E-DMD): (4600, 7)
[INFO] Yf.shape (E-DMD): (4600, 7)
Number of training snapshots: 2300
Number of validation snapshots: 2300
70
0.39735970711951313
0.3535533905932738
0.4472135954999579
0.2847473987257497
1.6637015
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.5
Train Error Threshold      :  1e-06
Validation Error Threshold :  1e-06
Maximum number of Epochs   :  1000
Batch Size   :  400
--------------------------------------
Epoch No:  1000  |   Training error:  0.0019125489
                   Validation error:  0.002149737
---------------------------------------------------------------------------------------------------
Current Training Error  : 0.0019125489
Current Validation Error      : 0.002149737
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.3
Train Error Threshold      :  1e-06
Validation Error Threshold :  1e-06
Maximum number of Epochs   :  10000
Batch Size   :  400
--------------------------------------
Epoch No:  1000  |   Training error:  0.0015351259
                   Validation error:  0.0017631057
---------------------------------------------------------------------------------------------------
Epoch No:  2000  |   Training error:  0.0013532506
                   Validation error:  0.0015711056
---------------------------------------------------------------------------------------------------
Epoch No:  3000  |   Training error:  0.0014213963
                   Validation error:  0.0016323591
---------------------------------------------------------------------------------------------------
Epoch No:  4000  |   Training error:  0.0011893992
                   Validation error:  0.0013791773
---------------------------------------------------------------------------------------------------
Epoch No:  5000  |   Training error:  0.0011066971
                   Validation error:  0.0012957379
---------------------------------------------------------------------------------------------------
Epoch No:  6000  |   Training error:  0.001065508
                   Validation error:  0.0012491447
---------------------------------------------------------------------------------------------------
Epoch No:  7000  |   Training error:  0.0010480139
                   Validation error:  0.0012233693
---------------------------------------------------------------------------------------------------
Epoch No:  8000  |   Training error:  0.0010130618
                   Validation error:  0.0011904466
---------------------------------------------------------------------------------------------------
Epoch No:  9000  |   Training error:  0.0009977905
                   Validation error:  0.001169574
---------------------------------------------------------------------------------------------------
Epoch No:  10000  |   Training error:  0.00095882005
                    Validation error:  0.0011299136
---------------------------------------------------------------------------------------------------
Current Training Error  : 0.00095882005
Current Validation Error      : 0.0011299136
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.1
Train Error Threshold      :  1e-07
Validation Error Threshold :  1e-07
Maximum number of Epochs   :  10000
Batch Size   :  400
--------------------------------------
Epoch No:  1000  |   Training error:  0.000941551
                   Validation error:  0.0011096265
---------------------------------------------------------------------------------------------------
Epoch No:  2000  |   Training error:  0.0009320155
                   Validation error:  0.0010990875
---------------------------------------------------------------------------------------------------
Epoch No:  3000  |   Training error:  0.00092638464
                   Validation error:  0.0010929666
---------------------------------------------------------------------------------------------------
Epoch No:  4000  |   Training error:  0.0009157694
                   Validation error:  0.0010821396
---------------------------------------------------------------------------------------------------
Epoch No:  5000  |   Training error:  0.0009149626
                   Validation error:  0.0010813129
---------------------------------------------------------------------------------------------------
Epoch No:  6000  |   Training error:  0.00090170756
                   Validation error:  0.0010669997
---------------------------------------------------------------------------------------------------
Epoch No:  7000  |   Training error:  0.0008928223
                   Validation error:  0.0010580368
---------------------------------------------------------------------------------------------------
Epoch No:  8000  |   Training error:  0.0008862887
                   Validation error:  0.001050581
---------------------------------------------------------------------------------------------------
Epoch No:  9000  |   Training error:  0.0008849233
                   Validation error:  0.0010507515
---------------------------------------------------------------------------------------------------
Epoch No:  10000  |   Training error:  0.0008775661
                    Validation error:  0.0010405994
---------------------------------------------------------------------------------------------------
Current Training Error  : 0.0008775661
Current Validation Error      : 0.0010405994
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.09
Train Error Threshold      :  1e-08
Validation Error Threshold :  1e-08
Maximum number of Epochs   :  10000
Batch Size   :  400
--------------------------------------
Epoch No:  1000  |   Training error:  0.0008650395
                   Validation error:  0.001028263
---------------------------------------------------------------------------------------------------
Epoch No:  2000  |   Training error:  0.0008597341
                   Validation error:  0.0010230193
---------------------------------------------------------------------------------------------------
Epoch No:  3000  |   Training error:  0.0008508007
                   Validation error:  0.0010141598
---------------------------------------------------------------------------------------------------
Epoch No:  4000  |   Training error:  0.00085201237
                   Validation error:  0.0010132858
---------------------------------------------------------------------------------------------------
Epoch No:  5000  |   Training error:  0.0008386752
                   Validation error:  0.0010007182
---------------------------------------------------------------------------------------------------
Epoch No:  6000  |   Training error:  0.00083235506
                   Validation error:  0.0009944484
---------------------------------------------------------------------------------------------------
Epoch No:  7000  |   Training error:  0.00082978996
                   Validation error:  0.0009917523
---------------------------------------------------------------------------------------------------
Epoch No:  8000  |   Training error:  0.0008218375
                   Validation error:  0.0009823095
---------------------------------------------------------------------------------------------------
Epoch No:  9000  |   Training error:  0.0008140341
                   Validation error:  0.0009740331
---------------------------------------------------------------------------------------------------
Epoch No:  10000  |   Training error:  0.0008110694
                    Validation error:  0.0009709351
---------------------------------------------------------------------------------------------------
Current Training Error  : 0.0008110694
Current Validation Error      : 0.0009709351
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.08
Train Error Threshold      :  1e-08
Validation Error Threshold :  1e-08
Maximum number of Epochs   :  10000
Batch Size   :  400
--------------------------------------
Epoch No:  1000  |   Training error:  0.00080282293
                   Validation error:  0.00096224755
---------------------------------------------------------------------------------------------------
Epoch No:  2000  |   Training error:  0.0007996683
                   Validation error:  0.00095882703
---------------------------------------------------------------------------------------------------
Epoch No:  3000  |   Training error:  0.0007920009
                   Validation error:  0.0009498452
---------------------------------------------------------------------------------------------------
Epoch No:  4000  |   Training error:  0.0007865838
                   Validation error:  0.0009443449
---------------------------------------------------------------------------------------------------
Epoch No:  5000  |   Training error:  0.0007865895
                   Validation error:  0.00094320567
---------------------------------------------------------------------------------------------------
Epoch No:  6000  |   Training error:  0.0007769899
                   Validation error:  0.0009339123
---------------------------------------------------------------------------------------------------
Epoch No:  7000  |   Training error:  0.0007775952
                   Validation error:  0.00093197986
---------------------------------------------------------------------------------------------------
Epoch No:  8000  |   Training error:  0.0007657356
                   Validation error:  0.0009204797
---------------------------------------------------------------------------------------------------
Epoch No:  9000  |   Training error:  0.00075873063
                   Validation error:  0.00091196987
---------------------------------------------------------------------------------------------------
Epoch No:  10000  |   Training error:  0.0007540259
                    Validation error:  0.00090764917
---------------------------------------------------------------------------------------------------
Current Training Error  : 0.0007540259
Current Validation Error      : 0.00090764917
0.0007540259
---   OUTPUT COMPENSATED STATE TRAINING COMPLETE   ---
                                   0            1  ...            3            4
MSE training              0.00191255   0.00095882  ...  0.000811069  0.000754026
MSE validation            0.00214974   0.00112991  ...  0.000970935  0.000907649
activation flag                    2            2  ...            2            2
activation function              elu          elu  ...          elu          elu
batch size                       400          400  ...          400          400
no of epochs                    1000        10000  ...        10000        10000
r^2 training accuracy        95.9901      98.0813  ...      98.4766      98.6278
r^2 validation accuracy      95.5579      97.7247  ...      98.1191        98.28
step size                        0.5          0.3  ...         0.09         0.08
training error            0.00191255   0.00095882  ...  0.000811069  0.000754026
validation error          0.00214974   0.00112991  ...  0.000970935  0.000907649
x_hidden_variable_list   [12, 12, 3]  [12, 12, 3]  ...  [12, 12, 3]  [12, 12, 3]

[12 rows x 5 columns]
[[ 4.72021610e-01  3.38556647e-01  4.18689936e-01  5.00197947e-01
  -8.31248388e-02 -1.01515174e-01  3.24863672e-01 -1.07199080e-01
  -5.25555760e-02 -8.89151245e-02  1.40477065e-02 -4.08105925e-02
  -5.05048744e-02 -4.77822088e-02  3.71716097e-02 -4.54329997e-02
   1.43755116e-02 -4.80397791e-02  3.32842022e-02  6.11363053e-02
  -2.87101828e-02  1.82384923e-02  0.00000000e+00 -7.46918246e-02
   1.07431754e-01 -1.57148838e-01 -9.85258147e-02  3.14604789e-02
   6.84090853e-02  2.65282113e-02]
 [ 8.48779082e-01 -7.17963576e-01  4.39066291e-01 -4.07984763e-01
  -6.20698750e-01  1.23670173e+00  9.55862701e-02 -1.52714169e-02
  -2.87818648e-02 -6.84470981e-02  6.31697848e-02 -5.33242058e-03
   1.75399706e-02 -3.29068955e-03 -1.02510201e-02 -3.64312492e-02
  -8.67458135e-02  1.23510864e-02 -3.33768316e-02  6.75345659e-02
   1.99070331e-02  1.52588412e-01  0.00000000e+00 -8.12028535e-03
   1.92817017e-01  1.00640498e-01 -3.71387362e-01  1.46391122e-02
  -5.77177107e-02 -7.44304731e-02]
 [-1.94961563e-01  1.55483186e-01  2.25668952e-01  4.12493140e-01
  -2.89172649e-01  5.04668131e-02  2.09587902e-01 -3.79245579e-02
   2.90083885e-02  1.40719330e-02 -9.05176252e-02 -1.37555199e-02
  -5.71453385e-02 -4.55610454e-03  6.52652234e-03 -2.30827183e-02
  -5.50810695e-02 -1.13127036e-02  7.05968589e-02 -5.37536992e-03
  -4.00860906e-02 -9.74392071e-02  0.00000000e+00  3.99953067e-01
  -1.48389578e-01 -1.92993969e-01  2.80494064e-01  1.06487703e-02
   3.03828530e-02 -7.41987228e-02]
 [ 1.42681122e-01  1.38099000e-01  8.26231465e-02 -2.26357430e-01
   2.51242518e-01 -2.18633577e-01 -5.43674342e-02 -1.85664743e-02
  -1.33187901e-02 -3.13937361e-03  4.41333950e-02 -3.78221180e-03
   1.29165230e-02 -2.42586769e-02  1.08600771e-02 -1.62226576e-02
   2.82936487e-02 -1.33429570e-02 -2.53299829e-02 -1.63266603e-02
   3.21783088e-02  4.04494070e-02  0.00000000e+00 -5.07042855e-02
   2.12723210e-01 -4.75233188e-03 -1.05165243e-01 -9.16658156e-03
  -2.77324934e-02 -5.56448614e-03]
 [-3.32499057e-01  2.28532419e-01  1.91549256e-01  2.63558447e-01
   1.80633068e-01 -9.07276496e-02  1.71841830e-01  1.72209516e-02
   1.33938745e-01  1.57564908e-01 -9.09818411e-02 -5.18622436e-02
  -6.73819110e-02  1.42334700e-01 -1.94332581e-02  4.73408625e-02
   1.58480048e-01  7.75364563e-02 -1.39649525e-01  3.54051404e-02
  -9.51924697e-02 -1.61421329e-01  0.00000000e+00 -5.94000936e-01
   1.97728306e-01  5.74226417e-02 -3.68397534e-01 -5.75833917e-02
   6.06912971e-02  1.43775374e-01]
 [ 7.42916584e-01 -5.83198488e-01  2.36311868e-01 -8.48347068e-01
  -2.93863863e-01  9.25468326e-01 -5.09513199e-01  4.33954410e-02
   7.95441493e-02  7.11459294e-02  1.27575779e-02 -1.26514174e-02
   2.74136700e-02  7.45158195e-02 -3.37066762e-02 -1.36511875e-02
  -2.17071385e-03  8.58126134e-02 -1.21233612e-01  3.20427865e-02
  -7.66631439e-02  3.27694453e-02  0.00000000e+00 -2.93314070e-01
   1.31313100e-01  8.03700536e-02 -2.15062723e-01 -9.88025442e-02
   5.42738661e-03 -1.45176193e-02]
 [-3.14152181e-01  2.81061769e-01  2.43116930e-01  4.22723740e-01
  -1.06773570e-01 -1.62992939e-01  7.70393848e-01 -6.45077005e-02
   8.77915416e-03 -3.01323342e-03 -2.41301488e-02 -4.00016233e-02
  -2.90398877e-02 -9.98169184e-04  7.67876767e-03 -2.29442846e-02
  -2.15396704e-03 -2.02907324e-02  8.61994922e-03  6.58323690e-02
  -1.75015200e-02 -4.62848842e-02  0.00000000e+00 -3.02818511e-02
   9.26657990e-02  7.08582178e-02 -4.47889119e-02  8.83341283e-02
  -1.18165892e-02  3.26416008e-02]
 [ 9.10587192e-01  8.89168978e-02 -1.71380925e+00 -5.12568235e-01
   6.78518340e-02 -4.41929698e-01 -9.30596709e-01 -3.02964635e-02
   2.90434062e-01  4.97242093e-01 -7.20400035e-01  1.38922380e-02
  -4.89886791e-01  3.62063706e-01  2.42087558e-01  2.55168200e-01
   1.15831215e-02  9.02870148e-02  2.27217302e-01 -1.47329539e-01
  -4.58247691e-01 -7.96424508e-01  0.00000000e+00 -1.93161476e+00
   7.14042246e-01 -1.67933226e-01 -1.73818231e+00  1.38831154e-01
  -5.62373586e-02 -7.71982893e-02]
 [-6.24968290e-01  4.42626774e-01 -8.98404777e-01  5.56450903e-01
  -3.71360987e-01 -1.03725262e-01  4.02868062e-01 -2.66276747e-02
   3.57256889e-01  4.79882210e-01 -3.32526028e-01  1.75967604e-01
   1.85024559e-01  3.92382108e-02  1.07147612e-01  1.17679276e-01
  -1.73717827e-01  2.49621570e-01 -2.61997014e-01 -1.49054468e-01
   6.07348204e-01 -3.42899024e-01  0.00000000e+00 -1.53996444e+00
   2.13929683e-01  5.62886417e-01 -7.65730202e-01 -1.42705247e-01
   2.51404047e-01 -8.58714059e-02]
 [-1.77198768e-01 -2.86528707e-01 -8.13382789e-02  9.92919579e-02
  -1.29084074e+00  6.70777142e-01  5.77111483e-01 -8.88769776e-02
   1.41930491e-01  6.32992536e-02  9.32350382e-02 -1.15862206e-01
   4.02539283e-01  2.36165002e-01  3.53870749e-01  1.02935284e-02
  -1.75657466e-01 -9.69285741e-02 -1.60486192e-01  6.58358753e-01
  -3.83784086e-01 -2.24543065e-01  0.00000000e+00  2.45406985e-01
   2.19079509e-01 -6.55432165e-01 -1.23493314e-01  2.22438902e-01
  -2.60050476e-01 -1.41501665e-01]
 [ 8.92740369e-01 -1.21604311e+00  4.66681808e-01  1.79148111e-02
   2.45707184e-02  8.30945373e-01 -4.89901006e-01  7.99527228e-01
   3.76926437e-02  7.68536404e-02 -2.08924741e-01  5.48284352e-01
   1.06011964e-01 -1.98116675e-01 -7.38254607e-01  3.28864068e-01
  -3.76861811e-01  2.27851868e-01  2.88977265e-01 -1.92369729e-01
   2.59052873e-01  8.39488745e-01  0.00000000e+00  1.78102171e+00
   9.05329764e-01 -4.54333633e-01  1.18703321e-01  7.46895075e-01
  -7.25393534e-01  6.34675249e-02]
 [ 4.15755570e-01 -4.74210158e-02  1.38449565e-01  1.00829892e-01
   2.10326925e-01 -3.65294427e-01 -4.57485437e-01 -2.35200942e-01
   4.38201010e-01 -2.05884203e-01 -3.99543583e-01 -2.17268392e-02
   2.25557879e-01  3.87856886e-02 -2.18918407e-03 -3.40303332e-01
  -1.95349216e-01 -1.24205470e-01  1.33700356e-01  4.44391727e-01
  -7.81964242e-01 -7.58748293e-01  0.00000000e+00 -2.13025406e-01
   1.65376484e-01 -6.31777763e-01 -3.69366467e-01  1.36011600e-01
  -5.65077543e-01  3.70584846e-01]
 [ 6.41154051e-01  3.37557793e-01  2.83643931e-01 -1.35616457e+00
  -4.68263775e-01 -8.47803891e-01 -1.18001986e+00  3.76001120e-01
   3.91849801e-02  9.83202681e-02 -2.31172025e-01  1.15914106e-01
   2.60332048e-01  8.63628238e-02  2.35143956e-02 -1.70469269e-01
   1.18656598e-01  4.71216738e-01  1.21947691e-01 -8.08251441e-01
   9.03922096e-02  1.38807938e-01  0.00000000e+00  1.37834084e+00
   6.32730722e-01 -1.29325104e+00  1.16206443e+00 -4.43828017e-01
   4.01026100e-01 -2.67072916e-01]
 [ 3.60034108e-02  7.67257344e-03 -6.98638380e-01  4.85708445e-01
  -1.29481101e+00  5.53385504e-02 -7.56273866e-02 -6.09043241e-01
  -3.51963460e-01 -1.95649624e-01 -3.39335240e-02 -2.34038636e-01
  -5.28396443e-02  2.19291836e-01 -6.03780933e-02 -9.07979310e-02
  -2.02189848e-01 -5.25277779e-02 -8.66898708e-03  2.05893070e-02
   4.90600139e-01  6.06440365e-01  0.00000000e+00  7.63245761e-01
  -2.29005113e-01 -5.14670134e-01  7.50136077e-01 -4.77893233e-01
   4.14978862e-01 -2.23837957e-01]
 [-1.57804951e-01 -1.93809271e-01  1.02898479e+00  5.11063516e-01
  -4.74434912e-01  2.46352538e-01 -3.26581858e-02  2.19091047e-02
  -3.61383110e-01 -2.80940890e-01  2.24536002e-01  2.13068664e-01
   1.31324127e-01 -2.47522011e-01  4.55174714e-01  1.64270028e-01
  -6.01137936e-01 -1.98013321e-01  5.68196833e-01 -9.80517045e-02
   5.79907000e-01  2.03512713e-01  0.00000000e+00  1.48087502e+00
  -1.18680775e+00 -6.58904254e-01  9.36367989e-01  3.40393513e-01
   8.05552304e-02 -3.80210310e-01]
 [ 3.16732258e-01 -3.83855790e-01 -2.83055514e-01 -8.54100138e-02
  -8.36213470e-01 -3.24855500e-05 -5.43858707e-01 -3.17064337e-02
   2.92859286e-01  6.18303455e-02  1.13387287e-01 -5.27197599e-01
   1.20162135e-02  1.04343399e-01  1.60209881e-03 -1.20201401e-01
  -1.32553935e-01 -1.94758043e-01 -9.62805599e-02  1.80751622e-01
  -5.85892260e-01  8.27701092e-02  0.00000000e+00  6.50893092e-01
   1.34045494e+00 -7.28261650e-01 -7.21897304e-01 -1.06475033e-01
   2.44561747e-01 -2.20158607e-01]
 [-2.10854590e-01 -1.13472509e+00 -6.40003264e-01  9.86311018e-01
  -1.77692130e-01  1.85218954e+00  1.16771090e+00  5.19027948e-01
   1.15492314e-01 -1.16215954e-02 -2.09119260e-01  2.80016333e-01
   2.61475742e-01  1.74286991e-01 -5.67484498e-02  4.31424044e-02
  -1.06386654e-01  1.56662479e-01  3.39574963e-02 -1.09141037e-01
  -2.82227755e-01  3.71830463e-01  0.00000000e+00  1.82322466e+00
  -5.52596807e-01  5.24320185e-01  4.43821281e-01  1.80393875e-01
  -2.65822679e-01 -3.23761068e-02]
 [ 2.94792444e-01 -1.80234104e-01 -9.45258617e-01  2.03779548e-01
  -6.66597068e-01  1.74163684e-01  1.10995613e-01  1.08779259e-01
   3.33873034e-01 -9.22608078e-02 -7.08168373e-02  1.27328411e-01
  -1.40865281e-01 -1.02967255e-01 -2.88913757e-01  6.63279032e-04
   1.58132054e-02  5.90206757e-02  3.21817487e-01  7.41249979e-01
  -3.47356707e-01 -1.87513351e-01  0.00000000e+00  1.12754750e+00
  -1.48743942e-01  1.02349408e-02  5.15976608e-01  7.18461871e-02
  -3.98085117e-01  1.72628120e-01]
 [-6.67452812e-01  1.38474035e+00  1.23455632e+00  1.57202899e-01
   1.74883246e+00 -1.12067032e+00 -3.42481822e-01 -6.54553950e-01
   2.28824422e-01  2.04294652e-01 -2.82363802e-01 -1.77971661e-01
  -1.90061420e-01  2.97669530e-01  1.29798293e-01 -4.43857424e-02
  -2.41367429e-01 -1.63145617e-01  3.06502432e-01  7.59017050e-01
  -5.49215198e-01 -1.27685010e-01  0.00000000e+00  1.69377536e-01
   1.70821145e-01 -2.97135532e-01  4.09970164e-01  1.21392064e-01
  -5.73541403e-01  4.14770842e-02]
 [-1.91825181e-01  6.77523971e-01  2.65178353e-01  2.92960018e-01
  -2.35643253e-01 -6.79048002e-01 -1.76491201e-01  6.46104753e-01
   2.23806471e-01  4.42119777e-01  5.15198886e-01 -1.87782750e-01
   1.57752335e-01  5.35469174e-01 -3.02843511e-01  5.37263930e-01
   1.00268054e+00  4.78971273e-01 -1.33380008e+00  7.68559892e-03
   7.85466373e-01  5.74971676e-01  0.00000000e+00 -3.94513369e-01
   1.84186745e+00 -8.84968996e-01 -1.19528162e+00 -4.74006772e-01
   8.88470769e-01  3.87813985e-01]
 [ 1.26931453e+00 -2.55051374e+00  3.78774822e-01 -1.52502751e+00
  -6.97381854e-01  2.20281386e+00  4.09762681e-01 -6.22534633e-01
   2.35857949e-01  2.10892960e-01  1.35469204e-02 -3.34103554e-01
  -3.63902479e-01  4.85194206e-01  3.56837332e-01  9.61749069e-03
   2.97771871e-01  3.09208054e-02 -1.51415676e-01  4.73012388e-01
  -3.89781624e-01 -6.72709405e-01  0.00000000e+00 -3.85730290e+00
  -7.08636269e-02  1.65444934e+00 -3.24776721e+00 -1.36285037e-01
   5.05714081e-02  3.95666242e-01]
 [ 1.42058802e+00 -9.67213660e-02 -1.43865502e+00 -2.06736422e+00
   1.15796041e+00 -5.36676824e-01 -1.38192952e+00  4.28931415e-03
  -2.27251157e-01 -1.20658733e-01  4.47364688e-01  1.30644575e-01
   5.14725804e-01 -1.21475019e-01  1.59848899e-01  6.33786097e-02
  -1.04220949e-01 -1.03829883e-01 -3.69792014e-01  9.76711139e-02
   5.41807353e-01  7.36005485e-01  0.00000000e+00 -4.59456027e-01
   3.09845090e-01  3.54038090e-01 -9.90206599e-02 -1.11101776e-01
  -1.09064110e-01 -2.95385629e-01]
 [-1.93710625e-01  2.78077602e-01 -7.08065182e-03  2.40872368e-01
   4.87094373e-03 -2.29145318e-01 -3.47872488e-02  6.96308911e-02
   8.58664066e-02 -8.03382322e-02 -3.44852746e-01  1.29713044e-01
   3.80947627e-02  5.05493768e-02 -1.39468256e-02  4.22564335e-02
  -4.63147201e-02  1.37966676e-02 -6.72237426e-02  1.61423415e-01
  -3.81300002e-02  1.06794991e-01  1.00000000e+00  5.20616323e-02
   6.10655427e-01 -1.57441899e-01  2.75642425e-01  1.81107089e-01
  -3.47501546e-01  1.80519849e-01]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.54143745e-01
  -8.81606936e-02  1.54333308e-01 -7.31471479e-02 -7.89089352e-02
   1.44779891e-01  5.03405742e-03]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  1.07618637e-01
   6.82960153e-02 -6.88447580e-02 -4.00816416e-03  8.39496218e-03
  -4.77079302e-02  8.47373158e-02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  3.03086072e-01
   5.72880618e-02  5.44015430e-02  2.69710878e-03  8.89420435e-02
  -5.05398884e-02  4.14412171e-02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  6.76046014e-02
  -1.79971337e-01  5.21775819e-02  2.49087781e-01  6.41030073e-02
  -5.15941195e-02  9.58325267e-02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00 -6.51429236e-01
   7.00374544e-01  7.82967746e-01 -1.50843465e+00  5.21541119e-01
  -7.50556886e-01  3.60681176e-01]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  2.40758181e+00
  -6.37344480e-01  2.81465948e-01  1.13834488e+00  2.33213291e-01
   2.45706867e-02  7.06055388e-02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  5.05486071e-01
   1.17464435e+00 -6.28905714e-01 -5.23902833e-01 -1.54790729e-01
   2.10458532e-01  5.72097063e-01]]
Eigen values: 
[1.         0.95182735 0.95182735 0.7681029  0.7681029  0.99890142
 0.99890142 0.69286066 0.69286066 0.82287222 0.82287222 0.36575727
 0.36575727 0.89994308 0.22303001 0.22303001 0.05050051 0.05050051
 0.30547913 0.60893377 0.60893377 0.64531761 0.56347962 0.62914684
 0.70627899 0.70627899 0.73215486 0.27766786 0.16188221 0.00627899]
[COMP] The identified Koopman operator is STABLE
------ ------ -----
----- Run Info ----
------ ------ -----
                                  0           1           2
x_hidden_variable_list           12          12           3
activation flag                   2           2           2
activation function             elu         elu         elu
no of epochs                   1000        1000        1000
batch size                      400         400         400
step size                       0.5         0.5         0.5
training error           0.00191255  0.00191255  0.00191255
validation error         0.00214974  0.00214974  0.00214974
r^2 training accuracy       95.9901     95.9901     95.9901
r^2 validation accuracy     95.5579     95.5579     95.5579
MSE training             0.00191255  0.00191255  0.00191255
MSE validation           0.00214974  0.00214974  0.00214974
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
                                  0           1           2
x_hidden_variable_list           12          12           3
activation flag                   2           2           2
activation function             elu         elu         elu
no of epochs                  10000       10000       10000
batch size                      400         400         400
step size                       0.3         0.3         0.3
training error           0.00095882  0.00095882  0.00095882
validation error         0.00112991  0.00112991  0.00112991
r^2 training accuracy       98.0813     98.0813     98.0813
r^2 validation accuracy     97.7247     97.7247     97.7247
MSE training             0.00095882  0.00095882  0.00095882
MSE validation           0.00112991  0.00112991  0.00112991
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
                                   0            1            2
x_hidden_variable_list            12           12            3
activation flag                    2            2            2
activation function              elu          elu          elu
no of epochs                   10000        10000        10000
batch size                       400          400          400
step size                        0.1          0.1          0.1
training error           0.000877566  0.000877566  0.000877566
validation error           0.0010406    0.0010406    0.0010406
r^2 training accuracy         98.299       98.299       98.299
r^2 validation accuracy      97.9378      97.9378      97.9378
MSE training             0.000877566  0.000877566  0.000877566
MSE validation             0.0010406    0.0010406    0.0010406
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
                                   0            1            2
x_hidden_variable_list            12           12            3
activation flag                    2            2            2
activation function              elu          elu          elu
no of epochs                   10000        10000        10000
batch size                       400          400          400
step size                       0.09         0.09         0.09
training error           0.000811069  0.000811069  0.000811069
validation error         0.000970935  0.000970935  0.000970935
r^2 training accuracy        98.4766      98.4766      98.4766
r^2 validation accuracy      98.1191      98.1191      98.1191
MSE training             0.000811069  0.000811069  0.000811069
MSE validation           0.000970935  0.000970935  0.000970935
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
                                   0            1            2
x_hidden_variable_list            12           12            3
activation flag                    2            2            2
activation function              elu          elu          elu
no of epochs                   10000        10000        10000
batch size                       400          400          400
step size                       0.08         0.08         0.08
training error           0.000754026  0.000754026  0.000754026
validation error         0.000907649  0.000907649  0.000907649
r^2 training accuracy        98.6278      98.6278      98.6278
r^2 validation accuracy        98.28        98.28        98.28
MSE training             0.000754026  0.000754026  0.000754026
MSE validation           0.000907649  0.000907649  0.000907649
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
