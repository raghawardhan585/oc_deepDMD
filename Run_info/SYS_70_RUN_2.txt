[INFO] Number of total samples: 4600
[INFO] Observable dimension of a sample: 7
[INFO] Xp.shape (E-DMD): (4600, 7)
[INFO] Yf.shape (E-DMD): (4600, 7)
Number of training snapshots: 2300
Number of validation snapshots: 2300
70
0.4330127018922193
0.408248290463863
0.408248290463863
0.5
0.2847473987257497
0.86995643
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.5
Train Error Threshold      :  1e-06
Validation Error Threshold :  1e-06
Maximum number of Epochs   :  1000
Batch Size   :  400
--------------------------------------
Epoch No:  1000  |   Training error:  0.0018658625
                   Validation error:  0.0020628057
---------------------------------------------------------------------------------------------------
Current Training Error  : 0.0018658625
Current Validation Error      : 0.0020628057
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.3
Train Error Threshold      :  1e-06
Validation Error Threshold :  1e-06
Maximum number of Epochs   :  10000
Batch Size   :  400
--------------------------------------
Epoch No:  1000  |   Training error:  0.0014837291
                   Validation error:  0.0016773605
---------------------------------------------------------------------------------------------------
Epoch No:  2000  |   Training error:  0.0013677366
                   Validation error:  0.0015517274
---------------------------------------------------------------------------------------------------
Epoch No:  3000  |   Training error:  0.0012944681
                   Validation error:  0.0014738424
---------------------------------------------------------------------------------------------------
Epoch No:  4000  |   Training error:  0.0012223127
                   Validation error:  0.0014015209
---------------------------------------------------------------------------------------------------
Epoch No:  5000  |   Training error:  0.0014881198
                   Validation error:  0.0016936267
---------------------------------------------------------------------------------------------------
Epoch No:  6000  |   Training error:  0.0010711476
                   Validation error:  0.0012591049
---------------------------------------------------------------------------------------------------
Epoch No:  7000  |   Training error:  0.0010444692
                   Validation error:  0.0012349661
---------------------------------------------------------------------------------------------------
Epoch No:  8000  |   Training error:  0.0010103972
                   Validation error:  0.0012018296
---------------------------------------------------------------------------------------------------
Epoch No:  9000  |   Training error:  0.0010101554
                   Validation error:  0.0012075428
---------------------------------------------------------------------------------------------------
Epoch No:  10000  |   Training error:  0.0010519219
                    Validation error:  0.0012345053
---------------------------------------------------------------------------------------------------
Current Training Error  : 0.0010519219
Current Validation Error      : 0.0012345053
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.1
Train Error Threshold      :  1e-07
Validation Error Threshold :  1e-07
Maximum number of Epochs   :  10000
Batch Size   :  400
--------------------------------------
Epoch No:  1000  |   Training error:  0.00094200124
                   Validation error:  0.0011345823
---------------------------------------------------------------------------------------------------
Epoch No:  2000  |   Training error:  0.00093023997
                   Validation error:  0.0011203936
---------------------------------------------------------------------------------------------------
Epoch No:  3000  |   Training error:  0.00092107034
                   Validation error:  0.0011104369
---------------------------------------------------------------------------------------------------
Epoch No:  4000  |   Training error:  0.00091306213
                   Validation error:  0.0011014114
---------------------------------------------------------------------------------------------------
Epoch No:  5000  |   Training error:  0.0009059185
                   Validation error:  0.0010920878
---------------------------------------------------------------------------------------------------
Epoch No:  6000  |   Training error:  0.0008967243
                   Validation error:  0.0010832065
---------------------------------------------------------------------------------------------------
Epoch No:  7000  |   Training error:  0.0008914934
                   Validation error:  0.0010753452
---------------------------------------------------------------------------------------------------
Epoch No:  8000  |   Training error:  0.0008809203
                   Validation error:  0.0010660213
---------------------------------------------------------------------------------------------------
Epoch No:  9000  |   Training error:  0.000876108
                   Validation error:  0.0010599573
---------------------------------------------------------------------------------------------------
Epoch No:  10000  |   Training error:  0.0008671238
                    Validation error:  0.001049635
---------------------------------------------------------------------------------------------------
Current Training Error  : 0.0008671238
Current Validation Error      : 0.001049635
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.09
Train Error Threshold      :  1e-08
Validation Error Threshold :  1e-08
Maximum number of Epochs   :  10000
Batch Size   :  400
--------------------------------------
Epoch No:  1000  |   Training error:  0.0008592621
                   Validation error:  0.0010422715
---------------------------------------------------------------------------------------------------
Epoch No:  2000  |   Training error:  0.0008524094
                   Validation error:  0.001033764
---------------------------------------------------------------------------------------------------
Epoch No:  3000  |   Training error:  0.00084715587
                   Validation error:  0.0010276141
---------------------------------------------------------------------------------------------------
Epoch No:  4000  |   Training error:  0.0008431712
                   Validation error:  0.0010251052
---------------------------------------------------------------------------------------------------
Epoch No:  5000  |   Training error:  0.0008349612
                   Validation error:  0.0010160727
---------------------------------------------------------------------------------------------------
Epoch No:  6000  |   Training error:  0.0008326347
                   Validation error:  0.0010121671
---------------------------------------------------------------------------------------------------
Epoch No:  7000  |   Training error:  0.00082138
                   Validation error:  0.0010018436
---------------------------------------------------------------------------------------------------
Epoch No:  8000  |   Training error:  0.0008155009
                   Validation error:  0.0009954593
---------------------------------------------------------------------------------------------------
Epoch No:  9000  |   Training error:  0.0008099588
                   Validation error:  0.000989235
---------------------------------------------------------------------------------------------------
Epoch No:  10000  |   Training error:  0.00080515107
                    Validation error:  0.0009851179
---------------------------------------------------------------------------------------------------
Current Training Error  : 0.00080515107
Current Validation Error      : 0.0009851179
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.08
Train Error Threshold      :  1e-08
Validation Error Threshold :  1e-08
Maximum number of Epochs   :  10000
Batch Size   :  400
--------------------------------------
Epoch No:  1000  |   Training error:  0.00080011616
                   Validation error:  0.0009788661
---------------------------------------------------------------------------------------------------
Epoch No:  2000  |   Training error:  0.00079609925
                   Validation error:  0.00097529683
---------------------------------------------------------------------------------------------------
Epoch No:  3000  |   Training error:  0.0007908155
                   Validation error:  0.00096985267
---------------------------------------------------------------------------------------------------
Epoch No:  4000  |   Training error:  0.000786844
                   Validation error:  0.00096523185
---------------------------------------------------------------------------------------------------
Epoch No:  5000  |   Training error:  0.0007829815
                   Validation error:  0.00096257037
---------------------------------------------------------------------------------------------------
Epoch No:  6000  |   Training error:  0.0007776982
                   Validation error:  0.00095650397
---------------------------------------------------------------------------------------------------
Epoch No:  7000  |   Training error:  0.00077423954
                   Validation error:  0.0009524698
---------------------------------------------------------------------------------------------------
Epoch No:  8000  |   Training error:  0.00076944736
                   Validation error:  0.0009486092
---------------------------------------------------------------------------------------------------
Epoch No:  9000  |   Training error:  0.0007648111
                   Validation error:  0.00094367354
---------------------------------------------------------------------------------------------------
Epoch No:  10000  |   Training error:  0.00076044863
                    Validation error:  0.00093916827
---------------------------------------------------------------------------------------------------
Current Training Error  : 0.00076044863
Current Validation Error      : 0.00093916827
0.00076044863
---   OUTPUT COMPENSATED STATE TRAINING COMPLETE   ---
                                    0             1  ...             3             4
x_hidden_variable_list   [9, 9, 9, 3]  [9, 9, 9, 3]  ...  [9, 9, 9, 3]  [9, 9, 9, 3]
activation flag                     2             2  ...             2             2
activation function               elu           elu  ...           elu           elu
no of epochs                     1000         10000  ...         10000         10000
batch size                        400           400  ...           400           400
step size                         0.5           0.3  ...          0.09          0.08
training error             0.00186586    0.00105192  ...   0.000805151   0.000760449
validation error           0.00206281    0.00123451  ...   0.000985118   0.000939168
r^2 training accuracy         95.8775       97.7874  ...       98.4147       98.5648
r^2 validation accuracy       95.4472       97.3084  ...       97.9635        98.127
MSE training               0.00186586    0.00105192  ...   0.000805151   0.000760449
MSE validation             0.00206281    0.00123451  ...   0.000985118   0.000939168

[12 rows x 5 columns]
[[ 4.72021610e-01  3.38556647e-01  4.18689936e-01  5.00197947e-01
  -8.31248388e-02 -1.01515174e-01  3.24863672e-01 -1.07199080e-01
  -5.25555760e-02 -8.89151245e-02  1.40477065e-02 -4.08105925e-02
  -5.05048744e-02 -4.77822088e-02  3.71716097e-02 -4.54329997e-02
   1.43755116e-02 -4.80397791e-02  3.32842022e-02  6.11363053e-02
  -2.87101828e-02  1.82384923e-02  0.00000000e+00 -3.04775476e-01
   2.31318414e-01 -2.03151777e-01 -3.00314605e-01  1.56181352e-02
  -7.35835508e-02 -2.81460583e-02]
 [ 8.48779082e-01 -7.17963576e-01  4.39066291e-01 -4.07984763e-01
  -6.20698750e-01  1.23670173e+00  9.55862701e-02 -1.52714169e-02
  -2.87818648e-02 -6.84470981e-02  6.31697848e-02 -5.33242058e-03
   1.75399706e-02 -3.29068955e-03 -1.02510201e-02 -3.64312492e-02
  -8.67458135e-02  1.23510864e-02 -3.33768316e-02  6.75345659e-02
   1.99070331e-02  1.52588412e-01  0.00000000e+00  9.89265069e-02
   2.58809030e-01  1.81857832e-02 -4.10345554e-01  3.31554911e-03
  -3.05377059e-02 -4.98882346e-02]
 [-1.94961563e-01  1.55483186e-01  2.25668952e-01  4.12493140e-01
  -2.89172649e-01  5.04668131e-02  2.09587902e-01 -3.79245579e-02
   2.90083885e-02  1.40719330e-02 -9.05176252e-02 -1.37555199e-02
  -5.71453385e-02 -4.55610454e-03  6.52652234e-03 -2.30827183e-02
  -5.50810695e-02 -1.13127036e-02  7.05968589e-02 -5.37536992e-03
  -4.00860906e-02 -9.74392071e-02  0.00000000e+00  3.34795684e-01
   3.54884611e-03 -1.84549540e-01  1.30532727e-01  2.26044599e-02
  -2.05632616e-02  5.62775321e-03]
 [ 1.42681122e-01  1.38099000e-01  8.26231465e-02 -2.26357430e-01
   2.51242518e-01 -2.18633577e-01 -5.43674342e-02 -1.85664743e-02
  -1.33187901e-02 -3.13937361e-03  4.41333950e-02 -3.78221180e-03
   1.29165230e-02 -2.42586769e-02  1.08600771e-02 -1.62226576e-02
   2.82936487e-02 -1.33429570e-02 -2.53299829e-02 -1.63266603e-02
   3.21783088e-02  4.04494070e-02  0.00000000e+00  4.64547910e-02
   1.29346520e-01  1.80953350e-02  8.89415760e-03  7.20818993e-03
   2.60495171e-02  1.85943134e-02]
 [-3.32499057e-01  2.28532419e-01  1.91549256e-01  2.63558447e-01
   1.80633068e-01 -9.07276496e-02  1.71841830e-01  1.72209516e-02
   1.33938745e-01  1.57564908e-01 -9.09818411e-02 -5.18622436e-02
  -6.73819110e-02  1.42334700e-01 -1.94332581e-02  4.73408625e-02
   1.58480048e-01  7.75364563e-02 -1.39649525e-01  3.54051404e-02
  -9.51924697e-02 -1.61421329e-01  0.00000000e+00 -5.25269508e-01
   5.45774437e-02  9.46289450e-02 -2.60713339e-01 -7.28616770e-03
  -4.97332625e-02  5.15979491e-02]
 [ 7.42916584e-01 -5.83198488e-01  2.36311868e-01 -8.48347068e-01
  -2.93863863e-01  9.25468326e-01 -5.09513199e-01  4.33954410e-02
   7.95441493e-02  7.11459294e-02  1.27575779e-02 -1.26514174e-02
   2.74136700e-02  7.45158195e-02 -3.37066762e-02 -1.36511875e-02
  -2.17071385e-03  8.58126134e-02 -1.21233612e-01  3.20427865e-02
  -7.66631439e-02  3.27694453e-02  0.00000000e+00 -4.80706431e-02
  -3.25914398e-02  9.93628204e-02 -3.80430259e-02  4.74974327e-02
  -4.95600440e-02  1.24260291e-01]
 [-3.14152181e-01  2.81061769e-01  2.43116930e-01  4.22723740e-01
  -1.06773570e-01 -1.62992939e-01  7.70393848e-01 -6.45077005e-02
   8.77915416e-03 -3.01323342e-03 -2.41301488e-02 -4.00016233e-02
  -2.90398877e-02 -9.98169184e-04  7.67876767e-03 -2.29442846e-02
  -2.15396704e-03 -2.02907324e-02  8.61994922e-03  6.58323690e-02
  -1.75015200e-02 -4.62848842e-02  0.00000000e+00 -2.53693223e-01
   1.71726018e-01  4.40864675e-02 -2.16984570e-01  3.63767669e-02
   3.46616399e-03 -7.16334507e-02]
 [ 9.10587192e-01  8.89168978e-02 -1.71380925e+00 -5.12568235e-01
   6.78518340e-02 -4.41929698e-01 -9.30596709e-01 -3.02964635e-02
   2.90434062e-01  4.97242093e-01 -7.20400035e-01  1.38922380e-02
  -4.89886791e-01  3.62063706e-01  2.42087558e-01  2.55168200e-01
   1.15831215e-02  9.02870148e-02  2.27217302e-01 -1.47329539e-01
  -4.58247691e-01 -7.96424508e-01  0.00000000e+00 -1.94307184e+00
   5.13823450e-01  1.47762001e-01 -1.36093175e+00  2.78949700e-02
   4.22349796e-02  6.99489787e-02]
 [-6.24968290e-01  4.42626774e-01 -8.98404777e-01  5.56450903e-01
  -3.71360987e-01 -1.03725262e-01  4.02868062e-01 -2.66276747e-02
   3.57256889e-01  4.79882210e-01 -3.32526028e-01  1.75967604e-01
   1.85024559e-01  3.92382108e-02  1.07147612e-01  1.17679276e-01
  -1.73717827e-01  2.49621570e-01 -2.61997014e-01 -1.49054468e-01
   6.07348204e-01 -3.42899024e-01  0.00000000e+00 -1.43753135e+00
   3.77595156e-01  3.63863200e-01 -1.15765190e+00  1.80641696e-01
  -7.43380040e-02  6.27849996e-02]
 [-1.77198768e-01 -2.86528707e-01 -8.13382789e-02  9.92919579e-02
  -1.29084074e+00  6.70777142e-01  5.77111483e-01 -8.88769776e-02
   1.41930491e-01  6.32992536e-02  9.32350382e-02 -1.15862206e-01
   4.02539283e-01  2.36165002e-01  3.53870749e-01  1.02935284e-02
  -1.75657466e-01 -9.69285741e-02 -1.60486192e-01  6.58358753e-01
  -3.83784086e-01 -2.24543065e-01  0.00000000e+00  1.95247471e-01
   1.45248324e-01 -4.19191539e-01 -4.57033776e-02  2.29964480e-01
  -4.99774277e-01 -6.97417706e-02]
 [ 8.92740369e-01 -1.21604311e+00  4.66681808e-01  1.79148111e-02
   2.45707184e-02  8.30945373e-01 -4.89901006e-01  7.99527228e-01
   3.76926437e-02  7.68536404e-02 -2.08924741e-01  5.48284352e-01
   1.06011964e-01 -1.98116675e-01 -7.38254607e-01  3.28864068e-01
  -3.76861811e-01  2.27851868e-01  2.88977265e-01 -1.92369729e-01
   2.59052873e-01  8.39488745e-01  0.00000000e+00  1.96116257e+00
   8.84234965e-01 -4.60979432e-01 -5.23091853e-02 -5.33821108e-03
   6.47360146e-01 -6.16958201e-01]
 [ 4.15755570e-01 -4.74210158e-02  1.38449565e-01  1.00829892e-01
   2.10326925e-01 -3.65294427e-01 -4.57485437e-01 -2.35200942e-01
   4.38201010e-01 -2.05884203e-01 -3.99543583e-01 -2.17268392e-02
   2.25557879e-01  3.87856886e-02 -2.18918407e-03 -3.40303332e-01
  -1.95349216e-01 -1.24205470e-01  1.33700356e-01  4.44391727e-01
  -7.81964242e-01 -7.58748293e-01  0.00000000e+00  6.23747289e-01
   2.13990748e-01 -6.84080839e-01 -1.78089604e-01 -4.31973726e-01
   5.91221035e-01 -5.02374649e-01]
 [ 6.41154051e-01  3.37557793e-01  2.83643931e-01 -1.35616457e+00
  -4.68263775e-01 -8.47803891e-01 -1.18001986e+00  3.76001120e-01
   3.91849801e-02  9.83202681e-02 -2.31172025e-01  1.15914106e-01
   2.60332048e-01  8.63628238e-02  2.35143956e-02 -1.70469269e-01
   1.18656598e-01  4.71216738e-01  1.21947691e-01 -8.08251441e-01
   9.03922096e-02  1.38807938e-01  0.00000000e+00  1.38242161e+00
   7.85880566e-01 -1.47156453e+00  8.92388701e-01  3.12710583e-01
  -4.31812316e-01  6.10940695e-01]
 [ 3.60034108e-02  7.67257344e-03 -6.98638380e-01  4.85708445e-01
  -1.29481101e+00  5.53385504e-02 -7.56273866e-02 -6.09043241e-01
  -3.51963460e-01 -1.95649624e-01 -3.39335240e-02 -2.34038636e-01
  -5.28396443e-02  2.19291836e-01 -6.03780933e-02 -9.07979310e-02
  -2.02189848e-01 -5.25277779e-02 -8.66898708e-03  2.05893070e-02
   4.90600139e-01  6.06440365e-01  0.00000000e+00  4.36685085e-01
  -3.41838412e-02 -9.18390393e-01  3.21989954e-01 -5.03629595e-02
  -2.86851764e-01  3.64147425e-01]
 [-1.57804951e-01 -1.93809271e-01  1.02898479e+00  5.11063516e-01
  -4.74434912e-01  2.46352538e-01 -3.26581858e-02  2.19091047e-02
  -3.61383110e-01 -2.80940890e-01  2.24536002e-01  2.13068664e-01
   1.31324127e-01 -2.47522011e-01  4.55174714e-01  1.64270028e-01
  -6.01137936e-01 -1.98013321e-01  5.68196833e-01 -9.80517045e-02
   5.79907000e-01  2.03512713e-01  0.00000000e+00  1.35450017e+00
  -1.04554629e+00 -2.73918539e-01  1.00188470e+00  2.17016131e-01
  -1.83042228e-01  9.28657874e-02]
 [ 3.16732258e-01 -3.83855790e-01 -2.83055514e-01 -8.54100138e-02
  -8.36213470e-01 -3.24855500e-05 -5.43858707e-01 -3.17064337e-02
   2.92859286e-01  6.18303455e-02  1.13387287e-01 -5.27197599e-01
   1.20162135e-02  1.04343399e-01  1.60209881e-03 -1.20201401e-01
  -1.32553935e-01 -1.94758043e-01 -9.62805599e-02  1.80751622e-01
  -5.85892260e-01  8.27701092e-02  0.00000000e+00  7.78498292e-01
   1.65900791e+00 -6.35165751e-01 -1.05589366e+00  4.51157149e-03
  -3.39577161e-02 -1.66756481e-01]
 [-2.10854590e-01 -1.13472509e+00 -6.40003264e-01  9.86311018e-01
  -1.77692130e-01  1.85218954e+00  1.16771090e+00  5.19027948e-01
   1.15492314e-01 -1.16215954e-02 -2.09119260e-01  2.80016333e-01
   2.61475742e-01  1.74286991e-01 -5.67484498e-02  4.31424044e-02
  -1.06386654e-01  1.56662479e-01  3.39574963e-02 -1.09141037e-01
  -2.82227755e-01  3.71830463e-01  0.00000000e+00  2.27476072e+00
  -4.63625938e-01  5.26259601e-01  4.99750316e-01 -9.39726159e-02
   1.49000630e-01 -3.26544523e-01]
 [ 2.94792444e-01 -1.80234104e-01 -9.45258617e-01  2.03779548e-01
  -6.66597068e-01  1.74163684e-01  1.10995613e-01  1.08779259e-01
   3.33873034e-01 -9.22608078e-02 -7.08168373e-02  1.27328411e-01
  -1.40865281e-01 -1.02967255e-01 -2.88913757e-01  6.63279032e-04
   1.58132054e-02  5.90206757e-02  3.21817487e-01  7.41249979e-01
  -3.47356707e-01 -1.87513351e-01  0.00000000e+00  8.14581037e-01
   9.87713858e-02  9.63154137e-02 -6.55861897e-03 -1.58702239e-01
  -2.97431555e-02 -3.03881198e-01]
 [-6.67452812e-01  1.38474035e+00  1.23455632e+00  1.57202899e-01
   1.74883246e+00 -1.12067032e+00 -3.42481822e-01 -6.54553950e-01
   2.28824422e-01  2.04294652e-01 -2.82363802e-01 -1.77971661e-01
  -1.90061420e-01  2.97669530e-01  1.29798293e-01 -4.43857424e-02
  -2.41367429e-01 -1.63145617e-01  3.06502432e-01  7.59017050e-01
  -5.49215198e-01 -1.27685010e-01  0.00000000e+00  6.44704048e-03
  -2.18178481e-02 -1.81619495e-01  2.35529423e-01 -2.44910270e-01
   2.12622255e-01 -2.94455290e-01]
 [-1.91825181e-01  6.77523971e-01  2.65178353e-01  2.92960018e-01
  -2.35643253e-01 -6.79048002e-01 -1.76491201e-01  6.46104753e-01
   2.23806471e-01  4.42119777e-01  5.15198886e-01 -1.87782750e-01
   1.57752335e-01  5.35469174e-01 -3.02843511e-01  5.37263930e-01
   1.00268054e+00  4.78971273e-01 -1.33380008e+00  7.68559892e-03
   7.85466373e-01  5.74971676e-01  0.00000000e+00 -4.91942585e-01
   1.43095171e+00 -6.05841935e-01 -7.34000921e-01  2.62763113e-01
  -7.40568280e-01  7.60796726e-01]
 [ 1.26931453e+00 -2.55051374e+00  3.78774822e-01 -1.52502751e+00
  -6.97381854e-01  2.20281386e+00  4.09762681e-01 -6.22534633e-01
   2.35857949e-01  2.10892960e-01  1.35469204e-02 -3.34103554e-01
  -3.63902479e-01  4.85194206e-01  3.56837332e-01  9.61749069e-03
   2.97771871e-01  3.09208054e-02 -1.51415676e-01  4.73012388e-01
  -3.89781624e-01 -6.72709405e-01  0.00000000e+00 -4.15440416e+00
  -1.27632171e-01  1.54291105e+00 -3.31637430e+00 -2.95829147e-01
   4.18936228e-03 -9.55143124e-02]
 [ 1.42058802e+00 -9.67213660e-02 -1.43865502e+00 -2.06736422e+00
   1.15796041e+00 -5.36676824e-01 -1.38192952e+00  4.28931415e-03
  -2.27251157e-01 -1.20658733e-01  4.47364688e-01  1.30644575e-01
   5.14725804e-01 -1.21475019e-01  1.59848899e-01  6.33786097e-02
  -1.04220949e-01 -1.03829883e-01 -3.69792014e-01  9.76711139e-02
   5.41807353e-01  7.36005485e-01  0.00000000e+00 -3.29423606e-01
   2.21723467e-01  5.09468257e-01 -3.77488732e-02  5.20998389e-02
   3.12634744e-02 -4.33184728e-02]
 [-1.93710625e-01  2.78077602e-01 -7.08065182e-03  2.40872368e-01
   4.87094373e-03 -2.29145318e-01 -3.47872488e-02  6.96308911e-02
   8.58664066e-02 -8.03382322e-02 -3.44852746e-01  1.29713044e-01
   3.80947627e-02  5.05493768e-02 -1.39468256e-02  4.22564335e-02
  -4.63147201e-02  1.37966676e-02 -6.72237426e-02  1.61423415e-01
  -3.81300002e-02  1.06794991e-01  1.00000000e+00  9.53977287e-01
   9.71159935e-01 -4.73781735e-01  2.89539486e-01  1.96769848e-01
   2.58819629e-02 -4.87407558e-02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00 -4.66349572e-01
   1.04804464e-01  8.91030878e-02 -2.75999457e-01 -2.80491840e-02
  -2.78567020e-02 -1.33889103e-02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  7.77396932e-02
   6.12190031e-02 -1.22643180e-01  8.90119299e-02 -3.88204642e-02
   4.43180166e-02  9.79682654e-02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00 -7.14033283e-03
   2.98944145e-01 -4.95621711e-02 -2.07779452e-01 -7.52261728e-02
   1.21058203e-01 -1.01440184e-01]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.69007152e-01
  -1.45999953e-01  7.08746463e-02  1.33526802e-01  6.65289257e-03
   4.17342484e-02  6.05251752e-02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  6.75991416e-01
  -1.00354397e+00  1.06807184e+00  4.44492608e-01  1.26111239e-01
   4.00700659e-01 -2.37111941e-01]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.36099482e+00
   5.00319421e-01 -7.13515133e-02 -7.28482246e-01 -4.76994574e-01
   9.78261650e-01 -5.47200620e-01]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  1.20566416e+00
  -9.27697837e-01 -5.21257937e-01  1.85297787e+00  1.01428321e-02
   1.35949269e-01  3.35743397e-01]]
Eigen values: 
[1.         0.95182735 0.95182735 0.7681029  0.7681029  0.99890142
 0.99890142 0.69286066 0.69286066 0.82287222 0.82287222 0.36575727
 0.36575727 0.89994308 0.22303001 0.22303001 0.05050051 0.05050051
 0.30547913 0.60893377 0.60893377 0.64531761 0.56347962 0.57200923
 0.70262896 0.70262896 0.47590969 0.10524464 0.10524464 0.1506449 ]
[COMP] The identified Koopman operator is STABLE
------ ------ -----
----- Run Info ----
------ ------ -----
                                  0           1           2           3
x_hidden_variable_list            9           9           9           3
activation flag                   2           2           2           2
activation function             elu         elu         elu         elu
no of epochs                   1000        1000        1000        1000
batch size                      400         400         400         400
step size                       0.5         0.5         0.5         0.5
training error           0.00186586  0.00186586  0.00186586  0.00186586
validation error         0.00206281  0.00206281  0.00206281  0.00206281
r^2 training accuracy       95.8775     95.8775     95.8775     95.8775
r^2 validation accuracy     95.4472     95.4472     95.4472     95.4472
MSE training             0.00186586  0.00186586  0.00186586  0.00186586
MSE validation           0.00206281  0.00206281  0.00206281  0.00206281
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
                                  0           1           2           3
x_hidden_variable_list            9           9           9           3
activation flag                   2           2           2           2
activation function             elu         elu         elu         elu
no of epochs                  10000       10000       10000       10000
batch size                      400         400         400         400
step size                       0.3         0.3         0.3         0.3
training error           0.00105192  0.00105192  0.00105192  0.00105192
validation error         0.00123451  0.00123451  0.00123451  0.00123451
r^2 training accuracy       97.7874     97.7874     97.7874     97.7874
r^2 validation accuracy     97.3084     97.3084     97.3084     97.3084
MSE training             0.00105192  0.00105192  0.00105192  0.00105192
MSE validation           0.00123451  0.00123451  0.00123451  0.00123451
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
                                   0            1            2            3
x_hidden_variable_list             9            9            9            3
activation flag                    2            2            2            2
activation function              elu          elu          elu          elu
no of epochs                   10000        10000        10000        10000
batch size                       400          400          400          400
step size                        0.1          0.1          0.1          0.1
training error           0.000867124  0.000867124  0.000867124  0.000867124
validation error          0.00104964   0.00104964   0.00104964   0.00104964
r^2 training accuracy        98.1986      98.1986      98.1986      98.1986
r^2 validation accuracy      97.7239      97.7239      97.7239      97.7239
MSE training             0.000867124  0.000867124  0.000867124  0.000867124
MSE validation            0.00104964   0.00104964   0.00104964   0.00104964
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
                                   0            1            2            3
x_hidden_variable_list             9            9            9            3
activation flag                    2            2            2            2
activation function              elu          elu          elu          elu
no of epochs                   10000        10000        10000        10000
batch size                       400          400          400          400
step size                       0.09         0.09         0.09         0.09
training error           0.000805151  0.000805151  0.000805151  0.000805151
validation error         0.000985118  0.000985118  0.000985118  0.000985118
r^2 training accuracy        98.4147      98.4147      98.4147      98.4147
r^2 validation accuracy      97.9635      97.9635      97.9635      97.9635
MSE training             0.000805151  0.000805151  0.000805151  0.000805151
MSE validation           0.000985118  0.000985118  0.000985118  0.000985118
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
                                   0            1            2            3
x_hidden_variable_list             9            9            9            3
activation flag                    2            2            2            2
activation function              elu          elu          elu          elu
no of epochs                   10000        10000        10000        10000
batch size                       400          400          400          400
step size                       0.08         0.08         0.08         0.08
training error           0.000760449  0.000760449  0.000760449  0.000760449
validation error         0.000939168  0.000939168  0.000939168  0.000939168
r^2 training accuracy        98.5648      98.5648      98.5648      98.5648
r^2 validation accuracy       98.127       98.127       98.127       98.127
MSE training             0.000760449  0.000760449  0.000760449  0.000760449
MSE validation           0.000939168  0.000939168  0.000939168  0.000939168
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
