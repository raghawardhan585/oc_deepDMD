[INFO] Number of total samples: 4600
[INFO] Observable dimension of a sample: 7
[INFO] Xp.shape (E-DMD): (4600, 7)
[INFO] Yf.shape (E-DMD): (4600, 7)
Number of training snapshots: 2300
Number of validation snapshots: 2300
70
0.39735970711951313
0.3535533905932738
0.3535533905932738
0.4330127018922193
0.2773500981126146
1.0466205
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.5
Train Error Threshold      :  1e-06
Validation Error Threshold :  1e-06
Maximum number of Epochs   :  1000
Batch Size   :  400
--------------------------------------
Epoch No:  1000  |   Training error:  0.0020629053
                   Validation error:  0.0023025966
---------------------------------------------------------------------------------------------------
Current Training Error  : 0.0020629053
Current Validation Error      : 0.0023025966
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.3
Train Error Threshold      :  1e-06
Validation Error Threshold :  1e-06
Maximum number of Epochs   :  10000
Batch Size   :  400
--------------------------------------
Epoch No:  1000  |   Training error:  0.0016756176
                   Validation error:  0.0018981058
---------------------------------------------------------------------------------------------------
Epoch No:  2000  |   Training error:  0.0014979796
                   Validation error:  0.0017171704
---------------------------------------------------------------------------------------------------
Epoch No:  3000  |   Training error:  0.0013936976
                   Validation error:  0.0016119799
---------------------------------------------------------------------------------------------------
Epoch No:  4000  |   Training error:  0.0013237786
                   Validation error:  0.00154123
---------------------------------------------------------------------------------------------------
Epoch No:  5000  |   Training error:  0.0012740343
                   Validation error:  0.0014880819
---------------------------------------------------------------------------------------------------
Epoch No:  6000  |   Training error:  0.0012333085
                   Validation error:  0.0014445852
---------------------------------------------------------------------------------------------------
Epoch No:  7000  |   Training error:  0.0011997177
                   Validation error:  0.0014099253
---------------------------------------------------------------------------------------------------
Epoch No:  8000  |   Training error:  0.0011788277
                   Validation error:  0.001388108
---------------------------------------------------------------------------------------------------
Epoch No:  9000  |   Training error:  0.0011480757
                   Validation error:  0.0013539458
---------------------------------------------------------------------------------------------------
Epoch No:  10000  |   Training error:  0.0011283221
                    Validation error:  0.001330908
---------------------------------------------------------------------------------------------------
Current Training Error  : 0.0011283221
Current Validation Error      : 0.001330908
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.1
Train Error Threshold      :  1e-07
Validation Error Threshold :  1e-07
Maximum number of Epochs   :  10000
Batch Size   :  400
--------------------------------------
Epoch No:  1000  |   Training error:  0.0011201152
                   Validation error:  0.0013219087
---------------------------------------------------------------------------------------------------
Epoch No:  2000  |   Training error:  0.0011138334
                   Validation error:  0.0013148453
---------------------------------------------------------------------------------------------------
Epoch No:  3000  |   Training error:  0.0011076675
                   Validation error:  0.0013084468
---------------------------------------------------------------------------------------------------
Epoch No:  4000  |   Training error:  0.0011021433
                   Validation error:  0.0013018952
---------------------------------------------------------------------------------------------------
Epoch No:  5000  |   Training error:  0.0010964604
                   Validation error:  0.0012957641
---------------------------------------------------------------------------------------------------
Epoch No:  6000  |   Training error:  0.0010910549
                   Validation error:  0.0012895275
---------------------------------------------------------------------------------------------------
Epoch No:  7000  |   Training error:  0.0010868438
                   Validation error:  0.0012849644
---------------------------------------------------------------------------------------------------
Epoch No:  8000  |   Training error:  0.0010813222
                   Validation error:  0.0012788936
---------------------------------------------------------------------------------------------------
Epoch No:  9000  |   Training error:  0.0010761697
                   Validation error:  0.0012727772
---------------------------------------------------------------------------------------------------
Epoch No:  10000  |   Training error:  0.0010720412
                    Validation error:  0.0012676641
---------------------------------------------------------------------------------------------------
Current Training Error  : 0.0010720412
Current Validation Error      : 0.0012676641
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.09
Train Error Threshold      :  1e-08
Validation Error Threshold :  1e-08
Maximum number of Epochs   :  10000
Batch Size   :  400
--------------------------------------
Epoch No:  1000  |   Training error:  0.0010674818
                   Validation error:  0.0012627715
---------------------------------------------------------------------------------------------------
Epoch No:  2000  |   Training error:  0.0010634855
                   Validation error:  0.0012581734
---------------------------------------------------------------------------------------------------
Epoch No:  3000  |   Training error:  0.0010597747
                   Validation error:  0.0012537371
---------------------------------------------------------------------------------------------------
Epoch No:  4000  |   Training error:  0.0010559781
                   Validation error:  0.0012493056
---------------------------------------------------------------------------------------------------
Epoch No:  5000  |   Training error:  0.0010525078
                   Validation error:  0.0012456498
---------------------------------------------------------------------------------------------------
Epoch No:  6000  |   Training error:  0.0010487061
                   Validation error:  0.0012413533
---------------------------------------------------------------------------------------------------
Epoch No:  7000  |   Training error:  0.0010450622
                   Validation error:  0.0012368405
---------------------------------------------------------------------------------------------------
Epoch No:  8000  |   Training error:  0.0010419416
                   Validation error:  0.0012333518
---------------------------------------------------------------------------------------------------
Epoch No:  9000  |   Training error:  0.0010381541
                   Validation error:  0.0012291048
---------------------------------------------------------------------------------------------------
Epoch No:  10000  |   Training error:  0.0010348461
                    Validation error:  0.0012253498
---------------------------------------------------------------------------------------------------
Current Training Error  : 0.0010348461
Current Validation Error      : 0.0012253498
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.08
Train Error Threshold      :  1e-08
Validation Error Threshold :  1e-08
Maximum number of Epochs   :  10000
Batch Size   :  400
--------------------------------------
Epoch No:  1000  |   Training error:  0.001032358
                   Validation error:  0.0012224448
---------------------------------------------------------------------------------------------------
Epoch No:  2000  |   Training error:  0.0010293158
                   Validation error:  0.0012192382
---------------------------------------------------------------------------------------------------
Epoch No:  3000  |   Training error:  0.0010262245
                   Validation error:  0.00121587
---------------------------------------------------------------------------------------------------
Epoch No:  4000  |   Training error:  0.0010235168
                   Validation error:  0.0012124835
---------------------------------------------------------------------------------------------------
Epoch No:  5000  |   Training error:  0.0010205809
                   Validation error:  0.0012092408
---------------------------------------------------------------------------------------------------
Epoch No:  6000  |   Training error:  0.0010178437
                   Validation error:  0.0012063372
---------------------------------------------------------------------------------------------------
Epoch No:  7000  |   Training error:  0.0010151314
                   Validation error:  0.0012031196
---------------------------------------------------------------------------------------------------
Epoch No:  8000  |   Training error:  0.0010125902
                   Validation error:  0.0012002976
---------------------------------------------------------------------------------------------------
Epoch No:  9000  |   Training error:  0.0010100856
                   Validation error:  0.0011976766
---------------------------------------------------------------------------------------------------
Epoch No:  10000  |   Training error:  0.0010072794
                    Validation error:  0.0011943491
---------------------------------------------------------------------------------------------------
Current Training Error  : 0.0010072794
Current Validation Error      : 0.0011943491
0.0010072794
---   OUTPUT COMPENSATED STATE TRAINING COMPLETE   ---
                                       0  ...                4
MSE training                  0.00206291  ...       0.00100728
MSE validation                 0.0023026  ...       0.00119435
activation flag                        2  ...                2
activation function                  elu  ...              elu
batch size                           400  ...              400
no of epochs                        1000  ...            10000
r^2 training accuracy             95.188  ...          97.7666
r^2 validation accuracy          94.6673  ...           97.357
step size                            0.5  ...             0.08
training error                0.00206291  ...       0.00100728
validation error               0.0023026  ...       0.00119435
x_hidden_variable_list   [12, 12, 12, 4]  ...  [12, 12, 12, 4]

[12 rows x 5 columns]
[[ 4.72021610e-01  3.38556647e-01  4.18689936e-01  5.00197947e-01
  -8.31248388e-02 -1.01515174e-01  3.24863672e-01 -1.07199080e-01
  -5.25555760e-02 -8.89151245e-02  1.40477065e-02 -4.08105925e-02
  -5.05048744e-02 -4.77822088e-02  3.71716097e-02 -4.54329997e-02
   1.43755116e-02 -4.80397791e-02  3.32842022e-02  6.11363053e-02
  -2.87101828e-02  1.82384923e-02  0.00000000e+00 -3.74838024e-01
   1.18191801e-01 -9.44111943e-02 -3.39191318e-01  1.13381140e-01
  -2.12972853e-02  4.06649522e-02 -1.98932618e-01]
 [ 8.48779082e-01 -7.17963576e-01  4.39066291e-01 -4.07984763e-01
  -6.20698750e-01  1.23670173e+00  9.55862701e-02 -1.52714169e-02
  -2.87818648e-02 -6.84470981e-02  6.31697848e-02 -5.33242058e-03
   1.75399706e-02 -3.29068955e-03 -1.02510201e-02 -3.64312492e-02
  -8.67458135e-02  1.23510864e-02 -3.33768316e-02  6.75345659e-02
   1.99070331e-02  1.52588412e-01  0.00000000e+00  3.31044406e-01
   9.03052315e-02  4.72549014e-02 -1.58803672e-01 -2.83646807e-02
  -2.19404455e-02 -5.87189794e-02  8.26070234e-02]
 [-1.94961563e-01  1.55483186e-01  2.25668952e-01  4.12493140e-01
  -2.89172649e-01  5.04668131e-02  2.09587902e-01 -3.79245579e-02
   2.90083885e-02  1.40719330e-02 -9.05176252e-02 -1.37555199e-02
  -5.71453385e-02 -4.55610454e-03  6.52652234e-03 -2.30827183e-02
  -5.50810695e-02 -1.13127036e-02  7.05968589e-02 -5.37536992e-03
  -4.00860906e-02 -9.74392071e-02  0.00000000e+00  2.27906987e-01
   1.07232966e-01 -2.17163950e-01  3.03290430e-02 -1.16331503e-02
  -3.23415291e-03 -2.13726726e-03  1.65205374e-02]
 [ 1.42681122e-01  1.38099000e-01  8.26231465e-02 -2.26357430e-01
   2.51242518e-01 -2.18633577e-01 -5.43674342e-02 -1.85664743e-02
  -1.33187901e-02 -3.13937361e-03  4.41333950e-02 -3.78221180e-03
   1.29165230e-02 -2.42586769e-02  1.08600771e-02 -1.62226576e-02
   2.82936487e-02 -1.33429570e-02 -2.53299829e-02 -1.63266603e-02
   3.21783088e-02  4.04494070e-02  0.00000000e+00 -3.40261668e-01
   3.84128571e-01  7.76548637e-03 -3.89243364e-01 -2.80159004e-02
   1.08698849e-03 -2.38686167e-02 -2.52688164e-03]
 [-3.32499057e-01  2.28532419e-01  1.91549256e-01  2.63558447e-01
   1.80633068e-01 -9.07276496e-02  1.71841830e-01  1.72209516e-02
   1.33938745e-01  1.57564908e-01 -9.09818411e-02 -5.18622436e-02
  -6.73819110e-02  1.42334700e-01 -1.94332581e-02  4.73408625e-02
   1.58480048e-01  7.75364563e-02 -1.39649525e-01  3.54051404e-02
  -9.51924697e-02 -1.61421329e-01  0.00000000e+00 -7.01858044e-01
   1.37618333e-01  9.23194960e-02 -3.85451078e-01 -2.35610432e-03
   8.95471592e-03 -3.25217214e-03 -5.23211658e-02]
 [ 7.42916584e-01 -5.83198488e-01  2.36311868e-01 -8.48347068e-01
  -2.93863863e-01  9.25468326e-01 -5.09513199e-01  4.33954410e-02
   7.95441493e-02  7.11459294e-02  1.27575779e-02 -1.26514174e-02
   2.74136700e-02  7.45158195e-02 -3.37066762e-02 -1.36511875e-02
  -2.17071385e-03  8.58126134e-02 -1.21233612e-01  3.20427865e-02
  -7.66631439e-02  3.27694453e-02  0.00000000e+00  1.77985847e-01
  -1.21748358e-01  5.43688759e-02  2.51039326e-01 -6.36176839e-02
   3.67607595e-03  5.16914204e-03  3.21836993e-02]
 [-3.14152181e-01  2.81061769e-01  2.43116930e-01  4.22723740e-01
  -1.06773570e-01 -1.62992939e-01  7.70393848e-01 -6.45077005e-02
   8.77915416e-03 -3.01323342e-03 -2.41301488e-02 -4.00016233e-02
  -2.90398877e-02 -9.98169184e-04  7.67876767e-03 -2.29442846e-02
  -2.15396704e-03 -2.02907324e-02  8.61994922e-03  6.58323690e-02
  -1.75015200e-02 -4.62848842e-02  0.00000000e+00 -2.21326068e-01
   4.07397412e-02  1.34636298e-01 -1.66982114e-01  3.99487726e-02
  -1.38715794e-02 -7.23778233e-02 -1.35516925e-02]
 [ 9.10587192e-01  8.89168978e-02 -1.71380925e+00 -5.12568235e-01
   6.78518340e-02 -4.41929698e-01 -9.30596709e-01 -3.02964635e-02
   2.90434062e-01  4.97242093e-01 -7.20400035e-01  1.38922380e-02
  -4.89886791e-01  3.62063706e-01  2.42087558e-01  2.55168200e-01
   1.15831215e-02  9.02870148e-02  2.27217302e-01 -1.47329539e-01
  -4.58247691e-01 -7.96424508e-01  0.00000000e+00 -2.81788182e+00
   1.30272377e+00  1.99730620e-01 -2.63849497e+00  2.95828879e-02
  -1.41710313e-02 -1.55929616e-02  7.43788928e-02]
 [-6.24968290e-01  4.42626774e-01 -8.98404777e-01  5.56450903e-01
  -3.71360987e-01 -1.03725262e-01  4.02868062e-01 -2.66276747e-02
   3.57256889e-01  4.79882210e-01 -3.32526028e-01  1.75967604e-01
   1.85024559e-01  3.92382108e-02  1.07147612e-01  1.17679276e-01
  -1.73717827e-01  2.49621570e-01 -2.61997014e-01 -1.49054468e-01
   6.07348204e-01 -3.42899024e-01  0.00000000e+00 -1.97631383e+00
   7.80171096e-01  1.50922313e-01 -1.19119298e+00  5.15001789e-02
   1.22430958e-01 -2.45972961e-01 -1.52597278e-01]
 [-1.77198768e-01 -2.86528707e-01 -8.13382789e-02  9.92919579e-02
  -1.29084074e+00  6.70777142e-01  5.77111483e-01 -8.88769776e-02
   1.41930491e-01  6.32992536e-02  9.32350382e-02 -1.15862206e-01
   4.02539283e-01  2.36165002e-01  3.53870749e-01  1.02935284e-02
  -1.75657466e-01 -9.69285741e-02 -1.60486192e-01  6.58358753e-01
  -3.83784086e-01 -2.24543065e-01  0.00000000e+00  7.00453222e-01
  -4.60173458e-01 -1.07670039e-01  4.87855643e-01 -4.68894579e-02
  -1.43776834e-01 -8.05443376e-02  2.16006979e-01]
 [ 8.92740369e-01 -1.21604311e+00  4.66681808e-01  1.79148111e-02
   2.45707184e-02  8.30945373e-01 -4.89901006e-01  7.99527228e-01
   3.76926437e-02  7.68536404e-02 -2.08924741e-01  5.48284352e-01
   1.06011964e-01 -1.98116675e-01 -7.38254607e-01  3.28864068e-01
  -3.76861811e-01  2.27851868e-01  2.88977265e-01 -1.92369729e-01
   2.59052873e-01  8.39488745e-01  0.00000000e+00  2.15865898e+00
   5.28033018e-01 -3.09882879e-01  2.15814874e-01 -6.60207421e-02
   1.14113227e-01 -4.94202256e-01  5.11381209e-01]
 [ 4.15755570e-01 -4.74210158e-02  1.38449565e-01  1.00829892e-01
   2.10326925e-01 -3.65294427e-01 -4.57485437e-01 -2.35200942e-01
   4.38201010e-01 -2.05884203e-01 -3.99543583e-01 -2.17268392e-02
   2.25557879e-01  3.87856886e-02 -2.18918407e-03 -3.40303332e-01
  -1.95349216e-01 -1.24205470e-01  1.33700356e-01  4.44391727e-01
  -7.81964242e-01 -7.58748293e-01  0.00000000e+00 -5.14651656e-01
   9.33251739e-01 -1.07221043e+00 -1.32299352e+00 -2.81827837e-01
  -1.43574223e-01 -3.38089228e-01  5.38933992e-01]
 [ 6.41154051e-01  3.37557793e-01  2.83643931e-01 -1.35616457e+00
  -4.68263775e-01 -8.47803891e-01 -1.18001986e+00  3.76001120e-01
   3.91849801e-02  9.83202681e-02 -2.31172025e-01  1.15914106e-01
   2.60332048e-01  8.63628238e-02  2.35143956e-02 -1.70469269e-01
   1.18656598e-01  4.71216738e-01  1.21947691e-01 -8.08251441e-01
   9.03922096e-02  1.38807938e-01  0.00000000e+00  1.52986205e+00
   7.83232570e-01 -1.52643251e+00  1.37135935e+00 -2.98363239e-01
   5.41699938e-02  3.86502109e-02 -3.14826727e-01]
 [ 3.60034108e-02  7.67257344e-03 -6.98638380e-01  4.85708445e-01
  -1.29481101e+00  5.53385504e-02 -7.56273866e-02 -6.09043241e-01
  -3.51963460e-01 -1.95649624e-01 -3.39335240e-02 -2.34038636e-01
  -5.28396443e-02  2.19291836e-01 -6.03780933e-02 -9.07979310e-02
  -2.02189848e-01 -5.25277779e-02 -8.66898708e-03  2.05893070e-02
   4.90600139e-01  6.06440365e-01  0.00000000e+00  1.18760300e+00
  -4.44427729e-01 -1.31574976e+00  9.64234591e-01  2.03979552e-01
  -1.20124608e-01  4.08855937e-02 -2.59143263e-01]
 [-1.57804951e-01 -1.93809271e-01  1.02898479e+00  5.11063516e-01
  -4.74434912e-01  2.46352538e-01 -3.26581858e-02  2.19091047e-02
  -3.61383110e-01 -2.80940890e-01  2.24536002e-01  2.13068664e-01
   1.31324127e-01 -2.47522011e-01  4.55174714e-01  1.64270028e-01
  -6.01137936e-01 -1.98013321e-01  5.68196833e-01 -9.80517045e-02
   5.79907000e-01  2.03512713e-01  0.00000000e+00  1.71846414e+00
  -9.24480557e-01 -4.48299736e-01  1.20835197e+00  1.50055975e-01
   1.42261281e-03  4.03219223e-01 -1.92057624e-01]
 [ 3.16732258e-01 -3.83855790e-01 -2.83055514e-01 -8.54100138e-02
  -8.36213470e-01 -3.24855500e-05 -5.43858707e-01 -3.17064337e-02
   2.92859286e-01  6.18303455e-02  1.13387287e-01 -5.27197599e-01
   1.20162135e-02  1.04343399e-01  1.60209881e-03 -1.20201401e-01
  -1.32553935e-01 -1.94758043e-01 -9.62805599e-02  1.80751622e-01
  -5.85892260e-01  8.27701092e-02  0.00000000e+00  4.18921262e-01
   1.91242743e+00 -7.07973778e-01 -1.02356422e+00 -1.91348359e-01
   4.69489692e-04  5.01391850e-02  1.03670046e-01]
 [-2.10854590e-01 -1.13472509e+00 -6.40003264e-01  9.86311018e-01
  -1.77692130e-01  1.85218954e+00  1.16771090e+00  5.19027948e-01
   1.15492314e-01 -1.16215954e-02 -2.09119260e-01  2.80016333e-01
   2.61475742e-01  1.74286991e-01 -5.67484498e-02  4.31424044e-02
  -1.06386654e-01  1.56662479e-01  3.39574963e-02 -1.09141037e-01
  -2.82227755e-01  3.71830463e-01  0.00000000e+00  3.10889792e+00
  -8.06845009e-01  2.36664578e-01  1.51124036e+00 -7.56888762e-02
   6.60784915e-02  5.36587927e-03  2.45574996e-01]
 [ 2.94792444e-01 -1.80234104e-01 -9.45258617e-01  2.03779548e-01
  -6.66597068e-01  1.74163684e-01  1.10995613e-01  1.08779259e-01
   3.33873034e-01 -9.22608078e-02 -7.08168373e-02  1.27328411e-01
  -1.40865281e-01 -1.02967255e-01 -2.88913757e-01  6.63279032e-04
   1.58132054e-02  5.90206757e-02  3.21817487e-01  7.41249979e-01
  -3.47356707e-01 -1.87513351e-01  0.00000000e+00  1.02546179e+00
  -3.30130339e-01  3.96555752e-01  5.63682199e-01 -1.77946687e-02
   3.91470753e-02 -7.24074990e-02  9.11722258e-02]
 [-6.67452812e-01  1.38474035e+00  1.23455632e+00  1.57202899e-01
   1.74883246e+00 -1.12067032e+00 -3.42481822e-01 -6.54553950e-01
   2.28824422e-01  2.04294652e-01 -2.82363802e-01 -1.77971661e-01
  -1.90061420e-01  2.97669530e-01  1.29798293e-01 -4.43857424e-02
  -2.41367429e-01 -1.63145617e-01  3.06502432e-01  7.59017050e-01
  -5.49215198e-01 -1.27685010e-01  0.00000000e+00 -3.68676811e-01
   2.37774745e-01 -3.17518026e-01  2.67869443e-01 -4.88257930e-02
   1.08948916e-01 -3.35315913e-01  2.60110438e-01]
 [-1.91825181e-01  6.77523971e-01  2.65178353e-01  2.92960018e-01
  -2.35643253e-01 -6.79048002e-01 -1.76491201e-01  6.46104753e-01
   2.23806471e-01  4.42119777e-01  5.15198886e-01 -1.87782750e-01
   1.57752335e-01  5.35469174e-01 -3.02843511e-01  5.37263930e-01
   1.00268054e+00  4.78971273e-01 -1.33380008e+00  7.68559892e-03
   7.85466373e-01  5.74971676e-01  0.00000000e+00 -1.59817040e+00
   2.25041056e+00 -7.46987104e-01 -1.88524210e+00  7.40033090e-02
  -8.69049504e-02  5.21072686e-01 -6.32205844e-01]
 [ 1.26931453e+00 -2.55051374e+00  3.78774822e-01 -1.52502751e+00
  -6.97381854e-01  2.20281386e+00  4.09762681e-01 -6.22534633e-01
   2.35857949e-01  2.10892960e-01  1.35469204e-02 -3.34103554e-01
  -3.63902479e-01  4.85194206e-01  3.56837332e-01  9.61749069e-03
   2.97771871e-01  3.09208054e-02 -1.51415676e-01  4.73012388e-01
  -3.89781624e-01 -6.72709405e-01  0.00000000e+00 -4.15465689e+00
  -2.10594237e-01  1.54912198e+00 -3.23699141e+00  3.13263852e-03
   8.43778998e-03 -7.23110959e-02  2.36448258e-01]
 [ 1.42058802e+00 -9.67213660e-02 -1.43865502e+00 -2.06736422e+00
   1.15796041e+00 -5.36676824e-01 -1.38192952e+00  4.28931415e-03
  -2.27251157e-01 -1.20658733e-01  4.47364688e-01  1.30644575e-01
   5.14725804e-01 -1.21475019e-01  1.59848899e-01  6.33786097e-02
  -1.04220949e-01 -1.03829883e-01 -3.69792014e-01  9.76711139e-02
   5.41807353e-01  7.36005485e-01  0.00000000e+00 -3.24039340e-01
   3.04116040e-01  2.83067614e-01  2.12649349e-02  6.56131878e-02
  -3.57625037e-02  3.73178013e-02 -4.83125411e-02]
 [-1.93710625e-01  2.78077602e-01 -7.08065182e-03  2.40872368e-01
   4.87094373e-03 -2.29145318e-01 -3.47872488e-02  6.96308911e-02
   8.58664066e-02 -8.03382322e-02 -3.44852746e-01  1.29713044e-01
   3.80947627e-02  5.05493768e-02 -1.39468256e-02  4.22564335e-02
  -4.63147201e-02  1.37966676e-02 -6.72237426e-02  1.61423415e-01
  -3.81300002e-02  1.06794991e-01  1.00000000e+00  1.72381163e-01
   1.03039169e+00 -3.94876033e-01 -1.81236546e-02  9.96131226e-02
  -2.37145349e-02 -2.71245278e-03  3.45979273e-01]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.23761033e-02
  -1.72261894e-01  1.62565127e-01  9.18312073e-02  9.97681022e-02
  -7.77378678e-03  1.27088323e-01 -2.07661465e-01]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  5.54756112e-02
   8.94822553e-02 -5.64519763e-02  9.38964635e-02 -1.32391807e-02
   2.45006662e-02  3.16227935e-02  6.69012740e-02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00 -5.59241325e-03
   3.20127040e-01  7.16179758e-02 -2.49724954e-01 -2.82872058e-02
   2.79100593e-02 -1.23540983e-01  2.14192569e-01]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  1.94372050e-02
  -3.75211030e-01  1.48413017e-01  4.18848962e-01 -1.62985791e-02
   1.10551137e-02 -4.75835726e-02  1.07849754e-01]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  5.66096306e-01
   1.84646592e-01  1.59940854e-01  3.79269302e-01 -4.49224822e-02
   1.82798237e-01  7.87213072e-03  5.23707330e-01]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  1.14185348e-01
   4.65683788e-01  1.16410427e-01  2.61231095e-01 -5.39757550e-01
   8.29563320e-01 -6.80766106e-01  2.60096848e-01]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  5.61216295e-01
  -5.25095910e-02 -3.39251384e-02  5.51209092e-01  9.04419050e-02
  -2.08324447e-01  1.02346383e-01 -8.99001062e-02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00 -6.10187829e-01
   4.17187601e-01  1.60079196e-01 -6.27721965e-01  1.10829063e-02
  -9.78226140e-02 -1.33222178e-01  2.40494668e-01]]
Eigen values: 
[1.         0.95182735 0.95182735 0.7681029  0.7681029  0.99890142
 0.99890142 0.69286066 0.69286066 0.82287222 0.82287222 0.36575727
 0.36575727 0.89994308 0.22303001 0.22303001 0.05050051 0.05050051
 0.30547913 0.60893377 0.60893377 0.64531761 0.56347962 0.88264143
 0.59858522 0.59858522 0.45912542 0.26483813 0.26483813 0.12527148
 0.03352249]
[COMP] The identified Koopman operator is STABLE
------ ------ -----
----- Run Info ----
------ ------ -----
                                  0           1           2           3
x_hidden_variable_list           12          12          12           4
activation flag                   2           2           2           2
activation function             elu         elu         elu         elu
no of epochs                   1000        1000        1000        1000
batch size                      400         400         400         400
step size                       0.5         0.5         0.5         0.5
training error           0.00206291  0.00206291  0.00206291  0.00206291
validation error          0.0023026   0.0023026   0.0023026   0.0023026
r^2 training accuracy        95.188      95.188      95.188      95.188
r^2 validation accuracy     94.6673     94.6673     94.6673     94.6673
MSE training             0.00206291  0.00206291  0.00206291  0.00206291
MSE validation            0.0023026   0.0023026   0.0023026   0.0023026
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
                                  0           1           2           3
x_hidden_variable_list           12          12          12           4
activation flag                   2           2           2           2
activation function             elu         elu         elu         elu
no of epochs                  10000       10000       10000       10000
batch size                      400         400         400         400
step size                       0.3         0.3         0.3         0.3
training error           0.00112832  0.00112832  0.00112832  0.00112832
validation error         0.00133091  0.00133091  0.00133091  0.00133091
r^2 training accuracy       97.4906     97.4906     97.4906     97.4906
r^2 validation accuracy     97.0483     97.0483     97.0483     97.0483
MSE training             0.00112832  0.00112832  0.00112832  0.00112832
MSE validation           0.00133091  0.00133091  0.00133091  0.00133091
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
                                  0           1           2           3
x_hidden_variable_list           12          12          12           4
activation flag                   2           2           2           2
activation function             elu         elu         elu         elu
no of epochs                  10000       10000       10000       10000
batch size                      400         400         400         400
step size                       0.1         0.1         0.1         0.1
training error           0.00107204  0.00107204  0.00107204  0.00107204
validation error         0.00126766  0.00126766  0.00126766  0.00126766
r^2 training accuracy       97.6267     97.6267     97.6267     97.6267
r^2 validation accuracy     97.2005     97.2005     97.2005     97.2005
MSE training             0.00107204  0.00107204  0.00107204  0.00107204
MSE validation           0.00126766  0.00126766  0.00126766  0.00126766
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
                                  0           1           2           3
x_hidden_variable_list           12          12          12           4
activation flag                   2           2           2           2
activation function             elu         elu         elu         elu
no of epochs                  10000       10000       10000       10000
batch size                      400         400         400         400
step size                      0.09        0.09        0.09        0.09
training error           0.00103485  0.00103485  0.00103485  0.00103485
validation error         0.00122535  0.00122535  0.00122535  0.00122535
r^2 training accuracy       97.7079     97.7079     97.7079     97.7079
r^2 validation accuracy     97.2928     97.2928     97.2928     97.2928
MSE training             0.00103485  0.00103485  0.00103485  0.00103485
MSE validation           0.00122535  0.00122535  0.00122535  0.00122535
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
                                  0           1           2           3
x_hidden_variable_list           12          12          12           4
activation flag                   2           2           2           2
activation function             elu         elu         elu         elu
no of epochs                  10000       10000       10000       10000
batch size                      400         400         400         400
step size                      0.08        0.08        0.08        0.08
training error           0.00100728  0.00100728  0.00100728  0.00100728
validation error         0.00119435  0.00119435  0.00119435  0.00119435
r^2 training accuracy       97.7666     97.7666     97.7666     97.7666
r^2 validation accuracy      97.357      97.357      97.357      97.357
MSE training             0.00100728  0.00100728  0.00100728  0.00100728
MSE validation           0.00119435  0.00119435  0.00119435  0.00119435
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
