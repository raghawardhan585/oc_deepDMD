[INFO] Number of total samples: 4600
[INFO] Observable dimension of a sample: 7
[INFO] Xp.shape (E-DMD): (4600, 7)
[INFO] Yf.shape (E-DMD): (4600, 7)
Number of training snapshots: 2300
Number of validation snapshots: 2300
70
0.4803844614152614
0.5
0.5
0.5773502691896257
0.2847473987257497
1.4399776
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.5
Train Error Threshold      :  1e-06
Validation Error Threshold :  1e-06
Maximum number of Epochs   :  1000
Batch Size   :  400
--------------------------------------
Epoch No:  1000  |   Training error:  0.001667299
                   Validation error:  0.0018367235
---------------------------------------------------------------------------------------------------
Current Training Error  : 0.001667299
Current Validation Error      : 0.0018367235
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.3
Train Error Threshold      :  1e-06
Validation Error Threshold :  1e-06
Maximum number of Epochs   :  10000
Batch Size   :  400
--------------------------------------
Epoch No:  1000  |   Training error:  0.001457061
                   Validation error:  0.0016236018
---------------------------------------------------------------------------------------------------
Epoch No:  2000  |   Training error:  0.0012123021
                   Validation error:  0.0013955553
---------------------------------------------------------------------------------------------------
Epoch No:  3000  |   Training error:  0.0011405323
                   Validation error:  0.0013253539
---------------------------------------------------------------------------------------------------
Epoch No:  4000  |   Training error:  0.0010960755
                   Validation error:  0.0012880344
---------------------------------------------------------------------------------------------------
Epoch No:  5000  |   Training error:  0.001030295
                   Validation error:  0.0012222668
---------------------------------------------------------------------------------------------------
Epoch No:  6000  |   Training error:  0.0010077781
                   Validation error:  0.0011943172
---------------------------------------------------------------------------------------------------
Epoch No:  7000  |   Training error:  0.0010185754
                   Validation error:  0.0012057098
---------------------------------------------------------------------------------------------------
Epoch No:  8000  |   Training error:  0.0008923619
                   Validation error:  0.0010858208
---------------------------------------------------------------------------------------------------
Epoch No:  9000  |   Training error:  0.00089552696
                   Validation error:  0.0010935438
---------------------------------------------------------------------------------------------------
Epoch No:  10000  |   Training error:  0.0009099743
                    Validation error:  0.0010995542
---------------------------------------------------------------------------------------------------
Current Training Error  : 0.0009099743
Current Validation Error      : 0.0010995542
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.1
Train Error Threshold      :  1e-07
Validation Error Threshold :  1e-07
Maximum number of Epochs   :  10000
Batch Size   :  400
--------------------------------------
Epoch No:  1000  |   Training error:  0.00080956426
                   Validation error:  0.0010031946
---------------------------------------------------------------------------------------------------
Epoch No:  2000  |   Training error:  0.0008004387
                   Validation error:  0.0009946137
---------------------------------------------------------------------------------------------------
Epoch No:  3000  |   Training error:  0.0007887153
                   Validation error:  0.0009835768
---------------------------------------------------------------------------------------------------
Epoch No:  4000  |   Training error:  0.0007818795
                   Validation error:  0.000976295
---------------------------------------------------------------------------------------------------
Epoch No:  5000  |   Training error:  0.00077009253
                   Validation error:  0.00096566067
---------------------------------------------------------------------------------------------------
Epoch No:  6000  |   Training error:  0.0007610679
                   Validation error:  0.00095683336
---------------------------------------------------------------------------------------------------
Epoch No:  7000  |   Training error:  0.0007517912
                   Validation error:  0.0009476654
---------------------------------------------------------------------------------------------------
Epoch No:  8000  |   Training error:  0.00074506673
                   Validation error:  0.0009394103
---------------------------------------------------------------------------------------------------
Epoch No:  9000  |   Training error:  0.0007353112
                   Validation error:  0.00092975626
---------------------------------------------------------------------------------------------------
Epoch No:  10000  |   Training error:  0.0007279236
                    Validation error:  0.00092197297
---------------------------------------------------------------------------------------------------
Current Training Error  : 0.0007279236
Current Validation Error      : 0.00092197297
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.09
Train Error Threshold      :  1e-08
Validation Error Threshold :  1e-08
Maximum number of Epochs   :  10000
Batch Size   :  400
--------------------------------------
Epoch No:  1000  |   Training error:  0.00072046724
                   Validation error:  0.0009124957
---------------------------------------------------------------------------------------------------
Epoch No:  2000  |   Training error:  0.00071447087
                   Validation error:  0.00090681826
---------------------------------------------------------------------------------------------------
Epoch No:  3000  |   Training error:  0.0007073569
                   Validation error:  0.0008976096
---------------------------------------------------------------------------------------------------
Epoch No:  4000  |   Training error:  0.0007021482
                   Validation error:  0.000890418
---------------------------------------------------------------------------------------------------
Epoch No:  5000  |   Training error:  0.00069533155
                   Validation error:  0.0008831857
---------------------------------------------------------------------------------------------------
Epoch No:  6000  |   Training error:  0.0006919766
                   Validation error:  0.00087818195
---------------------------------------------------------------------------------------------------
Epoch No:  7000  |   Training error:  0.0006847897
                   Validation error:  0.00086892635
---------------------------------------------------------------------------------------------------
Epoch No:  8000  |   Training error:  0.0006789554
                   Validation error:  0.00086322665
---------------------------------------------------------------------------------------------------
Epoch No:  9000  |   Training error:  0.0006742579
                   Validation error:  0.0008562033
---------------------------------------------------------------------------------------------------
Epoch No:  10000  |   Training error:  0.00066924596
                    Validation error:  0.0008506062
---------------------------------------------------------------------------------------------------
Current Training Error  : 0.00066924596
Current Validation Error      : 0.0008506062
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.08
Train Error Threshold      :  1e-08
Validation Error Threshold :  1e-08
Maximum number of Epochs   :  10000
Batch Size   :  400
--------------------------------------
Epoch No:  1000  |   Training error:  0.0006636437
                   Validation error:  0.00084364106
---------------------------------------------------------------------------------------------------
Epoch No:  2000  |   Training error:  0.0006597507
                   Validation error:  0.00083952147
---------------------------------------------------------------------------------------------------
Epoch No:  3000  |   Training error:  0.000657439
                   Validation error:  0.00083413516
---------------------------------------------------------------------------------------------------
Epoch No:  4000  |   Training error:  0.0006503226
                   Validation error:  0.0008268077
---------------------------------------------------------------------------------------------------
Epoch No:  5000  |   Training error:  0.0006485619
                   Validation error:  0.0008241425
---------------------------------------------------------------------------------------------------
Epoch No:  6000  |   Training error:  0.0006424537
                   Validation error:  0.00081638264
---------------------------------------------------------------------------------------------------
Epoch No:  7000  |   Training error:  0.0006395365
                   Validation error:  0.00081367884
---------------------------------------------------------------------------------------------------
Epoch No:  8000  |   Training error:  0.0006350701
                   Validation error:  0.00080757966
---------------------------------------------------------------------------------------------------
Epoch No:  9000  |   Training error:  0.0006334535
                   Validation error:  0.00080477726
---------------------------------------------------------------------------------------------------
Epoch No:  10000  |   Training error:  0.000627931
                    Validation error:  0.00079792197
---------------------------------------------------------------------------------------------------
Current Training Error  : 0.000627931
Current Validation Error      : 0.00079792197
0.000627931
---   OUTPUT COMPENSATED STATE TRAINING COMPLETE   ---
                                    0             1  ...             3             4
MSE training                0.0016673   0.000909974  ...   0.000669246   0.000627931
MSE validation             0.00183672    0.00109955  ...   0.000850606   0.000797922
activation flag                     2             2  ...             2             2
activation function               elu           elu  ...           elu           elu
batch size                        400           400  ...           400           400
no of epochs                     1000         10000  ...         10000         10000
r^2 training accuracy         96.1473       98.2553  ...       98.3683       98.2202
r^2 validation accuracy       96.0025       97.8387  ...       98.2581       98.1114
step size                         0.5           0.3  ...          0.09          0.08
training error              0.0016673   0.000909974  ...   0.000669246   0.000627931
validation error           0.00183672    0.00109955  ...   0.000850606   0.000797922
x_hidden_variable_list   [6, 6, 6, 3]  [6, 6, 6, 3]  ...  [6, 6, 6, 3]  [6, 6, 6, 3]

[12 rows x 5 columns]
[[ 4.72021610e-01  3.38556647e-01  4.18689936e-01  5.00197947e-01
  -8.31248388e-02 -1.01515174e-01  3.24863672e-01 -1.07199080e-01
  -5.25555760e-02 -8.89151245e-02  1.40477065e-02 -4.08105925e-02
  -5.05048744e-02 -4.77822088e-02  3.71716097e-02 -4.54329997e-02
   1.43755116e-02 -4.80397791e-02  3.32842022e-02  6.11363053e-02
  -2.87101828e-02  1.82384923e-02  0.00000000e+00 -2.41777986e-01
   2.63365477e-01 -1.14443600e-01 -3.60201001e-01  4.52612177e-04
  -3.84792536e-02  2.35857423e-02]
 [ 8.48779082e-01 -7.17963576e-01  4.39066291e-01 -4.07984763e-01
  -6.20698750e-01  1.23670173e+00  9.55862701e-02 -1.52714169e-02
  -2.87818648e-02 -6.84470981e-02  6.31697848e-02 -5.33242058e-03
   1.75399706e-02 -3.29068955e-03 -1.02510201e-02 -3.64312492e-02
  -8.67458135e-02  1.23510864e-02 -3.33768316e-02  6.75345659e-02
   1.99070331e-02  1.52588412e-01  0.00000000e+00  1.21305712e-01
   1.33417770e-01  7.78386518e-02 -3.41768444e-01  3.34155522e-02
  -4.64180624e-03 -2.13247426e-02]
 [-1.94961563e-01  1.55483186e-01  2.25668952e-01  4.12493140e-01
  -2.89172649e-01  5.04668131e-02  2.09587902e-01 -3.79245579e-02
   2.90083885e-02  1.40719330e-02 -9.05176252e-02 -1.37555199e-02
  -5.71453385e-02 -4.55610454e-03  6.52652234e-03 -2.30827183e-02
  -5.50810695e-02 -1.13127036e-02  7.05968589e-02 -5.37536992e-03
  -4.00860906e-02 -9.74392071e-02  0.00000000e+00  2.85540074e-01
  -5.51586598e-02 -1.78106606e-01  1.67578772e-01  4.37682159e-02
  -4.78530228e-02  4.52152491e-02]
 [ 1.42681122e-01  1.38099000e-01  8.26231465e-02 -2.26357430e-01
   2.51242518e-01 -2.18633577e-01 -5.43674342e-02 -1.85664743e-02
  -1.33187901e-02 -3.13937361e-03  4.41333950e-02 -3.78221180e-03
   1.29165230e-02 -2.42586769e-02  1.08600771e-02 -1.62226576e-02
   2.82936487e-02 -1.33429570e-02 -2.53299829e-02 -1.63266603e-02
   3.21783088e-02  4.04494070e-02  0.00000000e+00 -1.41948685e-01
   2.48916507e-01 -5.85211255e-03 -1.66071519e-01  1.41360620e-02
   4.10631448e-02 -4.47615311e-02]
 [-3.32499057e-01  2.28532419e-01  1.91549256e-01  2.63558447e-01
   1.80633068e-01 -9.07276496e-02  1.71841830e-01  1.72209516e-02
   1.33938745e-01  1.57564908e-01 -9.09818411e-02 -5.18622436e-02
  -6.73819110e-02  1.42334700e-01 -1.94332581e-02  4.73408625e-02
   1.58480048e-01  7.75364563e-02 -1.39649525e-01  3.54051404e-02
  -9.51924697e-02 -1.61421329e-01  0.00000000e+00 -3.94951701e-01
   7.75012523e-02  3.90880704e-02 -1.76901057e-01 -4.31625247e-02
  -4.52435948e-02  3.65226753e-02]
 [ 7.42916584e-01 -5.83198488e-01  2.36311868e-01 -8.48347068e-01
  -2.93863863e-01  9.25468326e-01 -5.09513199e-01  4.33954410e-02
   7.95441493e-02  7.11459294e-02  1.27575779e-02 -1.26514174e-02
   2.74136700e-02  7.45158195e-02 -3.37066762e-02 -1.36511875e-02
  -2.17071385e-03  8.58126134e-02 -1.21233612e-01  3.20427865e-02
  -7.66631439e-02  3.27694453e-02  0.00000000e+00 -5.40931672e-02
  -8.09476152e-02  9.94803831e-02  3.19456123e-02 -1.57166999e-02
  -2.68557165e-02 -5.04755229e-02]
 [-3.14152181e-01  2.81061769e-01  2.43116930e-01  4.22723740e-01
  -1.06773570e-01 -1.62992939e-01  7.70393848e-01 -6.45077005e-02
   8.77915416e-03 -3.01323342e-03 -2.41301488e-02 -4.00016233e-02
  -2.90398877e-02 -9.98169184e-04  7.67876767e-03 -2.29442846e-02
  -2.15396704e-03 -2.02907324e-02  8.61994922e-03  6.58323690e-02
  -1.75015200e-02 -4.62848842e-02  0.00000000e+00 -3.24441105e-01
   4.71113771e-01  6.49511069e-02 -5.27001381e-01 -1.52580542e-04
   7.31237009e-02 -3.31943408e-02]
 [ 9.10587192e-01  8.89168978e-02 -1.71380925e+00 -5.12568235e-01
   6.78518340e-02 -4.41929698e-01 -9.30596709e-01 -3.02964635e-02
   2.90434062e-01  4.97242093e-01 -7.20400035e-01  1.38922380e-02
  -4.89886791e-01  3.62063706e-01  2.42087558e-01  2.55168200e-01
   1.15831215e-02  9.02870148e-02  2.27217302e-01 -1.47329539e-01
  -4.58247691e-01 -7.96424508e-01  0.00000000e+00 -2.43411708e+00
   2.53864825e-01  5.81343919e-02 -1.61306703e+00 -4.26226221e-02
  -5.71992248e-02  1.78696945e-01]
 [-6.24968290e-01  4.42626774e-01 -8.98404777e-01  5.56450903e-01
  -3.71360987e-01 -1.03725262e-01  4.02868062e-01 -2.66276747e-02
   3.57256889e-01  4.79882210e-01 -3.32526028e-01  1.75967604e-01
   1.85024559e-01  3.92382108e-02  1.07147612e-01  1.17679276e-01
  -1.73717827e-01  2.49621570e-01 -2.61997014e-01 -1.49054468e-01
   6.07348204e-01 -3.42899024e-01  0.00000000e+00 -1.36885977e+00
   4.95860815e-01  2.09736899e-01 -9.05816793e-01 -5.74642755e-02
   1.77771822e-02  2.65726328e-01]
 [-1.77198768e-01 -2.86528707e-01 -8.13382789e-02  9.92919579e-02
  -1.29084074e+00  6.70777142e-01  5.77111483e-01 -8.88769776e-02
   1.41930491e-01  6.32992536e-02  9.32350382e-02 -1.15862206e-01
   4.02539283e-01  2.36165002e-01  3.53870749e-01  1.02935284e-02
  -1.75657466e-01 -9.69285741e-02 -1.60486192e-01  6.58358753e-01
  -3.83784086e-01 -2.24543065e-01  0.00000000e+00  6.68707430e-01
  -5.15415370e-01 -3.69591862e-01  4.83364582e-01  3.09994429e-01
  -1.65008858e-01 -1.53947338e-01]
 [ 8.92740369e-01 -1.21604311e+00  4.66681808e-01  1.79148111e-02
   2.45707184e-02  8.30945373e-01 -4.89901006e-01  7.99527228e-01
   3.76926437e-02  7.68536404e-02 -2.08924741e-01  5.48284352e-01
   1.06011964e-01 -1.98116675e-01 -7.38254607e-01  3.28864068e-01
  -3.76861811e-01  2.27851868e-01  2.88977265e-01 -1.92369729e-01
   2.59052873e-01  8.39488745e-01  0.00000000e+00  1.60349846e+00
   1.15774736e-01 -5.66181876e-02  9.66524556e-02  6.14804104e-02
   7.96607912e-01  3.15187015e-02]
 [ 4.15755570e-01 -4.74210158e-02  1.38449565e-01  1.00829892e-01
   2.10326925e-01 -3.65294427e-01 -4.57485437e-01 -2.35200942e-01
   4.38201010e-01 -2.05884203e-01 -3.99543583e-01 -2.17268392e-02
   2.25557879e-01  3.87856886e-02 -2.18918407e-03 -3.40303332e-01
  -1.95349216e-01 -1.24205470e-01  1.33700356e-01  4.44391727e-01
  -7.81964242e-01 -7.58748293e-01  0.00000000e+00 -4.36184049e-01
   2.56131351e-01 -1.16204262e+00 -2.62480855e-01 -1.27603471e-01
   2.10602269e-01 -4.40428734e-01]
 [ 6.41154051e-01  3.37557793e-01  2.83643931e-01 -1.35616457e+00
  -4.68263775e-01 -8.47803891e-01 -1.18001986e+00  3.76001120e-01
   3.91849801e-02  9.83202681e-02 -2.31172025e-01  1.15914106e-01
   2.60332048e-01  8.63628238e-02  2.35143956e-02 -1.70469269e-01
   1.18656598e-01  4.71216738e-01  1.21947691e-01 -8.08251441e-01
   9.03922096e-02  1.38807938e-01  0.00000000e+00  1.44496548e+00
   4.21450287e-01 -1.02883375e+00  1.14349854e+00  4.81754951e-02
  -4.57115203e-01  4.20235693e-01]
 [ 3.60034108e-02  7.67257344e-03 -6.98638380e-01  4.85708445e-01
  -1.29481101e+00  5.53385504e-02 -7.56273866e-02 -6.09043241e-01
  -3.51963460e-01 -1.95649624e-01 -3.39335240e-02 -2.34038636e-01
  -5.28396443e-02  2.19291836e-01 -6.03780933e-02 -9.07979310e-02
  -2.02189848e-01 -5.25277779e-02 -8.66898708e-03  2.05893070e-02
   4.90600139e-01  6.06440365e-01  0.00000000e+00  1.13175023e+00
  -2.60037631e-01 -9.44786191e-01  7.16080546e-01 -7.96060115e-02
  -6.33826673e-01  3.13007176e-01]
 [-1.57804951e-01 -1.93809271e-01  1.02898479e+00  5.11063516e-01
  -4.74434912e-01  2.46352538e-01 -3.26581858e-02  2.19091047e-02
  -3.61383110e-01 -2.80940890e-01  2.24536002e-01  2.13068664e-01
   1.31324127e-01 -2.47522011e-01  4.55174714e-01  1.64270028e-01
  -6.01137936e-01 -1.98013321e-01  5.68196833e-01 -9.80517045e-02
   5.79907000e-01  2.03512713e-01  0.00000000e+00  1.09765530e+00
  -8.75751078e-01 -4.21526998e-01  7.35066593e-01 -8.20148960e-02
  -2.10159838e-01  2.07391813e-01]
 [ 3.16732258e-01 -3.83855790e-01 -2.83055514e-01 -8.54100138e-02
  -8.36213470e-01 -3.24855500e-05 -5.43858707e-01 -3.17064337e-02
   2.92859286e-01  6.18303455e-02  1.13387287e-01 -5.27197599e-01
   1.20162135e-02  1.04343399e-01  1.60209881e-03 -1.20201401e-01
  -1.32553935e-01 -1.94758043e-01 -9.62805599e-02  1.80751622e-01
  -5.85892260e-01  8.27701092e-02  0.00000000e+00  5.38372576e-01
   1.36199772e+00 -3.89982522e-01 -6.40326262e-01  2.08830997e-01
   5.01080036e-01 -3.94121706e-01]
 [-2.10854590e-01 -1.13472509e+00 -6.40003264e-01  9.86311018e-01
  -1.77692130e-01  1.85218954e+00  1.16771090e+00  5.19027948e-01
   1.15492314e-01 -1.16215954e-02 -2.09119260e-01  2.80016333e-01
   2.61475742e-01  1.74286991e-01 -5.67484498e-02  4.31424044e-02
  -1.06386654e-01  1.56662479e-01  3.39574963e-02 -1.09141037e-01
  -2.82227755e-01  3.71830463e-01  0.00000000e+00  2.10769987e+00
  -3.14325243e-01  3.93211097e-01  5.33370852e-01  3.21618617e-02
  -4.55633178e-02  7.12474361e-02]
 [ 2.94792444e-01 -1.80234104e-01 -9.45258617e-01  2.03779548e-01
  -6.66597068e-01  1.74163684e-01  1.10995613e-01  1.08779259e-01
   3.33873034e-01 -9.22608078e-02 -7.08168373e-02  1.27328411e-01
  -1.40865281e-01 -1.02967255e-01 -2.88913757e-01  6.63279032e-04
   1.58132054e-02  5.90206757e-02  3.21817487e-01  7.41249979e-01
  -3.47356707e-01 -1.87513351e-01  0.00000000e+00  1.83720469e-01
  -1.37401417e-01  2.95517087e-01 -3.59010044e-03  9.73798558e-02
   3.96970779e-01 -3.96124035e-01]
 [-6.67452812e-01  1.38474035e+00  1.23455632e+00  1.57202899e-01
   1.74883246e+00 -1.12067032e+00 -3.42481822e-01 -6.54553950e-01
   2.28824422e-01  2.04294652e-01 -2.82363802e-01 -1.77971661e-01
  -1.90061420e-01  2.97669530e-01  1.29798293e-01 -4.43857424e-02
  -2.41367429e-01 -1.63145617e-01  3.06502432e-01  7.59017050e-01
  -5.49215198e-01 -1.27685010e-01  0.00000000e+00 -3.86827290e-01
  -1.78654686e-01 -1.26379192e-01  2.72555977e-01  3.64447474e-01
   4.56739962e-01 -5.63135445e-01]
 [-1.91825181e-01  6.77523971e-01  2.65178353e-01  2.92960018e-01
  -2.35643253e-01 -6.79048002e-01 -1.76491201e-01  6.46104753e-01
   2.23806471e-01  4.42119777e-01  5.15198886e-01 -1.87782750e-01
   1.57752335e-01  5.35469174e-01 -3.02843511e-01  5.37263930e-01
   1.00268054e+00  4.78971273e-01 -1.33380008e+00  7.68559892e-03
   7.85466373e-01  5.74971676e-01  0.00000000e+00  7.22003877e-01
   1.22614229e+00 -8.69785607e-01  5.08690812e-02 -4.05639261e-01
  -5.02922833e-01  3.78759146e-01]
 [ 1.26931453e+00 -2.55051374e+00  3.78774822e-01 -1.52502751e+00
  -6.97381854e-01  2.20281386e+00  4.09762681e-01 -6.22534633e-01
   2.35857949e-01  2.10892960e-01  1.35469204e-02 -3.34103554e-01
  -3.63902479e-01  4.85194206e-01  3.56837332e-01  9.61749069e-03
   2.97771871e-01  3.09208054e-02 -1.51415676e-01  4.73012388e-01
  -3.89781624e-01 -6.72709405e-01  0.00000000e+00 -4.22233772e+00
   6.59826770e-02  1.32922387e+00 -3.29601359e+00 -3.10902119e-01
  -1.02933377e-01 -1.32096797e-01]
 [ 1.42058802e+00 -9.67213660e-02 -1.43865502e+00 -2.06736422e+00
   1.15796041e+00 -5.36676824e-01 -1.38192952e+00  4.28931415e-03
  -2.27251157e-01 -1.20658733e-01  4.47364688e-01  1.30644575e-01
   5.14725804e-01 -1.21475019e-01  1.59848899e-01  6.33786097e-02
  -1.04220949e-01 -1.03829883e-01 -3.69792014e-01  9.76711139e-02
   5.41807353e-01  7.36005485e-01  0.00000000e+00  1.66919306e-01
   2.13784307e-01  3.05534005e-01  2.41107509e-01  8.06096271e-02
   1.94109917e-01 -3.30136985e-01]
 [-1.93710625e-01  2.78077602e-01 -7.08065182e-03  2.40872368e-01
   4.87094373e-03 -2.29145318e-01 -3.47872488e-02  6.96308911e-02
   8.58664066e-02 -8.03382322e-02 -3.44852746e-01  1.29713044e-01
   3.80947627e-02  5.05493768e-02 -1.39468256e-02  4.22564335e-02
  -4.63147201e-02  1.37966676e-02 -6.72237426e-02  1.61423415e-01
  -3.81300002e-02  1.06794991e-01  1.00000000e+00 -3.22882831e-03
   5.08549333e-01 -5.19721746e-01  3.25105220e-01  2.40415245e-01
   2.59418517e-01  2.05530480e-01]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.25898415e-01
   3.07832751e-02  7.69238174e-02 -1.17527477e-01 -4.53954600e-02
  -9.25969332e-02  9.23413709e-02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  3.01128447e-01
  -6.74874261e-02 -8.23670253e-02  3.44510019e-01 -2.78219506e-02
  -6.42589927e-02 -2.39324775e-02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  1.72463045e-01
   1.16309226e-01  8.21357071e-02 -3.34082283e-02  1.03878826e-02
   1.00190699e-01 -4.37650084e-02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  1.12250745e-01
  -8.67100656e-02  1.18812934e-01  2.43275404e-01 -5.44194803e-02
   4.53326404e-02 -9.15291011e-02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.72564733e+00
  -1.96301699e+00  1.16268599e+00  2.71313637e-01  1.18387870e-01
  -2.26124004e-01  2.37135932e-01]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.79821813e+00
   1.74898648e+00  6.90323174e-01 -2.76057792e+00 -3.56888175e-01
   7.78421640e-01 -3.68253738e-01]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  2.61027074e+00
  -6.75013244e-01  1.04527569e+00  8.63142848e-01 -1.87985122e-01
   2.20292419e-01 -2.94565503e-02]]
Eigen values: 
[1.         0.95182735 0.95182735 0.7681029  0.7681029  0.99890142
 0.99890142 0.69286066 0.69286066 0.82287222 0.82287222 0.36575727
 0.36575727 0.89994308 0.22303001 0.22303001 0.05050051 0.05050051
 0.30547913 0.60893377 0.60893377 0.56347962 0.64531761 0.76237711
 0.61041476 0.61041476 0.52213291 0.36945982 0.171481   0.03037177]
[COMP] The identified Koopman operator is STABLE
------ ------ -----
----- Run Info ----
------ ------ -----
                                  0           1           2           3
x_hidden_variable_list            6           6           6           3
activation flag                   2           2           2           2
activation function             elu         elu         elu         elu
no of epochs                   1000        1000        1000        1000
batch size                      400         400         400         400
step size                       0.5         0.5         0.5         0.5
training error            0.0016673   0.0016673   0.0016673   0.0016673
validation error         0.00183672  0.00183672  0.00183672  0.00183672
r^2 training accuracy       96.1473     96.1473     96.1473     96.1473
r^2 validation accuracy     96.0025     96.0025     96.0025     96.0025
MSE training              0.0016673   0.0016673   0.0016673   0.0016673
MSE validation           0.00183672  0.00183672  0.00183672  0.00183672
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
                                   0            1            2            3
x_hidden_variable_list             6            6            6            3
activation flag                    2            2            2            2
activation function              elu          elu          elu          elu
no of epochs                   10000        10000        10000        10000
batch size                       400          400          400          400
step size                        0.3          0.3          0.3          0.3
training error           0.000909974  0.000909974  0.000909974  0.000909974
validation error          0.00109955   0.00109955   0.00109955   0.00109955
r^2 training accuracy        98.2553      98.2553      98.2553      98.2553
r^2 validation accuracy      97.8387      97.8387      97.8387      97.8387
MSE training             0.000909974  0.000909974  0.000909974  0.000909974
MSE validation            0.00109955   0.00109955   0.00109955   0.00109955
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
                                   0            1            2            3
x_hidden_variable_list             6            6            6            3
activation flag                    2            2            2            2
activation function              elu          elu          elu          elu
no of epochs                   10000        10000        10000        10000
batch size                       400          400          400          400
step size                        0.1          0.1          0.1          0.1
training error           0.000727924  0.000727924  0.000727924  0.000727924
validation error         0.000921973  0.000921973  0.000921973  0.000921973
r^2 training accuracy        98.6366      98.6366      98.6366      98.6366
r^2 validation accuracy      98.3314      98.3314      98.3314      98.3314
MSE training             0.000727924  0.000727924  0.000727924  0.000727924
MSE validation           0.000921973  0.000921973  0.000921973  0.000921973
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
                                   0            1            2            3
x_hidden_variable_list             6            6            6            3
activation flag                    2            2            2            2
activation function              elu          elu          elu          elu
no of epochs                   10000        10000        10000        10000
batch size                       400          400          400          400
step size                       0.09         0.09         0.09         0.09
training error           0.000669246  0.000669246  0.000669246  0.000669246
validation error         0.000850606  0.000850606  0.000850606  0.000850606
r^2 training accuracy        98.3683      98.3683      98.3683      98.3683
r^2 validation accuracy      98.2581      98.2581      98.2581      98.2581
MSE training             0.000669246  0.000669246  0.000669246  0.000669246
MSE validation           0.000850606  0.000850606  0.000850606  0.000850606
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
                                   0            1            2            3
x_hidden_variable_list             6            6            6            3
activation flag                    2            2            2            2
activation function              elu          elu          elu          elu
no of epochs                   10000        10000        10000        10000
batch size                       400          400          400          400
step size                       0.08         0.08         0.08         0.08
training error           0.000627931  0.000627931  0.000627931  0.000627931
validation error         0.000797922  0.000797922  0.000797922  0.000797922
r^2 training accuracy        98.2202      98.2202      98.2202      98.2202
r^2 validation accuracy      98.1114      98.1114      98.1114      98.1114
MSE training             0.000627931  0.000627931  0.000627931  0.000627931
MSE validation           0.000797922  0.000797922  0.000797922  0.000797922
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
