[INFO] Number of total samples: 19800
[INFO] Observable dimension of a sample: 7
[INFO] Xp.shape (E-DMD): (19800, 7)
[INFO] Yf.shape (E-DMD): (19800, 7)
Number of training snapshots: 9900
Number of validation snapshots: 9900
53
0.39735970711951313
0.3535533905932738
0.4472135954999579
0.30151134457776363
2.0918722
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.5
Train Error Threshold      :  1e-06
Validation Error Threshold :  1e-06
Maximum number of Epochs   :  10000
Batch Size   :  500
--------------------------------------
Epoch No:  1000  |   Training error:  7.012878e-05
                   Validation error:  8.2749095e-05
---------------------------------------------------------------------------------------------------
Epoch No:  2000  |   Training error:  3.6888363e-05
                   Validation error:  4.4322882e-05
---------------------------------------------------------------------------------------------------
Epoch No:  3000  |   Training error:  2.5830863e-05
                   Validation error:  3.1321328e-05
---------------------------------------------------------------------------------------------------
Epoch No:  4000  |   Training error:  1.9022522e-05
                   Validation error:  2.3498364e-05
---------------------------------------------------------------------------------------------------
Epoch No:  5000  |   Training error:  1.5557649e-05
                   Validation error:  1.9412551e-05
---------------------------------------------------------------------------------------------------
Epoch No:  6000  |   Training error:  1.6743998e-05
                   Validation error:  2.0154304e-05
---------------------------------------------------------------------------------------------------
Epoch No:  7000  |   Training error:  1.1706549e-05
                   Validation error:  1.4886066e-05
---------------------------------------------------------------------------------------------------
Epoch No:  8000  |   Training error:  1.2152004e-05
                   Validation error:  1.5136488e-05
---------------------------------------------------------------------------------------------------
Epoch No:  9000  |   Training error:  1.030877e-05
                   Validation error:  1.3073806e-05
---------------------------------------------------------------------------------------------------
Epoch No:  10000  |   Training error:  1.641759e-05
                    Validation error:  1.9161129e-05
---------------------------------------------------------------------------------------------------
Current Training Error  : 1.641759e-05
Current Validation Error      : 1.9161129e-05
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.3
Train Error Threshold      :  1e-06
Validation Error Threshold :  1e-06
Maximum number of Epochs   :  10000
Batch Size   :  500
--------------------------------------
Epoch No:  1000  |   Training error:  8.44916e-06
                   Validation error:  1.09196135e-05
---------------------------------------------------------------------------------------------------
Epoch No:  2000  |   Training error:  8.145477e-06
                   Validation error:  1.04830515e-05
---------------------------------------------------------------------------------------------------
Epoch No:  3000  |   Training error:  7.772258e-06
                   Validation error:  1.00424095e-05
---------------------------------------------------------------------------------------------------
Epoch No:  4000  |   Training error:  7.448654e-06
                   Validation error:  9.628742e-06
---------------------------------------------------------------------------------------------------
Epoch No:  5000  |   Training error:  7.24896e-06
                   Validation error:  9.324426e-06
---------------------------------------------------------------------------------------------------
Epoch No:  6000  |   Training error:  6.92438e-06
                   Validation error:  8.9217965e-06
---------------------------------------------------------------------------------------------------
Epoch No:  7000  |   Training error:  6.772424e-06
                   Validation error:  8.67766e-06
---------------------------------------------------------------------------------------------------
Epoch No:  8000  |   Training error:  6.5344852e-06
                   Validation error:  8.377606e-06
---------------------------------------------------------------------------------------------------
Epoch No:  9000  |   Training error:  6.2928543e-06
                   Validation error:  8.0767895e-06
---------------------------------------------------------------------------------------------------
Epoch No:  10000  |   Training error:  6.138702e-06
                    Validation error:  7.857961e-06
---------------------------------------------------------------------------------------------------
Current Training Error  : 6.138702e-06
Current Validation Error      : 7.857961e-06
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.1
Train Error Threshold      :  1e-07
Validation Error Threshold :  1e-07
Maximum number of Epochs   :  10000
Batch Size   :  500
--------------------------------------
Epoch No:  1000  |   Training error:  6.052066e-06
                   Validation error:  7.76386e-06
---------------------------------------------------------------------------------------------------
Epoch No:  2000  |   Training error:  5.997682e-06
                   Validation error:  7.692518e-06
---------------------------------------------------------------------------------------------------
Epoch No:  3000  |   Training error:  5.9564027e-06
                   Validation error:  7.623061e-06
---------------------------------------------------------------------------------------------------
Epoch No:  4000  |   Training error:  5.891409e-06
                   Validation error:  7.5431117e-06
---------------------------------------------------------------------------------------------------
Epoch No:  5000  |   Training error:  5.8411124e-06
                   Validation error:  7.4748446e-06
---------------------------------------------------------------------------------------------------
Epoch No:  6000  |   Training error:  5.7973316e-06
                   Validation error:  7.4100376e-06
---------------------------------------------------------------------------------------------------
Epoch No:  7000  |   Training error:  5.7443312e-06
                   Validation error:  7.347101e-06
---------------------------------------------------------------------------------------------------
Epoch No:  8000  |   Training error:  5.6953245e-06
                   Validation error:  7.281155e-06
---------------------------------------------------------------------------------------------------
Epoch No:  9000  |   Training error:  5.648728e-06
                   Validation error:  7.215255e-06
---------------------------------------------------------------------------------------------------
Epoch No:  10000  |   Training error:  5.6018002e-06
                    Validation error:  7.1517757e-06
---------------------------------------------------------------------------------------------------
Current Training Error  : 5.6018002e-06
Current Validation Error      : 7.1517757e-06
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.05
Train Error Threshold      :  1e-08
Validation Error Threshold :  1e-08
Maximum number of Epochs   :  10000
Batch Size   :  500
--------------------------------------
Epoch No:  1000  |   Training error:  5.577598e-06
                   Validation error:  7.116888e-06
---------------------------------------------------------------------------------------------------
Epoch No:  2000  |   Training error:  5.5595365e-06
                   Validation error:  7.0872948e-06
---------------------------------------------------------------------------------------------------
Epoch No:  3000  |   Training error:  5.5359214e-06
                   Validation error:  7.055656e-06
---------------------------------------------------------------------------------------------------
Epoch No:  4000  |   Training error:  5.513745e-06
                   Validation error:  7.0284004e-06
---------------------------------------------------------------------------------------------------
Epoch No:  5000  |   Training error:  5.4910965e-06
                   Validation error:  7.0013543e-06
---------------------------------------------------------------------------------------------------
Epoch No:  6000  |   Training error:  5.4684265e-06
                   Validation error:  6.9702983e-06
---------------------------------------------------------------------------------------------------
Epoch No:  7000  |   Training error:  5.44878e-06
                   Validation error:  6.9446123e-06
---------------------------------------------------------------------------------------------------
Epoch No:  8000  |   Training error:  5.426439e-06
                   Validation error:  6.910618e-06
---------------------------------------------------------------------------------------------------
Epoch No:  9000  |   Training error:  5.4079187e-06
                   Validation error:  6.8890627e-06
---------------------------------------------------------------------------------------------------
Epoch No:  10000  |   Training error:  5.385579e-06
                    Validation error:  6.8568324e-06
---------------------------------------------------------------------------------------------------
Current Training Error  : 5.385579e-06
Current Validation Error      : 6.8568324e-06
5.385579e-06
---   OUTPUT COMPENSATED STATE TRAINING COMPLETE   ---
                                   0            1            2            3
MSE training             1.64176e-05   6.1387e-06   5.6018e-06  5.38558e-06
MSE validation           1.91611e-05  7.85796e-06  7.15178e-06  6.85683e-06
activation flag                    2            2            2            2
activation function              elu          elu          elu          elu
batch size                       500          500          500          500
no of epochs                   10000        10000        10000        10000
r^2 training accuracy        99.9437      99.9743      99.9789      99.9807
r^2 validation accuracy      99.9238      99.9658      99.9722      99.9746
step size                        0.5          0.3          0.1         0.05
training error           1.64176e-05   6.1387e-06   5.6018e-06  5.38558e-06
validation error         1.91611e-05  7.85796e-06  7.15178e-06  6.85683e-06
x_hidden_variable_list   [12, 12, 3]  [12, 12, 3]  [12, 12, 3]  [12, 12, 3]
[[ 7.13289320e-01  3.73343855e-01  2.61047184e-01  2.80228227e-01
   3.29394072e-01 -2.77355403e-01  3.89565974e-02  1.40307397e-02
   4.45115380e-02  1.28610479e-02 -3.38329524e-02  4.30197380e-02
   1.26113677e-02  4.02629040e-02  1.09166428e-02 -3.98590341e-02
  -3.65076773e-03  2.83834990e-02  1.63800213e-02 -2.28001699e-02
  -1.92249175e-02  4.97753210e-02 -1.43624255e-02  3.00348569e-02
   0.00000000e+00 -2.87056472e-02 -1.78361200e-02 -3.84160541e-02
   2.34709196e-02]
 [ 1.93109617e-01  3.67725104e-01  6.58195078e-01  3.02011371e-01
   2.77236789e-01  4.54962015e-01  6.08768612e-02 -5.62104657e-02
  -2.31661126e-02 -3.01321428e-02  5.60246594e-03  4.09880839e-02
   1.46681396e-02 -2.31029857e-02  1.01702707e-02  7.44178370e-02
  -2.02806871e-02 -1.03404671e-02  4.14457768e-02  2.27482654e-02
  -2.46594343e-02 -7.01413751e-02  4.33857702e-02 -4.41123871e-03
   0.00000000e+00 -3.73839922e-02  6.99975109e-03  8.25316366e-03
   1.86402183e-02]
 [-9.22858343e-02  2.06039146e-01  7.90167809e-01 -3.72381471e-02
  -1.02051869e-01 -1.33791789e-01 -9.22475127e-04 -9.92832240e-03
  -3.27173471e-02  1.76530909e-02 -3.11729405e-02  5.68372905e-02
  -9.38196760e-03  2.85996888e-02  2.39323927e-04 -6.00883216e-02
   4.70101610e-02  8.90701860e-02  2.17114482e-02 -7.26794377e-02
  -7.24131018e-02  3.79388221e-02 -4.71005253e-02  2.01506522e-02
   0.00000000e+00  4.34833989e-02 -1.41150495e-02 -6.68910071e-02
  -7.12233654e-04]
 [-1.24740645e-01  2.79368550e-01 -1.46106392e-01  3.42293888e-01
  -2.40135536e-01 -1.83513418e-01  1.57349974e-01 -1.98405492e-03
  -2.00012848e-02 -3.86125669e-02  3.92935239e-03 -1.37650520e-01
  -2.12065019e-02 -4.74513806e-02  3.40570845e-02  3.44708352e-03
   3.65303755e-02 -2.60229427e-02 -1.50788920e-02  1.48838600e-02
   3.64389131e-03 -4.26955596e-02  2.23035589e-02 -5.71039086e-03
   0.00000000e+00  1.23023130e-01 -4.69400100e-02  2.50392240e-02
  -3.98847535e-02]
 [-1.95166841e-01  2.92690217e-01 -9.95034259e-03  6.45796433e-02
   4.35161382e-01 -2.41682827e-01 -7.83892628e-03  2.08858922e-02
   5.01177786e-03  1.72372013e-02  8.58332962e-03  2.56685466e-02
   7.87891820e-03  8.85870773e-03  6.34337636e-03  3.17285396e-02
  -1.28408438e-02  6.09520823e-03 -5.63988136e-03  2.37052627e-02
  -2.63873488e-02  2.06130352e-02  1.64066665e-02 -2.86629554e-02
   0.00000000e+00 -1.01296507e-01  2.03982275e-02  1.62991807e-02
  -5.97730651e-03]
 [-4.82665263e-02  1.14238806e-01  6.71327710e-01 -3.06347340e-01
   1.91544726e-01  7.13121533e-01 -6.94709942e-02 -4.33368944e-02
  -4.04188670e-02  1.10429544e-02  4.00294475e-02  1.11723647e-01
   1.67480838e-02 -2.18718648e-02 -1.99551415e-02  9.80339274e-02
  -4.39100079e-02 -5.23174554e-02  3.52546871e-02  3.30079719e-02
  -7.31121469e-03 -6.26808628e-02  2.19459031e-02 -1.87828448e-02
   0.00000000e+00  6.33340850e-02 -3.45830992e-02  4.19178754e-02
  -2.88041942e-02]
 [-7.77555332e-02  7.89411217e-02  1.22022502e-01  2.05136389e-01
   4.00773361e-02 -6.48133084e-02  8.88719976e-01  2.24004779e-02
   2.27424670e-02  2.78670564e-02 -2.97146407e-03  4.13332880e-02
   7.27075757e-03  2.61369646e-02 -1.37068266e-02 -1.25004929e-02
  -1.97341032e-02  1.32138934e-02 -7.53738126e-03 -9.77981370e-03
  -3.97462136e-04  3.76621336e-02 -1.59141887e-02  5.95838204e-03
   0.00000000e+00  8.83339122e-02 -2.64734495e-02 -3.24001238e-02
   1.37051344e-02]
 [-2.76837293e-02 -6.01973943e-02  3.02930266e-01 -4.88353401e-01
  -2.47776248e-02 -3.59240890e-01 -8.97331610e-02  6.53241158e-01
  -2.38840953e-01  4.33583677e-01  1.78104624e-01  9.67249215e-01
  -3.06027710e-01  1.96709916e-01 -4.95750666e-01 -7.20763579e-02
  -9.27593336e-02 -1.39438406e-01 -1.58731803e-01  1.83103815e-01
   7.03317346e-03  4.54063714e-01 -3.79591376e-01  5.63138500e-02
   0.00000000e+00 -1.93825662e-01  4.39647049e-01  2.28622973e-01
  -3.17363709e-01]
 [-1.86216403e-02  6.06528878e-01 -7.64283895e-01 -1.04591238e+00
   3.24215412e-01 -6.53479993e-01 -1.35834605e-01 -1.17840610e-01
   2.84201384e-01  7.51786977e-02  6.13517351e-02  7.02314675e-01
   1.97371811e-01  1.30940408e-01 -2.09759846e-01 -1.20307967e-01
  -6.70270100e-02  1.60679877e-01  4.11358684e-01 -4.00008112e-01
   9.34786126e-02  7.09203184e-02 -2.34455779e-01 -7.78520256e-02
   0.00000000e+00  6.27859950e-01 -1.31622270e-01 -1.80265624e-02
  -8.61651897e-02]
 [-3.52437675e-01  3.86207521e-01 -3.53227764e-01  6.25606894e-01
  -3.94049734e-01 -2.18030319e-01 -1.16570219e-02  1.19763121e-01
   4.55048710e-01  9.18986738e-01  2.87670046e-01  1.00997341e+00
  -4.40174863e-02  3.96209240e-01 -2.14814574e-01  2.46316791e-01
  -6.58010900e-01 -1.02964029e-01  8.49665552e-02 -6.40487447e-02
  -3.77993621e-02  3.85982096e-01 -1.35956571e-01 -3.90043668e-02
   0.00000000e+00 -3.33102554e-01  2.54294276e-01  2.19384819e-01
   2.26979807e-01]
 [ 1.98431268e-01 -2.17020661e-01  6.16759360e-02  4.79672402e-01
  -6.46810651e-01  2.89455235e-01  5.33287935e-02 -2.45745018e-01
  -8.26632679e-02 -2.23024294e-01  2.02173173e-01  2.14622319e-01
  -2.30009966e-02  2.00093061e-01 -1.83915526e-01  9.79050547e-02
  -1.59670547e-01 -2.50197351e-01  2.60864869e-02  2.65710264e-01
   3.50765616e-01 -5.05275488e-01 -1.10899754e-01 -1.56842858e-01
   0.00000000e+00 -2.91288018e-01  1.75622597e-01  2.37185240e-01
  -2.03534052e-01]
 [-2.34606743e+00  3.66609025e+00  1.01527143e+00  1.37611353e+00
   1.33010888e+00 -2.81962276e+00  1.40193790e-01  1.74888875e-02
  -1.20252639e-01 -2.95096096e-02  1.03572689e-01 -5.54252565e-01
  -1.28157035e-01 -3.20992589e-01  7.42723607e-03 -5.30753247e-02
   2.18049720e-01 -3.05375487e-01 -3.40914637e-01  6.88345432e-02
   2.41448775e-01 -1.34531453e-01  4.91720065e-02 -5.89059815e-02
   0.00000000e+00 -1.91908956e-01 -2.29133695e-01 -1.59743398e-01
   9.55896005e-02]
 [-2.84012944e-01  4.11545128e-01 -4.22416419e-01  6.18948460e-01
   1.64187834e-01 -1.02636807e-01  6.80548400e-02 -2.12675735e-01
   8.97616893e-02 -1.15692362e-01 -9.34478547e-03  8.39457884e-02
   5.60078144e-01  6.98673278e-02 -2.15905920e-01  4.71831292e-01
   2.51080871e-01  1.87263712e-01  2.23312095e-01  1.64937764e-01
   1.66219264e-01 -4.73814463e-04 -4.69454154e-02 -3.28634918e-01
   0.00000000e+00  2.32427597e-01  6.43615648e-02  9.92498323e-02
   1.06356293e-01]
 [-4.69279349e-01  1.00907457e+00 -1.19666327e-02 -7.78246343e-01
   3.96427900e-01 -1.09618533e+00 -1.79820195e-01 -1.87981620e-01
  -1.23330221e-01  3.92278731e-02 -4.11245935e-02  3.96158308e-01
   1.27834663e-01  4.05650675e-01  1.63787842e-01  3.22909266e-01
  -1.47636890e-01  2.23957617e-02  5.41918337e-01 -1.06467893e-02
  -2.76101917e-01  2.03080937e-01  2.07336828e-01 -1.33684635e-01
   0.00000000e+00 -1.58834547e-01 -3.45347166e-01 -5.28275549e-01
  -1.40502602e-01]
 [ 2.44223967e-01 -1.46126062e-01 -5.82514144e-03 -1.93700194e-01
   6.45281792e-01  3.40322167e-01  3.51928989e-03 -7.52807930e-02
   4.76154722e-02  2.20514789e-01  1.08722903e-01 -2.34675035e-01
   1.50339780e-02 -5.96488900e-02  5.98970413e-01  8.51033255e-02
  -5.14329016e-01 -7.77474463e-01 -5.51950336e-01 -9.96820927e-02
   5.03619075e-01 -3.73273015e-01 -9.25351381e-02  1.96972534e-01
   0.00000000e+00 -4.43033278e-01  6.03965700e-01  4.02352184e-01
   2.05425516e-01]
 [-8.86008367e-02 -2.79116333e-01 -1.30350685e+00  1.37081170e+00
   3.23335737e-01  2.83665538e-01  2.59152591e-01  7.12307841e-02
   1.05976425e-01  9.90995765e-03 -3.04800063e-01 -3.09428930e-01
   9.74656567e-02  2.62361336e-02  9.26545113e-02  4.83126640e-01
  -1.13159917e-01  2.15171173e-01 -2.62003005e-01  4.60583270e-01
  -1.00500427e-01  4.22514677e-01  2.61414051e-01 -2.27794006e-01
   0.00000000e+00 -3.14913005e-01  3.35742980e-02 -4.90277082e-01
  -3.87660265e-01]
 [ 3.34300667e-01 -6.09860897e-01  7.61046767e-01 -5.31695127e-01
   2.11241618e-01  2.64591455e-01 -1.42141938e-01  1.83326438e-01
   3.56072307e-01  9.39408764e-02  3.40859592e-02 -8.65631580e-01
  -1.39240384e-01 -3.17291655e-02 -2.78522432e-01  8.41266140e-02
   4.84276503e-01  1.27151504e-01 -4.17168230e-01  4.22793657e-01
   3.13954115e-01  5.54675400e-01  8.77976492e-02 -3.76722306e-01
   0.00000000e+00 -1.42093420e-01 -3.95354241e-01 -1.28267929e-01
  -2.30845630e-01]
 [ 1.03904106e-01 -7.82205686e-02  5.30338526e-01  3.37620415e-02
   1.34445775e+00  1.76163375e-01 -8.04903044e-04 -1.72530696e-01
  -5.04191183e-02 -2.53042847e-01 -3.27733040e-01  1.13789058e+00
  -1.02966063e-01  4.20443445e-01  1.05929799e-01 -5.76910712e-02
  -4.00572978e-02  9.74528611e-01  4.22505915e-01 -4.32783132e-03
  -5.49949944e-01 -1.66207384e-02  2.69581135e-02 -3.28162313e-02
   0.00000000e+00  8.48511308e-02  1.36218041e-01  7.47739971e-02
  -6.17430918e-02]
 [-6.33019507e-01  9.64422107e-01  7.20613420e-01  4.87790585e-01
   5.61818123e-01 -9.49220359e-01 -7.33095221e-03  3.08739976e-03
   3.45885381e-02 -2.92679310e-01  5.49236722e-02 -1.58067286e+00
  -5.64185977e-01 -6.24839030e-02  5.02478816e-02 -2.05849499e-01
   3.98433477e-01  3.03835515e-02 -1.57491878e-01  1.64530918e-01
   1.03113227e-01 -4.41858411e-01 -5.07327989e-02  1.61370933e-01
   0.00000000e+00  1.79753006e-01  4.02202576e-01  2.85528123e-01
  -1.21680424e-01]
 [ 1.63793012e-01  3.84420693e-01 -9.23002601e-01 -4.24853116e-01
   9.57996957e-03 -7.94681981e-02 -5.12723960e-02  3.46089572e-01
  -7.94170722e-02  1.65796594e-03  9.97241884e-02 -4.46157426e-01
  -3.72450739e-01 -7.77749345e-02  6.84980229e-02  1.43399417e-01
  -6.77271709e-02  1.58521324e-01 -2.49249682e-01  4.42756653e-01
  -6.24094978e-02  1.73068181e-01  9.50552598e-02 -3.12800765e-01
   0.00000000e+00  2.01676190e-01 -4.87546101e-02  2.70934440e-02
   2.44486392e-01]
 [ 9.49787423e-02  3.27275813e-01 -7.62960374e-01 -9.41822827e-01
  -1.13863134e+00 -1.52624771e-01 -1.91889212e-01 -2.36335218e-01
  -5.36739593e-04 -3.46745759e-01 -3.83832663e-01  1.32687703e-01
  -1.61131054e-01  1.79538772e-01  9.61268842e-02 -2.43919671e-01
   1.73896536e-01  2.86319613e-01  7.99543187e-02  9.05171707e-02
   2.41472945e-01 -9.71607417e-02 -5.21104746e-02 -1.13772854e-01
   0.00000000e+00 -2.30286106e-01  2.23528016e-02 -3.16711336e-01
  -2.78668910e-01]
 [-1.48384720e-01  8.40216041e-01  8.14311206e-02 -3.56677413e-01
   3.72830659e-01 -6.55593276e-01 -5.18604852e-02  3.82429630e-01
   1.11071505e-01  3.45576018e-01 -2.96068817e-01  1.04643607e+00
   5.57686746e-01  1.99709371e-01  7.02491477e-02 -3.07799429e-01
  -1.74619794e-01  3.62960815e-01 -1.27725393e-01 -2.51845419e-01
  -4.90046859e-01  6.84905231e-01 -3.74498218e-01 -2.93752879e-01
   0.00000000e+00  1.80790082e-01 -4.07664061e-01  2.55572703e-02
  -9.69395116e-02]
 [ 2.05739051e-01 -1.85406432e-01 -7.43817806e-01 -2.61828065e-01
   5.88756561e-01  1.92224413e-01 -1.06305555e-01  1.22976921e-01
   1.84593737e-01 -1.13222457e-01  3.37211072e-01 -2.64297128e-01
  -1.88986644e-01 -2.77196974e-01 -1.54705942e-01 -1.35141551e-01
   2.93872446e-01 -3.67903739e-01 -1.02269895e-01  3.18091363e-01
  -1.10484543e-03 -3.36156577e-01  3.90682399e-01  1.66710895e-02
   0.00000000e+00  4.10233706e-01 -5.66432893e-01  3.44953835e-01
  -1.21183082e-01]
 [ 2.22504929e-01  2.79471308e-01 -2.44927034e-01 -7.87486374e-01
  -2.40717769e-01 -4.95657176e-01 -1.99068561e-01 -2.35201865e-01
  -3.58577847e-01  3.34802293e-03  1.69194922e-01  1.27992377e-01
   2.31655702e-01 -1.90302670e-01 -4.79258522e-02  6.07479572e-01
  -2.66284436e-01 -5.46456695e-01 -2.07225159e-01  4.94752109e-01
  -7.24124610e-02 -6.36079848e-01  2.67731577e-01  3.82107943e-01
   0.00000000e+00 -1.96335942e-01  3.91144723e-01  4.77913469e-01
  -2.99111336e-01]
 [-2.12985441e-01  3.27675313e-01  1.57453373e-01  1.54371513e-02
  -1.64621405e-03 -1.07215360e-01  2.25984026e-03 -2.57310681e-02
   1.13332927e-01 -2.96456050e-02  5.85088618e-02 -2.21648440e-01
  -1.16898872e-01  7.11651370e-02 -3.19709703e-02  2.22508106e-02
   5.02869347e-03 -2.31752824e-02 -2.78502069e-02 -4.54650596e-02
  -8.50452110e-02  7.59858787e-02  5.07518798e-02  2.44378597e-02
   1.00000000e+00 -3.65313053e-01 -3.31592374e-02 -3.23939994e-02
   2.73706555e-01]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  6.24923289e-01  3.86739001e-02  3.17322537e-02
  -8.72240216e-03]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00 -6.28304780e-01  5.35172462e-01 -4.73228306e-01
  -5.51177450e-02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00 -1.18209374e+00  2.31571302e-01  1.17445481e+00
   1.09916795e-02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00 -8.57633874e-02  8.67069885e-02 -8.90131295e-02
   8.01992834e-01]]
Eigen values: 
[1.         0.409193   0.41475891 0.41475891 0.79220705 0.79220705
 0.10168105 0.04362656 0.11700733 0.21165516 0.21165516 0.78168427
 0.78168427 0.96260791 0.96260791 0.78060905 0.78060905 0.46917254
 0.99832468 0.99832468 0.84547066 0.84547066 0.82519872 0.97288652
 0.90760348 0.72936495 0.72936495 0.89641927 0.89641927]
[COMP] The identified Koopman operator is STABLE
------ ------ -----
----- Run Info ----
------ ------ -----
                                   0            1            2
x_hidden_variable_list            12           12            3
activation flag                    2            2            2
activation function              elu          elu          elu
no of epochs                   10000        10000        10000
batch size                       500          500          500
step size                        0.5          0.5          0.5
training error           1.64176e-05  1.64176e-05  1.64176e-05
validation error         1.91611e-05  1.91611e-05  1.91611e-05
r^2 training accuracy        99.9437      99.9437      99.9437
r^2 validation accuracy      99.9238      99.9238      99.9238
MSE training             1.64176e-05  1.64176e-05  1.64176e-05
MSE validation           1.91611e-05  1.91611e-05  1.91611e-05
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
                                   0            1            2
x_hidden_variable_list            12           12            3
activation flag                    2            2            2
activation function              elu          elu          elu
no of epochs                   10000        10000        10000
batch size                       500          500          500
step size                        0.3          0.3          0.3
training error            6.1387e-06   6.1387e-06   6.1387e-06
validation error         7.85796e-06  7.85796e-06  7.85796e-06
r^2 training accuracy        99.9743      99.9743      99.9743
r^2 validation accuracy      99.9658      99.9658      99.9658
MSE training              6.1387e-06   6.1387e-06   6.1387e-06
MSE validation           7.85796e-06  7.85796e-06  7.85796e-06
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
                                   0            1            2
x_hidden_variable_list            12           12            3
activation flag                    2            2            2
activation function              elu          elu          elu
no of epochs                   10000        10000        10000
batch size                       500          500          500
step size                        0.1          0.1          0.1
training error            5.6018e-06   5.6018e-06   5.6018e-06
validation error         7.15178e-06  7.15178e-06  7.15178e-06
r^2 training accuracy        99.9789      99.9789      99.9789
r^2 validation accuracy      99.9722      99.9722      99.9722
MSE training              5.6018e-06   5.6018e-06   5.6018e-06
MSE validation           7.15178e-06  7.15178e-06  7.15178e-06
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
                                   0            1            2
x_hidden_variable_list            12           12            3
activation flag                    2            2            2
activation function              elu          elu          elu
no of epochs                   10000        10000        10000
batch size                       500          500          500
step size                       0.05         0.05         0.05
training error           5.38558e-06  5.38558e-06  5.38558e-06
validation error         6.85683e-06  6.85683e-06  6.85683e-06
r^2 training accuracy        99.9807      99.9807      99.9807
r^2 validation accuracy      99.9746      99.9746      99.9746
MSE training             5.38558e-06  5.38558e-06  5.38558e-06
MSE validation           6.85683e-06  6.85683e-06  6.85683e-06
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
