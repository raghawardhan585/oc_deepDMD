[INFO] Number of total samples: 4600
[INFO] Observable dimension of a sample: 7
[INFO] Xp.shape (E-DMD): (4600, 7)
[INFO] Yf.shape (E-DMD): (4600, 7)
Number of training snapshots: 2300
Number of validation snapshots: 2300
70
0.4803844614152614
0.5
0.5477225575051661
0.2773500981126146
1.9066464
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.5
Train Error Threshold      :  1e-06
Validation Error Threshold :  1e-06
Maximum number of Epochs   :  1000
Batch Size   :  400
--------------------------------------
Epoch No:  1000  |   Training error:  0.0017750274
                   Validation error:  0.0019308605
---------------------------------------------------------------------------------------------------
Current Training Error  : 0.0017750274
Current Validation Error      : 0.0019308605
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.3
Train Error Threshold      :  1e-06
Validation Error Threshold :  1e-06
Maximum number of Epochs   :  10000
Batch Size   :  400
--------------------------------------
Epoch No:  1000  |   Training error:  0.001372057
                   Validation error:  0.0015285915
---------------------------------------------------------------------------------------------------
Epoch No:  2000  |   Training error:  0.0012092949
                   Validation error:  0.0013585804
---------------------------------------------------------------------------------------------------
Epoch No:  3000  |   Training error:  0.0011496579
                   Validation error:  0.0012924073
---------------------------------------------------------------------------------------------------
Epoch No:  4000  |   Training error:  0.001075032
                   Validation error:  0.0012243026
---------------------------------------------------------------------------------------------------
Epoch No:  5000  |   Training error:  0.0010153003
                   Validation error:  0.0011598552
---------------------------------------------------------------------------------------------------
Epoch No:  6000  |   Training error:  0.0009839246
                   Validation error:  0.0011289405
---------------------------------------------------------------------------------------------------
Epoch No:  7000  |   Training error:  0.00096009875
                   Validation error:  0.0011000683
---------------------------------------------------------------------------------------------------
Epoch No:  8000  |   Training error:  0.00092944526
                   Validation error:  0.0010744538
---------------------------------------------------------------------------------------------------
Epoch No:  9000  |   Training error:  0.000899
                   Validation error:  0.0010394076
---------------------------------------------------------------------------------------------------
Epoch No:  10000  |   Training error:  0.0009289303
                    Validation error:  0.0010687193
---------------------------------------------------------------------------------------------------
Current Training Error  : 0.0009289303
Current Validation Error      : 0.0010687193
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.1
Train Error Threshold      :  1e-07
Validation Error Threshold :  1e-07
Maximum number of Epochs   :  10000
Batch Size   :  400
--------------------------------------
Epoch No:  1000  |   Training error:  0.00086771086
                   Validation error:  0.0010068064
---------------------------------------------------------------------------------------------------
Epoch No:  2000  |   Training error:  0.0008617339
                   Validation error:  0.0010004328
---------------------------------------------------------------------------------------------------
Epoch No:  3000  |   Training error:  0.00085566874
                   Validation error:  0.0009919668
---------------------------------------------------------------------------------------------------
Epoch No:  4000  |   Training error:  0.0008470556
                   Validation error:  0.000983427
---------------------------------------------------------------------------------------------------
Epoch No:  5000  |   Training error:  0.0008414612
                   Validation error:  0.0009773419
---------------------------------------------------------------------------------------------------
Epoch No:  6000  |   Training error:  0.00083811814
                   Validation error:  0.000972609
---------------------------------------------------------------------------------------------------
Epoch No:  7000  |   Training error:  0.0008295594
                   Validation error:  0.0009647726
---------------------------------------------------------------------------------------------------
Epoch No:  8000  |   Training error:  0.00082419603
                   Validation error:  0.00095838495
---------------------------------------------------------------------------------------------------
Epoch No:  9000  |   Training error:  0.0008186634
                   Validation error:  0.0009523987
---------------------------------------------------------------------------------------------------
Epoch No:  10000  |   Training error:  0.0008129793
                    Validation error:  0.0009456674
---------------------------------------------------------------------------------------------------
Current Training Error  : 0.0008129793
Current Validation Error      : 0.0009456674
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.09
Train Error Threshold      :  1e-08
Validation Error Threshold :  1e-08
Maximum number of Epochs   :  10000
Batch Size   :  400
--------------------------------------
Epoch No:  1000  |   Training error:  0.0008093064
                   Validation error:  0.0009410627
---------------------------------------------------------------------------------------------------
Epoch No:  2000  |   Training error:  0.00080511766
                   Validation error:  0.00093671674
---------------------------------------------------------------------------------------------------
Epoch No:  3000  |   Training error:  0.00079944107
                   Validation error:  0.0009293099
---------------------------------------------------------------------------------------------------
Epoch No:  4000  |   Training error:  0.0007977582
                   Validation error:  0.0009271404
---------------------------------------------------------------------------------------------------
Epoch No:  5000  |   Training error:  0.0007942268
                   Validation error:  0.0009217444
---------------------------------------------------------------------------------------------------
Epoch No:  6000  |   Training error:  0.000785943
                   Validation error:  0.0009145125
---------------------------------------------------------------------------------------------------
Epoch No:  7000  |   Training error:  0.00078195945
                   Validation error:  0.00090976374
---------------------------------------------------------------------------------------------------
Epoch No:  8000  |   Training error:  0.0007768819
                   Validation error:  0.0009049202
---------------------------------------------------------------------------------------------------
Epoch No:  9000  |   Training error:  0.0007726907
                   Validation error:  0.00090061116
---------------------------------------------------------------------------------------------------
Epoch No:  10000  |   Training error:  0.0007690352
                    Validation error:  0.0008969624
---------------------------------------------------------------------------------------------------
Current Training Error  : 0.0007690352
Current Validation Error      : 0.0008969624
======================================
CURRENT TRAINING PARAMETERS
======================================
Step Size Value            :  0.08
Train Error Threshold      :  1e-08
Validation Error Threshold :  1e-08
Maximum number of Epochs   :  10000
Batch Size   :  400
--------------------------------------
Epoch No:  1000  |   Training error:  0.00076583907
                   Validation error:  0.0008930062
---------------------------------------------------------------------------------------------------
Epoch No:  2000  |   Training error:  0.0007643446
                   Validation error:  0.0008914756
---------------------------------------------------------------------------------------------------
Epoch No:  3000  |   Training error:  0.0007586808
                   Validation error:  0.00088633725
---------------------------------------------------------------------------------------------------
Epoch No:  4000  |   Training error:  0.00075593585
                   Validation error:  0.00088307506
---------------------------------------------------------------------------------------------------
Epoch No:  5000  |   Training error:  0.00075254624
                   Validation error:  0.00087989785
---------------------------------------------------------------------------------------------------
Epoch No:  6000  |   Training error:  0.00075134565
                   Validation error:  0.0008796536
---------------------------------------------------------------------------------------------------
Epoch No:  7000  |   Training error:  0.00074663677
                   Validation error:  0.00087353477
---------------------------------------------------------------------------------------------------
Epoch No:  8000  |   Training error:  0.0007450607
                   Validation error:  0.00087150926
---------------------------------------------------------------------------------------------------
Epoch No:  9000  |   Training error:  0.000742463
                   Validation error:  0.00086877414
---------------------------------------------------------------------------------------------------
Epoch No:  10000  |   Training error:  0.0007392341
                    Validation error:  0.00086561637
---------------------------------------------------------------------------------------------------
Current Training Error  : 0.0007392341
Current Validation Error      : 0.00086561637
0.0007392341
---   OUTPUT COMPENSATED STATE TRAINING COMPLETE   ---
                                  0           1  ...            3            4
x_hidden_variable_list    [6, 6, 4]   [6, 6, 4]  ...    [6, 6, 4]    [6, 6, 4]
activation flag                   2           2  ...            2            2
activation function             elu         elu  ...          elu          elu
no of epochs                   1000       10000  ...        10000        10000
batch size                      400         400  ...          400          400
step size                       0.5         0.3  ...         0.09         0.08
training error           0.00177503  0.00092893  ...  0.000769035  0.000739234
validation error         0.00193086  0.00106872  ...  0.000896962  0.000865616
r^2 training accuracy       95.6241      97.877  ...      98.3063      98.4183
r^2 validation accuracy     95.2524       97.52  ...      97.9745      98.0993
MSE training             0.00177503  0.00092893  ...  0.000769035  0.000739234
MSE validation           0.00193086  0.00106872  ...  0.000896962  0.000865616

[12 rows x 5 columns]
[[ 4.72021610e-01  3.38556647e-01  4.18689936e-01  5.00197947e-01
  -8.31248388e-02 -1.01515174e-01  3.24863672e-01 -1.07199080e-01
  -5.25555760e-02 -8.89151245e-02  1.40477065e-02 -4.08105925e-02
  -5.05048744e-02 -4.77822088e-02  3.71716097e-02 -4.54329997e-02
   1.43755116e-02 -4.80397791e-02  3.32842022e-02  6.11363053e-02
  -2.87101828e-02  1.82384923e-02  0.00000000e+00 -1.49299145e-01
   4.61705290e-02 -1.76596746e-01 -1.07463740e-01 -5.09553663e-02
   2.32708193e-02  5.56704886e-02  4.70659286e-02]
 [ 8.48779082e-01 -7.17963576e-01  4.39066291e-01 -4.07984763e-01
  -6.20698750e-01  1.23670173e+00  9.55862701e-02 -1.52714169e-02
  -2.87818648e-02 -6.84470981e-02  6.31697848e-02 -5.33242058e-03
   1.75399706e-02 -3.29068955e-03 -1.02510201e-02 -3.64312492e-02
  -8.67458135e-02  1.23510864e-02 -3.33768316e-02  6.75345659e-02
   1.99070331e-02  1.52588412e-01  0.00000000e+00  2.89828122e-01
   1.52048960e-01 -1.71821732e-02 -2.52596676e-01 -3.01688090e-02
   5.34560233e-02  5.35697502e-04 -2.13760063e-02]
 [-1.94961563e-01  1.55483186e-01  2.25668952e-01  4.12493140e-01
  -2.89172649e-01  5.04668131e-02  2.09587902e-01 -3.79245579e-02
   2.90083885e-02  1.40719330e-02 -9.05176252e-02 -1.37555199e-02
  -5.71453385e-02 -4.55610454e-03  6.52652234e-03 -2.30827183e-02
  -5.50810695e-02 -1.13127036e-02  7.05968589e-02 -5.37536992e-03
  -4.00860906e-02 -9.74392071e-02  0.00000000e+00  3.17734241e-01
  -3.77436192e-03 -1.92572534e-01  1.65584221e-01  2.24596336e-02
   1.52237248e-02 -5.36325900e-03 -7.49885058e-03]
 [ 1.42681122e-01  1.38099000e-01  8.26231465e-02 -2.26357430e-01
   2.51242518e-01 -2.18633577e-01 -5.43674342e-02 -1.85664743e-02
  -1.33187901e-02 -3.13937361e-03  4.41333950e-02 -3.78221180e-03
   1.29165230e-02 -2.42586769e-02  1.08600771e-02 -1.62226576e-02
   2.82936487e-02 -1.33429570e-02 -2.53299829e-02 -1.63266603e-02
   3.21783088e-02  4.04494070e-02  0.00000000e+00 -1.40461288e-02
   1.90083727e-01  1.74334031e-02 -5.03039844e-02  9.79805738e-03
  -1.56258028e-02 -1.32428817e-02 -4.56614420e-03]
 [-3.32499057e-01  2.28532419e-01  1.91549256e-01  2.63558447e-01
   1.80633068e-01 -9.07276496e-02  1.71841830e-01  1.72209516e-02
   1.33938745e-01  1.57564908e-01 -9.09818411e-02 -5.18622436e-02
  -6.73819110e-02  1.42334700e-01 -1.94332581e-02  4.73408625e-02
   1.58480048e-01  7.75364563e-02 -1.39649525e-01  3.54051404e-02
  -9.51924697e-02 -1.61421329e-01  0.00000000e+00 -4.74144489e-01
   2.09425054e-02  4.69411127e-02 -1.76304787e-01 -5.37359267e-02
   2.77602728e-02  5.10383882e-02 -1.36129779e-03]
 [ 7.42916584e-01 -5.83198488e-01  2.36311868e-01 -8.48347068e-01
  -2.93863863e-01  9.25468326e-01 -5.09513199e-01  4.33954410e-02
   7.95441493e-02  7.11459294e-02  1.27575779e-02 -1.26514174e-02
   2.74136700e-02  7.45158195e-02 -3.37066762e-02 -1.36511875e-02
  -2.17071385e-03  8.58126134e-02 -1.21233612e-01  3.20427865e-02
  -7.66631439e-02  3.27694453e-02  0.00000000e+00  5.90616390e-02
  -3.03115714e-02  1.76195167e-02  4.02087532e-02 -4.06837575e-02
   9.87558886e-02  2.19081100e-02  4.45701070e-02]
 [-3.14152181e-01  2.81061769e-01  2.43116930e-01  4.22723740e-01
  -1.06773570e-01 -1.62992939e-01  7.70393848e-01 -6.45077005e-02
   8.77915416e-03 -3.01323342e-03 -2.41301488e-02 -4.00016233e-02
  -2.90398877e-02 -9.98169184e-04  7.67876767e-03 -2.29442846e-02
  -2.15396704e-03 -2.02907324e-02  8.61994922e-03  6.58323690e-02
  -1.75015200e-02 -4.62848842e-02  0.00000000e+00 -6.00348301e-02
  -2.48717498e-02  7.86547959e-02  3.34199029e-03  7.10098975e-05
   6.88276207e-03 -2.07408704e-02  2.78707370e-02]
 [ 9.10587192e-01  8.89168978e-02 -1.71380925e+00 -5.12568235e-01
   6.78518340e-02 -4.41929698e-01 -9.30596709e-01 -3.02964635e-02
   2.90434062e-01  4.97242093e-01 -7.20400035e-01  1.38922380e-02
  -4.89886791e-01  3.62063706e-01  2.42087558e-01  2.55168200e-01
   1.15831215e-02  9.02870148e-02  2.27217302e-01 -1.47329539e-01
  -4.58247691e-01 -7.96424508e-01  0.00000000e+00 -2.21585655e+00
   7.05672145e-01  1.72981173e-01 -1.52294588e+00 -1.10571928e-01
  -3.40277851e-02  1.15968496e-01 -7.57682621e-02]
 [-6.24968290e-01  4.42626774e-01 -8.98404777e-01  5.56450903e-01
  -3.71360987e-01 -1.03725262e-01  4.02868062e-01 -2.66276747e-02
   3.57256889e-01  4.79882210e-01 -3.32526028e-01  1.75967604e-01
   1.85024559e-01  3.92382108e-02  1.07147612e-01  1.17679276e-01
  -1.73717827e-01  2.49621570e-01 -2.61997014e-01 -1.49054468e-01
   6.07348204e-01 -3.42899024e-01  0.00000000e+00 -1.63551295e+00
   1.75922662e-01  1.14097752e-01 -8.51079524e-01  9.97348800e-02
   9.03296918e-02 -7.63184428e-02  7.26868212e-02]
 [-1.77198768e-01 -2.86528707e-01 -8.13382789e-02  9.92919579e-02
  -1.29084074e+00  6.70777142e-01  5.77111483e-01 -8.88769776e-02
   1.41930491e-01  6.32992536e-02  9.32350382e-02 -1.15862206e-01
   4.02539283e-01  2.36165002e-01  3.53870749e-01  1.02935284e-02
  -1.75657466e-01 -9.69285741e-02 -1.60486192e-01  6.58358753e-01
  -3.83784086e-01 -2.24543065e-01  0.00000000e+00  4.23395276e-01
   3.25330235e-02 -5.55602372e-01  3.48558813e-01 -2.18591094e-01
   2.23729283e-01  1.14932746e-01 -1.79313142e-02]
 [ 8.92740369e-01 -1.21604311e+00  4.66681808e-01  1.79148111e-02
   2.45707184e-02  8.30945373e-01 -4.89901006e-01  7.99527228e-01
   3.76926437e-02  7.68536404e-02 -2.08924741e-01  5.48284352e-01
   1.06011964e-01 -1.98116675e-01 -7.38254607e-01  3.28864068e-01
  -3.76861811e-01  2.27851868e-01  2.88977265e-01 -1.92369729e-01
   2.59052873e-01  8.39488745e-01  0.00000000e+00  1.88242102e+00
   9.15160060e-01 -6.08437061e-01 -1.08409941e-01  4.13736880e-01
  -3.20383728e-01 -4.72830564e-01 -1.48770623e-02]
 [ 4.15755570e-01 -4.74210158e-02  1.38449565e-01  1.00829892e-01
   2.10326925e-01 -3.65294427e-01 -4.57485437e-01 -2.35200942e-01
   4.38201010e-01 -2.05884203e-01 -3.99543583e-01 -2.17268392e-02
   2.25557879e-01  3.87856886e-02 -2.18918407e-03 -3.40303332e-01
  -1.95349216e-01 -1.24205470e-01  1.33700356e-01  4.44391727e-01
  -7.81964242e-01 -7.58748293e-01  0.00000000e+00  3.83036345e-01
   3.41891229e-01 -9.24373686e-01 -3.44700217e-01  4.89053011e-01
  -8.50645155e-02 -3.73818129e-01 -5.95906973e-01]
 [ 6.41154051e-01  3.37557793e-01  2.83643931e-01 -1.35616457e+00
  -4.68263775e-01 -8.47803891e-01 -1.18001986e+00  3.76001120e-01
   3.91849801e-02  9.83202681e-02 -2.31172025e-01  1.15914106e-01
   2.60332048e-01  8.63628238e-02  2.35143956e-02 -1.70469269e-01
   1.18656598e-01  4.71216738e-01  1.21947691e-01 -8.08251441e-01
   9.03922096e-02  1.38807938e-01  0.00000000e+00  1.57863712e+00
   4.98813003e-01 -1.61344039e+00  1.32089257e+00 -4.62521642e-01
   2.05300316e-01  5.79189003e-01  5.55020809e-01]
 [ 3.60034108e-02  7.67257344e-03 -6.98638380e-01  4.85708445e-01
  -1.29481101e+00  5.53385504e-02 -7.56273866e-02 -6.09043241e-01
  -3.51963460e-01 -1.95649624e-01 -3.39335240e-02 -2.34038636e-01
  -5.28396443e-02  2.19291836e-01 -6.03780933e-02 -9.07979310e-02
  -2.02189848e-01 -5.25277779e-02 -8.66898708e-03  2.05893070e-02
   4.90600139e-01  6.06440365e-01  0.00000000e+00  1.76005781e+00
  -5.42625606e-01 -1.02292895e+00  8.01402986e-01 -3.67876381e-01
  -4.38896343e-02  2.46581927e-01 -2.67355710e-01]
 [-1.57804951e-01 -1.93809271e-01  1.02898479e+00  5.11063516e-01
  -4.74434912e-01  2.46352538e-01 -3.26581858e-02  2.19091047e-02
  -3.61383110e-01 -2.80940890e-01  2.24536002e-01  2.13068664e-01
   1.31324127e-01 -2.47522011e-01  4.55174714e-01  1.64270028e-01
  -6.01137936e-01 -1.98013321e-01  5.68196833e-01 -9.80517045e-02
   5.79907000e-01  2.03512713e-01  0.00000000e+00  1.32426703e+00
  -9.35543060e-01 -3.31774831e-01  1.12093663e+00  5.75595461e-02
  -1.61565572e-01  3.63838859e-02  3.39025885e-01]
 [ 3.16732258e-01 -3.83855790e-01 -2.83055514e-01 -8.54100138e-02
  -8.36213470e-01 -3.24855500e-05 -5.43858707e-01 -3.17064337e-02
   2.92859286e-01  6.18303455e-02  1.13387287e-01 -5.27197599e-01
   1.20162135e-02  1.04343399e-01  1.60209881e-03 -1.20201401e-01
  -1.32553935e-01 -1.94758043e-01 -9.62805599e-02  1.80751622e-01
  -5.85892260e-01  8.27701092e-02  0.00000000e+00  8.88845861e-01
   1.33094418e+00 -5.13918936e-01 -2.80753434e-01  2.87676603e-01
   3.20382535e-01 -2.64906824e-01  6.06529266e-02]
 [-2.10854590e-01 -1.13472509e+00 -6.40003264e-01  9.86311018e-01
  -1.77692130e-01  1.85218954e+00  1.16771090e+00  5.19027948e-01
   1.15492314e-01 -1.16215954e-02 -2.09119260e-01  2.80016333e-01
   2.61475742e-01  1.74286991e-01 -5.67484498e-02  4.31424044e-02
  -1.06386654e-01  1.56662479e-01  3.39574963e-02 -1.09141037e-01
  -2.82227755e-01  3.71830463e-01  0.00000000e+00  1.72710133e+00
  -2.54897088e-01  3.81801188e-01  4.95366454e-02  1.20591387e-01
  -9.77698863e-02 -1.79820269e-01 -1.08390599e-01]
 [ 2.94792444e-01 -1.80234104e-01 -9.45258617e-01  2.03779548e-01
  -6.66597068e-01  1.74163684e-01  1.10995613e-01  1.08779259e-01
   3.33873034e-01 -9.22608078e-02 -7.08168373e-02  1.27328411e-01
  -1.40865281e-01 -1.02967255e-01 -2.88913757e-01  6.63279032e-04
   1.58132054e-02  5.90206757e-02  3.21817487e-01  7.41249979e-01
  -3.47356707e-01 -1.87513351e-01  0.00000000e+00  6.88949168e-01
   6.89964555e-03 -6.21733442e-02  2.34820962e-01  3.29931974e-02
   2.98168305e-02 -1.49784476e-01 -9.50081721e-02]
 [-6.67452812e-01  1.38474035e+00  1.23455632e+00  1.57202899e-01
   1.74883246e+00 -1.12067032e+00 -3.42481822e-01 -6.54553950e-01
   2.28824422e-01  2.04294652e-01 -2.82363802e-01 -1.77971661e-01
  -1.90061420e-01  2.97669530e-01  1.29798293e-01 -4.43857424e-02
  -2.41367429e-01 -1.63145617e-01  3.06502432e-01  7.59017050e-01
  -5.49215198e-01 -1.27685010e-01  0.00000000e+00 -3.50865334e-01
  -9.78772342e-02 -4.37071651e-01  3.42490613e-01  8.57401267e-03
   1.71377480e-01 -3.71185690e-01 -5.62467277e-01]
 [-1.91825181e-01  6.77523971e-01  2.65178353e-01  2.92960018e-01
  -2.35643253e-01 -6.79048002e-01 -1.76491201e-01  6.46104753e-01
   2.23806471e-01  4.42119777e-01  5.15198886e-01 -1.87782750e-01
   1.57752335e-01  5.35469174e-01 -3.02843511e-01  5.37263930e-01
   1.00268054e+00  4.78971273e-01 -1.33380008e+00  7.68559892e-03
   7.85466373e-01  5.74971676e-01  0.00000000e+00  3.45745087e-02
   1.50417507e+00 -7.14086235e-01 -3.91673952e-01 -2.96078861e-01
  -2.38503069e-02  5.47812223e-01  3.86433214e-01]
 [ 1.26931453e+00 -2.55051374e+00  3.78774822e-01 -1.52502751e+00
  -6.97381854e-01  2.20281386e+00  4.09762681e-01 -6.22534633e-01
   2.35857949e-01  2.10892960e-01  1.35469204e-02 -3.34103554e-01
  -3.63902479e-01  4.85194206e-01  3.56837332e-01  9.61749069e-03
   2.97771871e-01  3.09208054e-02 -1.51415676e-01  4.73012388e-01
  -3.89781624e-01 -6.72709405e-01  0.00000000e+00 -4.19222927e+00
  -3.04430604e-01  1.54759419e+00 -3.28825426e+00 -2.19847858e-01
   1.51757598e-01  7.37138987e-02 -3.73639554e-01]
 [ 1.42058802e+00 -9.67213660e-02 -1.43865502e+00 -2.06736422e+00
   1.15796041e+00 -5.36676824e-01 -1.38192952e+00  4.28931415e-03
  -2.27251157e-01 -1.20658733e-01  4.47364688e-01  1.30644575e-01
   5.14725804e-01 -1.21475019e-01  1.59848899e-01  6.33786097e-02
  -1.04220949e-01 -1.03829883e-01 -3.69792014e-01  9.76711139e-02
   5.41807353e-01  7.36005485e-01  0.00000000e+00 -3.84393752e-01
   3.04589659e-01  3.30631346e-01  1.02489432e-02  3.37432846e-02
   4.37591709e-02 -7.44792446e-02 -4.37109210e-02]
 [-1.93710625e-01  2.78077602e-01 -7.08065182e-03  2.40872368e-01
   4.87094373e-03 -2.29145318e-01 -3.47872488e-02  6.96308911e-02
   8.58664066e-02 -8.03382322e-02 -3.44852746e-01  1.29713044e-01
   3.80947627e-02  5.05493768e-02 -1.39468256e-02  4.22564335e-02
  -4.63147201e-02  1.37966676e-02 -6.72237426e-02  1.61423415e-01
  -3.81300002e-02  1.06794991e-01  1.00000000e+00  8.85073125e-01
   7.14710414e-01 -5.01415014e-01  5.33631146e-01  1.88261092e-01
  -1.03526175e-01 -4.82926071e-02 -1.80695921e-01]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00 -4.01358694e-01
   2.61337571e-02  1.66197762e-01 -2.82208264e-01 -1.00258216e-01
   1.24145309e-02  1.04195938e-01  3.46360281e-02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  5.39987534e-02
   4.36922126e-02 -4.95263934e-02  8.62277225e-02  5.44657968e-02
  -2.40022670e-02 -2.33948324e-02  1.84958410e-02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.10057548e-01
   2.22822428e-01  1.09032169e-01 -2.38768876e-01  8.67379233e-02
  -4.55593597e-03 -5.66320904e-02 -5.71450628e-02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00 -6.91203997e-02
  -3.01543415e-01  8.91972184e-02  3.31730366e-01  4.77166213e-02
   4.63697780e-03 -2.85738055e-02  7.52874985e-02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00 -9.70698059e-01
   5.89833021e-01  3.81658942e-01 -1.06969941e+00  4.22228128e-01
  -2.01652676e-01 -1.55742615e-01 -4.45929110e-01]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.44238698e-01
  -8.79182696e-01  3.16938639e-01  5.36330819e-01 -2.71489352e-01
   3.75020653e-01  4.98714685e-01  1.28942449e-02]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  1.63723910e+00
  -9.24677670e-01 -1.74736902e-01  1.91456509e+00  2.84888390e-02
   1.68726034e-02  6.38559997e-01  2.65504658e-01]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  1.73968017e+00
  -6.07241571e-01  5.67882538e-01  7.59137392e-01  4.28801447e-01
  -4.85817492e-01 -7.66119838e-01 -1.85443640e-01]]
Eigen values: 
[1.         0.95182735 0.95182735 0.7681029  0.7681029  0.99890142
 0.99890142 0.69286066 0.69286066 0.82287222 0.82287222 0.36575727
 0.36575727 0.89994308 0.22303001 0.22303001 0.05050051 0.05050051
 0.30547913 0.60893377 0.60893377 0.64531761 0.56347962 0.70692147
 0.77291338 0.77291338 0.16631538 0.03681724 0.21034869 0.43227121
 0.43227121]
[COMP] The identified Koopman operator is STABLE
------ ------ -----
----- Run Info ----
------ ------ -----
                                  0           1           2
x_hidden_variable_list            6           6           4
activation flag                   2           2           2
activation function             elu         elu         elu
no of epochs                   1000        1000        1000
batch size                      400         400         400
step size                       0.5         0.5         0.5
training error           0.00177503  0.00177503  0.00177503
validation error         0.00193086  0.00193086  0.00193086
r^2 training accuracy       95.6241     95.6241     95.6241
r^2 validation accuracy     95.2524     95.2524     95.2524
MSE training             0.00177503  0.00177503  0.00177503
MSE validation           0.00193086  0.00193086  0.00193086
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
                                  0           1           2
x_hidden_variable_list            6           6           4
activation flag                   2           2           2
activation function             elu         elu         elu
no of epochs                  10000       10000       10000
batch size                      400         400         400
step size                       0.3         0.3         0.3
training error           0.00092893  0.00092893  0.00092893
validation error         0.00106872  0.00106872  0.00106872
r^2 training accuracy        97.877      97.877      97.877
r^2 validation accuracy       97.52       97.52       97.52
MSE training             0.00092893  0.00092893  0.00092893
MSE validation           0.00106872  0.00106872  0.00106872
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
                                   0            1            2
x_hidden_variable_list             6            6            4
activation flag                    2            2            2
activation function              elu          elu          elu
no of epochs                   10000        10000        10000
batch size                       400          400          400
step size                        0.1          0.1          0.1
training error           0.000812979  0.000812979  0.000812979
validation error         0.000945667  0.000945667  0.000945667
r^2 training accuracy        98.1578      98.1578      98.1578
r^2 validation accuracy      97.8009      97.8009      97.8009
MSE training             0.000812979  0.000812979  0.000812979
MSE validation           0.000945667  0.000945667  0.000945667
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
                                   0            1            2
x_hidden_variable_list             6            6            4
activation flag                    2            2            2
activation function              elu          elu          elu
no of epochs                   10000        10000        10000
batch size                       400          400          400
step size                       0.09         0.09         0.09
training error           0.000769035  0.000769035  0.000769035
validation error         0.000896962  0.000896962  0.000896962
r^2 training accuracy        98.3063      98.3063      98.3063
r^2 validation accuracy      97.9745      97.9745      97.9745
MSE training             0.000769035  0.000769035  0.000769035
MSE validation           0.000896962  0.000896962  0.000896962
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
                                   0            1            2
x_hidden_variable_list             6            6            4
activation flag                    2            2            2
activation function              elu          elu          elu
no of epochs                   10000        10000        10000
batch size                       400          400          400
step size                       0.08         0.08         0.08
training error           0.000739234  0.000739234  0.000739234
validation error         0.000865616  0.000865616  0.000865616
r^2 training accuracy        98.4183      98.4183      98.4183
r^2 validation accuracy      98.0993      98.0993      98.0993
MSE training             0.000739234  0.000739234  0.000739234
MSE validation           0.000865616  0.000865616  0.000865616
-----     -----     -----     -----     -----     -----     -----     -----     -----     -----     -----
